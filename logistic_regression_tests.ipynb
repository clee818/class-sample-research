{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b520ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6a2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logistic_regression\n",
    "import reduceClasses\n",
    "import binaryRatio\n",
    "import train_with_dir\n",
    "import test \n",
    "import get_confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82986e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f35e2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x108b19b30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 10\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "n_epochs = 20\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "\n",
    "ratio = (100, 1) # (10, 1)? \n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32fb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = torchvision.datasets.MNIST('mnist', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "\n",
    "test_mnist = torchvision.datasets.MNIST('mnist', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a59eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_train_mnist = reduceClasses.Reduce(train_mnist, NUM_CLASSES_REDUCED)\n",
    "reduced_test_mnist = reduceClasses.Reduce(test_mnist, NUM_CLASSES_REDUCED)\n",
    "\n",
    "\n",
    "reduced_train_mnist_ratio = binaryRatio.Ratio(train_mnist, 2, ratio) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f647b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_reduced = DataLoader(reduced_train_mnist, batch_size=batch_size_train, shuffle=False) \n",
    "train_loader_reduced_ratio = DataLoader(reduced_train_mnist_ratio, batch_size=batch_size_train, shuffle=False)\n",
    "train_loader_normal = DataLoader(train_mnist, batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_mnist, batch_size=batch_size_test, shuffle=False) \n",
    "test_loader_normal = DataLoader(test_mnist, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25d1b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5923])\n",
      "torch.Size([980])\n",
      "torch.Size([6742])\n",
      "torch.Size([1135])\n",
      "torch.Size([5918])\n",
      "torch.Size([958])\n",
      "torch.Size([5851])\n",
      "torch.Size([974])\n"
     ]
    }
   ],
   "source": [
    "print(train_mnist.train_labels[train_mnist.train_labels==0].shape)\n",
    "print(test_mnist.test_labels[test_mnist.test_labels==0].shape)\n",
    "print(train_mnist.train_labels[train_mnist.train_labels==1].shape)\n",
    "print(test_mnist.test_labels[test_mnist.test_labels==1].shape)\n",
    "\n",
    "\n",
    "print(train_mnist.train_labels[train_mnist.train_labels==6].shape)\n",
    "print(test_mnist.test_labels[test_mnist.test_labels==6].shape)\n",
    "print(train_mnist.train_labels[train_mnist.train_labels==8].shape)\n",
    "print(test_mnist.test_labels[test_mnist.test_labels==8].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aebb3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.391519\n",
      "Train Epoch: 0 [640/60000 (1%)]\tLoss: 1.264056\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 0.899669\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 0.661826\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 0.528469\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 0.524239\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.430666\n",
      "Train Epoch: 0 [4480/60000 (7%)]\tLoss: 0.408026\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.749220\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.416634\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.408048\n",
      "Train Epoch: 0 [7040/60000 (12%)]\tLoss: 0.414640\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.446291\n",
      "Train Epoch: 0 [8320/60000 (14%)]\tLoss: 0.360250\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.369983\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.422143\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.590449\n",
      "Train Epoch: 0 [10880/60000 (18%)]\tLoss: 0.299529\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.627557\n",
      "Train Epoch: 0 [12160/60000 (20%)]\tLoss: 0.485572\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.374315\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.265171\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.599060\n",
      "Train Epoch: 0 [14720/60000 (25%)]\tLoss: 0.678561\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.316214\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.565068\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.495589\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.228640\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.323359\n",
      "Train Epoch: 0 [18560/60000 (31%)]\tLoss: 0.440105\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.419452\n",
      "Train Epoch: 0 [19840/60000 (33%)]\tLoss: 0.292677\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.253476\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.320642\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.120480\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.328457\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.504898\n",
      "Train Epoch: 0 [23680/60000 (39%)]\tLoss: 0.596332\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.270609\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.371619\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.285583\n",
      "Train Epoch: 0 [26240/60000 (44%)]\tLoss: 0.372914\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.517124\n",
      "Train Epoch: 0 [27520/60000 (46%)]\tLoss: 0.221134\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.373895\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.217079\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.250801\n",
      "Train Epoch: 0 [30080/60000 (50%)]\tLoss: 0.487548\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.451506\n",
      "Train Epoch: 0 [31360/60000 (52%)]\tLoss: 0.566454\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.392212\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.430564\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.381347\n",
      "Train Epoch: 0 [33920/60000 (57%)]\tLoss: 0.178862\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.356837\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.375125\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.305694\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.303614\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.419039\n",
      "Train Epoch: 0 [37760/60000 (63%)]\tLoss: 0.324151\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.246208\n",
      "Train Epoch: 0 [39040/60000 (65%)]\tLoss: 0.172362\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.337878\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.274699\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.448082\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.277689\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.252125\n",
      "Train Epoch: 0 [42880/60000 (71%)]\tLoss: 0.490200\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.332981\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.225066\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.449534\n",
      "Train Epoch: 0 [45440/60000 (76%)]\tLoss: 0.680374\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.523756\n",
      "Train Epoch: 0 [46720/60000 (78%)]\tLoss: 0.413750\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.327124\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.198700\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.295212\n",
      "Train Epoch: 0 [49280/60000 (82%)]\tLoss: 0.214101\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.297974\n",
      "Train Epoch: 0 [50560/60000 (84%)]\tLoss: 0.446539\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.435508\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.234210\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.146901\n",
      "Train Epoch: 0 [53120/60000 (88%)]\tLoss: 0.416313\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.151265\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.286268\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.279606\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.389960\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.233302\n",
      "Train Epoch: 0 [56960/60000 (95%)]\tLoss: 0.340218\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.451240\n",
      "Train Epoch: 0 [58240/60000 (97%)]\tLoss: 0.137249\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.061280\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.075249\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.246069\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.368521\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.390758\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.224682\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.212543\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.284067\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.137218\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.229660\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.588564\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.225056\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.271461\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.218576\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.273756\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.184197\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.249885\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.321270\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.502842\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.192247\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.575668\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.461249\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.229961\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.204620\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.499726\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.624610\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.191849\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.470697\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.421706\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.147273\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.273384\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.382151\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.346907\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.204644\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.198499\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.292199\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.088169\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.262757\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.454473\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.564171\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.206460\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.304238\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.233281\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.323621\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.474124\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.228801\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.288470\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.167131\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.189844\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.407031\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.378888\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.489107\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.360178\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.410049\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.373093\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.155084\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.315477\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.329127\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.260131\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.256863\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.403658\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.281571\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.207494\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.150334\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.300181\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.269003\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.443696\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.226933\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.222455\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.406453\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.326287\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.186827\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.411546\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.642186\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.489366\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.402514\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.289337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.172809\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.281974\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.207006\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.263407\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.389676\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.397663\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.200177\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.126119\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.404812\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.131283\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.264004\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.245760\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.383820\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.202636\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.300903\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.442992\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.124083\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.055349\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.066162\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9123/10000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.208912\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.349531\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.365097\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.205246\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.192188\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.281523\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.113111\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.215528\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.556448\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.215380\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.260346\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.198700\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.253884\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.171077\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.230557\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.299305\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.451687\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.179611\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.542470\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.454845\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.202932\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.196784\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.451837\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.626144\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.168075\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.454588\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.401709\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.135332\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.256643\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.364643\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.323707\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.186230\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.188301\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.286248\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.080954\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.244660\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.439868\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.550678\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.189317\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.287179\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.218687\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.312339\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.469904\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.233300\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.266593\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.155706\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.168600\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.389520\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.356305\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.460176\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.350245\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.410269\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.378863\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.145349\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.296381\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.315409\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.243684\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.241311\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.398844\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.269297\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.193144\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.144658\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.291260\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.270617\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.442300\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.206464\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.215829\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.369302\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.328165\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.174189\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.395395\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.622427\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.472577\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.400799\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.272013\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.162075\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.278196\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.203711\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.250522\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.362324\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.377613\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.184180\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.120134\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.402594\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.123412\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.252184\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.227389\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.379787\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.190311\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.280153\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.432966\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.118981\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.052323\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.062453\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9148/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.191086\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.343257\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.350229\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.196055\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.183583\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.280235\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.101423\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.206373\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.539961\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.213979\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.256667\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.188632\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.242661\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.166934\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.221591\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.289845\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.421317\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.172711\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.519567\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.448331\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.190724\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.193775\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.418768\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.626602\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.156281\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.448077\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.391260\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.131134\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.247629\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.355529\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.310849\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.177338\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.182507\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.281402\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.077123\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.234586\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.431746\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.540569\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.180335\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.279276\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.210621\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.306308\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.471545\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.234770\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.256442\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.150338\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.156308\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.381690\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.345000\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.442471\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.345636\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.414145\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.384877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.138774\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.283136\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.308743\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.233359\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.233128\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.396185\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.264195\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.184802\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.142904\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.287818\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.272144\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.440608\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.194314\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.213023\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.349038\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.329433\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.167231\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.386107\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.609218\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.463032\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.399997\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.260932\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.155654\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.276498\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.200868\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.243575\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.345494\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.363272\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.174387\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.118005\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.402464\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.118997\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.243048\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.215399\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.376596\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.183011\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.266585\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.424248\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.116294\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.050223\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.060239\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.180080\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.339804\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.340417\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.190289\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.178487\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.278791\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.094144\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.199071\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.529035\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.214859\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.254747\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.181932\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.234760\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.164837\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.216204\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.284800\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.400380\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.167876\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.502619\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.442760\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.183754\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.191864\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.395317\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.626015\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.148809\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.444628\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.384525\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.129217\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.242096\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.349629\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.302132\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.172273\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.178254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m      4\u001b[0m                   momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 6\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogistic_regression_results/normal\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/model\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     _, _, _ \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mtest(test_loader_normal, network)\n",
      "File \u001b[0;32m~/Downloads/ML/numbers mnist/train_with_dir.py:14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, train_loader, network, optimizer, directory, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m     output \u001b[38;5;241m=\u001b[39m network(data)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py:164\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    163\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 164\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    network = logistic_regression.Net(NUM_CLASSES)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "    for epoch in range(n_epochs):\n",
    "        _, _ = train_with_dir.train(epoch, train_loader_normal, network, optimizer, f'logistic_regression_results/normal{i}/model{epoch}')\n",
    "        _, _, _ = test.test(test_loader_normal, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    network = logistic_regression.Net(NUM_CLASSES_REDUCED)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "    for epoch in range(n_epochs):\n",
    "        _, _ = train_with_dir.train(epoch, train_loader_reduced, network, optimizer, f'logistic_regression_results/reduced{i}/model{epoch}')\n",
    "        _, _, _ = test.test(test_loader_reduced, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0887ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    network = logistic_regression.Net(NUM_CLASSES_REDUCED)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "    for epoch in range(n_epochs): \n",
    "        _, _ = train_with_dir.train(epoch, train_loader_reduced_ratio, network, optimizer, f'logistic_regression_results/reduced_ratio{i}/model{epoch}')\n",
    "        _, _, _ = test.test(test_loader_reduced, network)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "994d3589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0417, Accuracy: 990/2115 (47%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caralee/Downloads/ML/numbers mnist/get_confidence_interval.py:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  y_pred = np.asarray(y_pred)\n",
      "/Users/caralee/Downloads/ML/numbers mnist/get_confidence_interval.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_pred = np.asarray(y_pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46808510638297873 [0.448 - 0.491]\n",
      "\n",
      "Test set: Avg. loss: 0.0433, Accuracy: 2105/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9952718676122931 [0.992 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2110/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9976359338061466 [0.995 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0404, Accuracy: 2104/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9947990543735225 [0.991 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.1013, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1280, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0594, Accuracy: 344/2115 (16%)\n",
      "\n",
      "Accuracy: 0.16264775413711585 [0.147 - 0.178]\n",
      "\n",
      "Test set: Avg. loss: 0.0879, Accuracy: 2094/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9900709219858156 [0.986 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.0349, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.0231, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 769/2115 (36%)\n",
      "\n",
      "Accuracy: 0.36359338061465724 [0.344 - 0.385]\n",
      "\n",
      "Test set: Avg. loss: 0.1846, Accuracy: 2072/2115 (98%)\n",
      "\n",
      "Accuracy: 0.9796690307328605 [0.974 - 0.985]\n",
      "\n",
      "Test set: Avg. loss: 0.0198, Accuracy: 2109/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9971631205673759 [0.995 - 0.999]\n",
      "\n",
      "Test set: Avg. loss: 0.0508, Accuracy: 2104/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9947990543735225 [0.991 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.1004, Accuracy: 2095/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9905437352245863 [0.986 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.1319, Accuracy: 2094/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9900709219858156 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1429, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0342, Accuracy: 1406/2115 (66%)\n",
      "\n",
      "Accuracy: 0.6647754137115839 [0.645 - 0.684]\n",
      "\n",
      "Test set: Avg. loss: 0.6468, Accuracy: 1997/2115 (94%)\n",
      "\n",
      "Accuracy: 0.9442080378250591 [0.934 - 0.954]\n",
      "\n",
      "Test set: Avg. loss: 0.0425, Accuracy: 2105/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9952718676122931 [0.992 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.0853, Accuracy: 2103/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9943262411347518 [0.991 - 0.997]\n",
      "\n",
      "Test set: Avg. loss: 0.1301, Accuracy: 2095/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9905437352245863 [0.986 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.1517, Accuracy: 2091/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9886524822695035 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1651, Accuracy: 2089/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9877068557919622 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.0305, Accuracy: 965/2115 (46%)\n",
      "\n",
      "Accuracy: 0.4562647754137116 [0.434 - 0.478]\n",
      "\n",
      "Test set: Avg. loss: 0.0084, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0300, Accuracy: 2105/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9952718676122931 [0.992 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.0884, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.1151, Accuracy: 2088/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9872340425531915 [0.983 - 0.992]\n",
      "\n",
      "Test set: Avg. loss: 0.0299, Accuracy: 921/2115 (44%)\n",
      "\n",
      "Accuracy: 0.43546099290780144 [0.415 - 0.456]\n",
      "\n",
      "Test set: Avg. loss: 0.0149, Accuracy: 2110/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9976359338061466 [0.995 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0076, Accuracy: 2110/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9976359338061466 [0.995 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0419, Accuracy: 2104/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9947990543735225 [0.991 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.1030, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0999, Accuracy: 2094/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9900709219858156 [0.986 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1102, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.985 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 369/2115 (17%)\n",
      "\n",
      "Accuracy: 0.17446808510638298 [0.157 - 0.191]\n",
      "\n",
      "Test set: Avg. loss: 0.2882, Accuracy: 2053/2115 (97%)\n",
      "\n",
      "Accuracy: 0.9706855791962175 [0.964 - 0.978]\n",
      "\n",
      "Test set: Avg. loss: 0.0197, Accuracy: 2107/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9962174940898345 [0.993 - 0.999]\n",
      "\n",
      "Test set: Avg. loss: 0.0599, Accuracy: 2104/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9947990543735225 [0.991 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.1207, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1202, Accuracy: 2094/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9900709219858156 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1304, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.0143, Accuracy: 1486/2115 (70%)\n",
      "\n",
      "Accuracy: 0.7026004728132388 [0.684 - 0.721]\n",
      "\n",
      "Test set: Avg. loss: 0.0220, Accuracy: 2110/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9976359338061466 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0086, Accuracy: 2108/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9966903073286052 [0.994 - 0.999]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0596, Accuracy: 2092/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9891252955082742 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 998/2115 (47%)\n",
      "\n",
      "Accuracy: 0.4718676122931442 [0.452 - 0.495]\n",
      "\n",
      "Test set: Avg. loss: 0.0127, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0031, Accuracy: 2109/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9971631205673759 [0.995 - 0.999]\n",
      "\n",
      "Test set: Avg. loss: 0.0245, Accuracy: 2098/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9919621749408983 [0.988 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 2096/2115 (99%)\n",
      "\n",
      "Accuracy: 0.991016548463357 [0.987 - 0.995]\n",
      "\n",
      "Test set: Avg. loss: 0.0225, Accuracy: 913/2115 (43%)\n",
      "\n",
      "Accuracy: 0.43167848699763595 [0.410 - 0.452]\n",
      "\n",
      "Test set: Avg. loss: 0.7483, Accuracy: 1985/2115 (94%)\n",
      "\n",
      "Accuracy: 0.9385342789598109 [0.928 - 0.948]\n",
      "\n",
      "Test set: Avg. loss: 0.0544, Accuracy: 2104/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9947990543735225 [0.991 - 0.998]\n",
      "\n",
      "Test set: Avg. loss: 0.0984, Accuracy: 2101/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9933806146572104 [0.990 - 0.996]\n",
      "\n",
      "Test set: Avg. loss: 0.1376, Accuracy: 2093/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9895981087470449 [0.985 - 0.994]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n",
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n",
      "\n",
      "Test set: Avg. loss: 0.1607, Accuracy: 2090/2115 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9881796690307328 [0.984 - 0.993]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1435ef9a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(10):\n",
    "    model_accuracies = []\n",
    "    network = logistic_regression.Net(NUM_CLASSES_REDUCED)\n",
    "    _, y_preds, y_true = test.test(test_loader_reduced, network) \n",
    "    _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "    model_accuracies.append(acc)\n",
    "    for epoch in range(n_epochs):\n",
    "        state_dict = torch.load(f'logistic_regression_results/reduced_ratio{i}/model{epoch}')\n",
    "        network.load_state_dict(state_dict)\n",
    "        _, y_preds, y_true = test.test(test_loader_reduced, network) \n",
    "        _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "        model_accuracies.append(acc)\n",
    "    accuracies.append(model_accuracies)\n",
    "    \n",
    "for i in range(10):\n",
    "    plt.plot(np.arange(-1, n_epochs), accuracies[i])\n",
    "plt.title(\"Logistic Regression 2 classes 100:1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3734d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1457, Accuracy: 4/2115 (0%)\n",
      "\n",
      "Accuracy: 0.0018912529550827422 [0.000 - 0.00378]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9063 [0.900 - 0.912]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9123/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9123 [0.906 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9148/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9148 [0.909 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9159 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9172 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9181/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9181 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9188/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9188 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9189/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9189 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Accuracy: 0.919 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9194/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9194 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9195 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9197 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9203 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0861, Accuracy: 59/2115 (3%)\n",
      "\n",
      "Accuracy: 0.027895981087470448 [0.021 - 0.0355]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9064/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9064 [0.900 - 0.912]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9127 [0.907 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9159 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9176/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9176 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9183/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9183 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9188/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9188 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9184/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9184 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9188/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9188 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9195 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9199 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9202 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9203 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9208/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9208 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Accuracy: 0.921 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9211 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9214 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9214 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0861, Accuracy: 150/2115 (7%)\n",
      "\n",
      "Accuracy: 0.07092198581560284 [0.061 - 0.0823]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9071/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9071 [0.901 - 0.913]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9127 [0.907 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9146/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9146 [0.909 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9164/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9164 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9176/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9176 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9172 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9181/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9181 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9187/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9187 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9191 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9197 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9195 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9199 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9202 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9211 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9212/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9212 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9211 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0463, Accuracy: 512/2115 (24%)\n",
      "\n",
      "Accuracy: 0.242080378250591 [0.223 - 0.261]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9059 [0.900 - 0.911]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9127 [0.907 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9142/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9142 [0.909 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9153/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9153 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9164/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9164 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9170/10000 (92%)\n",
      "\n",
      "Accuracy: 0.917 [0.912 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9172/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9172 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9179 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9191 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9195 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9196 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9203 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9208/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9208 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9208/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9208 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9213 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9214 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9217/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9217 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0904, Accuracy: 36/2115 (2%)\n",
      "\n",
      "Accuracy: 0.01702127659574468 [0.011 - 0.0232]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9057/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9057 [0.900 - 0.912]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9130/10000 (91%)\n",
      "\n",
      "Accuracy: 0.913 [0.907 - 0.919]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9151/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9151 [0.909 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9166/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9166 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9172/10000 (92%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9172 [0.912 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9176/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9176 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9179 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9180/10000 (92%)\n",
      "\n",
      "Accuracy: 0.918 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9180/10000 (92%)\n",
      "\n",
      "Accuracy: 0.918 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9185/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9185 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9189/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9189 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9194/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9194 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9193/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9193 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9196/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9196 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9204 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9204 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9204 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.1195, Accuracy: 20/2115 (1%)\n",
      "\n",
      "Accuracy: 0.009456264775413711 [0.006 - 0.0142]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9067/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9067 [0.901 - 0.912]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9121/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9121 [0.906 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9142/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9142 [0.908 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9158/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9158 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9171/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9171 [0.912 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9176/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9176 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9182 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9191 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9190/10000 (92%)\n",
      "\n",
      "Accuracy: 0.919 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9192 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9197 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9202 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Accuracy: 0.921 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9212/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9212 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9212/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9212 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0872, Accuracy: 251/2115 (12%)\n",
      "\n",
      "Accuracy: 0.11867612293144209 [0.106 - 0.133]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9074/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9074 [0.902 - 0.913]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9127 [0.907 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9157/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9157 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9163/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9163 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9170/10000 (92%)\n",
      "\n",
      "Accuracy: 0.917 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9182 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9194/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9194 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9192 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9193/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9193 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9195/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9195 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9199 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9198/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9198 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9197 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9199 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.1181, Accuracy: 17/2115 (1%)\n",
      "\n",
      "Accuracy: 0.008037825059101654 [0.005 - 0.0118]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9075/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9075 [0.902 - 0.913]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9130/10000 (91%)\n",
      "\n",
      "Accuracy: 0.913 [0.907 - 0.919]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9144/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9144 [0.909 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9160/10000 (92%)\n",
      "\n",
      "Accuracy: 0.916 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9173/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9173 [0.912 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9179/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9179 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9182 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9185/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9185 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9193/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9193 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9197/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9197 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9202 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9201 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9207 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Accuracy: 0.921 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9212/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9212 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9213 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0851, Accuracy: 43/2115 (2%)\n",
      "\n",
      "Accuracy: 0.02033096926713948 [0.015 - 0.0265]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9074/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9074 [0.901 - 0.913]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9137/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9137 [0.908 - 0.919]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9157/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9157 [0.910 - 0.921]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9164/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9164 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9174/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9174 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9182 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9186/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9186 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9188/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9188 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9192/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9192 [0.914 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9202 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9202/10000 (92%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9202 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9203 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9205/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9205 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Accuracy: 0.921 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9214 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9216/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9216 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9214/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9214 [0.916 - 0.927]\n",
      "\n",
      "Test set: Avg. loss: 0.1120, Accuracy: 128/2115 (6%)\n",
      "\n",
      "Accuracy: 0.06052009456264775 [0.050 - 0.0709]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9071/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9071 [0.901 - 0.913]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9128/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9128 [0.907 - 0.918]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9148/10000 (91%)\n",
      "\n",
      "Accuracy: 0.9148 [0.909 - 0.92]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9166/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9166 [0.911 - 0.922]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9174/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9174 [0.912 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9182/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9182 [0.913 - 0.923]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9184/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9184 [0.913 - 0.924]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9193/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9193 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9191 [0.914 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9199/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9199 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "Accuracy: 0.92 [0.915 - 0.925]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9204/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9204 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9203 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9206/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9206 [0.915 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9210/10000 (92%)\n",
      "\n",
      "Accuracy: 0.921 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9213 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9211 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9211 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9209/10000 (92%)\n",
      "\n",
      "Accuracy: 0.9209 [0.916 - 0.926]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9211/10000 (92%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9211 [0.916 - 0.926]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12352b6d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(10):\n",
    "    model_accuracies = []\n",
    "    network = logistic_regression.Net(NUM_CLASSES)\n",
    "    _, y_preds, y_true = test.test(test_loader_reduced, network) \n",
    "    _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "    model_accuracies.append(acc)\n",
    "    for epoch in range(n_epochs):\n",
    "        state_dict = torch.load(f'logistic_regression_results/normal{i}/model{epoch}')\n",
    "        network.load_state_dict(state_dict)\n",
    "        _, y_preds, y_true = test.test(test_loader_normal, network) \n",
    "        _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "        model_accuracies.append(acc)\n",
    "    accuracies.append(model_accuracies)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(np.arange(-1, n_epochs), accuracies[i])\n",
    "plt.title(\"Logistic Regression 10 classes\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a06e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0217, Accuracy: 1376/2115 (65%)\n",
      "\n",
      "Accuracy: 0.6505910165484634 [0.632 - 0.671]\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0006, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0016, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0013, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0015, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0031, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0042, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0027, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0224, Accuracy: 999/2115 (47%)\n",
      "\n",
      "Accuracy: 0.4723404255319149 [0.453 - 0.494]\n",
      "\n",
      "Test set: Avg. loss: 0.0007, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0009, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0030, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0063, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0062, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0087, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0062, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0034, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0085, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0673, Accuracy: 539/2115 (25%)\n",
      "\n",
      "Accuracy: 0.2548463356973995 [0.236 - 0.274]\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0010, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0019, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0010, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0014, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0021, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0012, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0034, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0049, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0463, Accuracy: 1115/2115 (53%)\n",
      "\n",
      "Accuracy: 0.5271867612293144 [0.506 - 0.548]\n",
      "\n",
      "Test set: Avg. loss: 0.0000, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0008, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0016, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0036, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0076, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0132, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0080, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0059, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0375, Accuracy: 998/2115 (47%)\n",
      "\n",
      "Accuracy: 0.4718676122931442 [0.451 - 0.493]\n",
      "\n",
      "Test set: Avg. loss: 0.0015, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0118, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0073, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0038, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0188, Accuracy: 1096/2115 (52%)\n",
      "\n",
      "Accuracy: 0.5182033096926714 [0.497 - 0.539]\n",
      "\n",
      "Test set: Avg. loss: 0.0006, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0133, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0075, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 2110/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9976359338061466 [0.995 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0112, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0055, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0011, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0060, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0031, Accuracy: 2108/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9966903073286052 [0.994 - 0.999]\n",
      "\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0082, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0064, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0645, Accuracy: 962/2115 (45%)\n",
      "\n",
      "Accuracy: 0.4548463356973995 [0.435 - 0.475]\n",
      "\n",
      "Test set: Avg. loss: 0.0000, Accuracy: 2115/2115 (100%)\n",
      "\n",
      "Accuracy: 1.0 [1.000 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0000, Accuracy: 2115/2115 (100%)\n",
      "\n",
      "Accuracy: 1.0 [1.000 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0010, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0015, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0030, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0063, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0137, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0119, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0058, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0083, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0173, Accuracy: 1211/2115 (57%)\n",
      "\n",
      "Accuracy: 0.5725768321513003 [0.551 - 0.592]\n",
      "\n",
      "Test set: Avg. loss: 0.0025, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0056, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0122, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0159, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0079, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0077, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0129, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0157, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0134, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0095, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0046, Accuracy: 2111/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9981087470449173 [0.996 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0374, Accuracy: 805/2115 (38%)\n",
      "\n",
      "Accuracy: 0.3806146572104019 [0.361 - 0.402]\n",
      "\n",
      "Test set: Avg. loss: 0.0014, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0012, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0012, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0006, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0016, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0008, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0036, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0067, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0032, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0124, Accuracy: 1337/2115 (63%)\n",
      "\n",
      "Accuracy: 0.6321513002364066 [0.611 - 0.652]\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 2114/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9995271867612293 [0.999 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0024, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0028, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0026, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0018, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0019, Accuracy: 2112/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9985815602836879 [0.997 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n",
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 2113/2115 (100%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990543735224586 [0.998 - 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14210fd00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(10):\n",
    "    model_accuracies = []\n",
    "    network = logistic_regression.Net(NUM_CLASSES_REDUCED)\n",
    "    _, y_preds, y_true = test.test(test_loader_reduced, network) \n",
    "    _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "    model_accuracies.append(acc)\n",
    "    for epoch in range(n_epochs):\n",
    "        state_dict = torch.load(f'logistic_regression_results/reduced{i}/model{epoch}')\n",
    "        network.load_state_dict(state_dict)\n",
    "        _, y_preds, y_true = test.test(test_loader_reduced, network) \n",
    "        _, _, acc = get_confidence_interval.get_confidence_interval(y_preds, y_true)\n",
    "        model_accuracies.append(acc)\n",
    "    accuracies.append(model_accuracies)\n",
    "    \n",
    "for i in range(10):\n",
    "    plt.plot(np.arange(-1, n_epochs), accuracies[i])\n",
    "plt.title(\"Logistic Regression 2 classes\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac114c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378c3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import class_sampling\n",
    "import train\n",
    "import metric_utils\n",
    "import inference\n",
    "import loss_fns\n",
    "import torchvision.ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91dda12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "n_epochs = 30\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "momentum = 0\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "nums = (0, 1)\n",
    "ratio = (100, 1)\n",
    "\n",
    "CLASS_LABELS = {'airplane': 0,\n",
    "                 'automobile': 1,\n",
    "                 'bird': 2,\n",
    "                 'cat': 3,\n",
    "                 'deer': 4,\n",
    "                 'dog': 5,\n",
    "                 'frog': 6,\n",
    "                 'horse': 7,\n",
    "                 'ship': 8,\n",
    "                 'truck': 9}\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b57e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"name\", \n",
    "            \"num_classes\", \n",
    "            \"classes_used\", \n",
    "            \"ratio\", \n",
    "            \"learning_rate\", \n",
    "            \"mean_0\", \"variance_0\",\n",
    "            \"mean_10\", \"variance_10\",\n",
    "            \"mean_20\", \"variance_20\",\n",
    "            \"mean_30\", \"variance_30\",\n",
    "          #   \"mean_40\", \"variance_40\",\n",
    "          #   \"mean_50\", \"variance_50\",\n",
    "             \"cap\", \"normalization\", \"other\"]\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2a1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "norm=True\n",
    "\n",
    "if norm:\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.Normalize(mean=[143.8888, 127.1705, 117.5357], std=[69.8313, 64.5137, 66.9933])])\n",
    "else:\n",
    "   # transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    transform=None\n",
    "\n",
    "train_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=True, download=True,\n",
    "                             transform=transform)  \n",
    "\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=False, download=True,\n",
    "                             transform=transform)  \n",
    "\n",
    "train_CIFAR10.data = train_CIFAR10.data.reshape(50000, 3, 32, 32)\n",
    "test_CIFAR10.data = test_CIFAR10.data.reshape(10000, 3, 32, 32)\n",
    "\n",
    "    \n",
    "reduced_train_CIFAR10 = class_sampling.Reduce(train_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True, transform=transform)\n",
    "reduced_test_CIFAR10 = class_sampling.Reduce(test_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True, transform=transform)\n",
    "\n",
    "ratio_train_CIFAR10 = class_sampling.Ratio(train_CIFAR10, NUM_CLASSES_REDUCED, ratio, nums=nums, transform=transform)\n",
    "\n",
    "triplet_train_CIFAR10 = class_sampling.ForTripletLoss(reduced_train_CIFAR10, smote=False, transform=transform, num_classes=2)\n",
    "triplet_ratio_train_CIFAR10 = class_sampling.ForTripletLoss(ratio_train_CIFAR10, smote=False, transform=transform, num_classes=2)\n",
    "\n",
    "smote_train_CIFAR10 = class_sampling.Smote(ratio_train_CIFAR10, 5000 * NUM_CLASSES_REDUCED, transform=transform)\n",
    "triplet_smote_train_CIFAR10 = class_sampling.ForTripletLoss(smote_train_CIFAR10, smote=True, transform=transform, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13159c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000   50]\n"
     ]
    }
   ],
   "source": [
    "targets = ratio_train_CIFAR10.labels \n",
    "\n",
    "class_count = np.unique(targets, return_counts=True)[1]\n",
    "print(class_count)\n",
    "\n",
    "weight = 1. / class_count\n",
    "\n",
    "samples_weight = weight[targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "oversampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(max(class_count) * NUM_CLASSES_REDUCED), replacement=True)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "undersampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * NUM_CLASSES_REDUCED), replacement=False)\n",
    "undersampler_smote = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * 50 * NUM_CLASSES_REDUCED), replacement=False)\n",
    "weight *= class_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8cd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_reduced = DataLoader(reduced_train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_ratio = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True) \n",
    "\n",
    "train_loader_oversampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=oversampler)\n",
    "\n",
    "train_loader_undersampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler)\n",
    "\n",
    "train_loader_sampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=sampler)\n",
    "\n",
    "train_loader_smote = DataLoader(smote_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_smote_undersampled = DataLoader(smote_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler_smote)\n",
    "\n",
    "train_loader_tripletloss = DataLoader(triplet_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_tripletloss_ratio = DataLoader(triplet_ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_tripletloss_smote = DataLoader(triplet_smote_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_CIFAR10, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9137b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used in distance capped smote - get average tensor for the entire class \n",
    "dataset = train_loader_ratio.dataset\n",
    "class0 = dataset.images[dataset.labels==0]\n",
    "class1 = dataset.images[dataset.labels==1]\n",
    "class0_avg = torch.mean(class0.float(), 0)\n",
    "class1_avg = torch.mean(class1.float(), 0)\n",
    "class_img_list = [class0, class1]\n",
    "avg_tensors_list = [class0_avg, class1_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006935921907424927, AUC: 0.49950249999999996\n",
      "\n",
      "Train loss: 2.177517574683876\n",
      "Train loss: 1.6380580819336472\n",
      "Train loss: 1.1406405074581218\n",
      "Train loss: 0.7840143058710037\n"
     ]
    }
   ],
   "source": [
    "# triplet loss first few epochs + capped smote (cosine distance)\n",
    "\n",
    "# 2 class triplet loss with capped SMOTE \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 1e-2), (1e-6, 5e-3), (1e-6, 1e-2), (5e-6, 5e-2)]\n",
    "\n",
    "cap_aucs = []\n",
    "loss_fn_args = {}\n",
    "loss_caps = [0.75, 1, 5]\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "loss_fn_args['distance'] = 'cosine'\n",
    "start_epoch = 7\n",
    "\n",
    "for cap in loss_caps:\n",
    "    learning_rate_aucs = []\n",
    "    for learning_rate in learning_rates:\n",
    "        aucs = []\n",
    "        for i in range(10): \n",
    "            model_aucs = []\n",
    "            embed_network = models.ConvNetOnlyEmbeddingsEarly(2)\n",
    "            linear_probe = models.ConvNetLinearProbeEarly(2)\n",
    "            complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "            embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "            linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "            model_aucs.append(auc)\n",
    "            for epoch in range(start_epoch):\n",
    "                _, train_losses = train.train_triplet_loss_smote(epoch, train_loader_tripletloss_smote, embed_network, embed_optimizer, verbose=False)\n",
    "                print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "            for epoch in range(start_epoch, n_epochs+1):\n",
    "                loss_fn_args['loss_cap'] = cap\n",
    "                loss_fn_args['avg_tensors'] = []\n",
    "                for k in range(2):\n",
    "                    avg_tensor = embed_network(avg_tensors_list[k])\n",
    "                    loss_fn_args['avg_tensors'].append(avg_tensor)\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, complete_network, linear_optimizer, verbose=False, loss_fn=loss_fns.CappedBCELossAvgDistance, loss_fn_args=loss_fn_args)\n",
    "                if (epoch + 1) % 10 == 0: \n",
    "                    _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                    model_aucs.append(auc) \n",
    "            aucs.append(model_aucs)\n",
    "        learning_rate_aucs.append(aucs)\n",
    "\n",
    "\n",
    "    learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "    auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "    auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "    cap_aucs.append([auc_mean, auc_variance])\n",
    "\n",
    "\n",
    "\n",
    "for c in range(len(cap_aucs)):\n",
    "    auc_mean = cap_aucs[c][0]\n",
    "    auc_variance = cap_aucs[c][1]\n",
    "    cap = loss_caps[c]\n",
    "    for i in range(len(learning_rates)): \n",
    "        row = [\"cosine_distance_capped_smote_with_smote_triplet_loss\", 2, nums, ratio, learning_rates[i],\n",
    "                auc_mean[i][0], auc_variance[i][0], \n",
    "                auc_mean[i][1], auc_variance[i][1],\n",
    "                auc_mean[i][2], auc_variance[i][2],\n",
    "                auc_mean[i][3], auc_variance[i][3], cap, norm, \"start_epoch=7\"]\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48c7bc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.001968830943107605, AUC: 0.6361665000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006622534990310669, AUC: 0.7385760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007262906134128571, AUC: 0.6065165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006622972488403321, AUC: 0.827749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010347468256950377, AUC: 0.515918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004892772287130356, AUC: 0.8685539999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008309755921363831, AUC: 0.8625809999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015312259197235107, AUC: 0.83128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016856086254119873, AUC: 0.402399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006069324612617493, AUC: 0.8425619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006350790858268738, AUC: 0.8384395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005941447913646698, AUC: 0.8411694999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008586450517177582, AUC: 0.620958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005511795878410339, AUC: 0.866982\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007755221128463746, AUC: 0.880608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004314573109149933, AUC: 0.894533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012711288928985596, AUC: 0.412528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006670472621917725, AUC: 0.7620390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006448141932487488, AUC: 0.8110480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006332345604896546, AUC: 0.8763159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024219154119491577, AUC: 0.5609035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004924880713224411, AUC: 0.8890125000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004381607621908188, AUC: 0.891078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008034327030181885, AUC: 0.864449\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012654619216918945, AUC: 0.595617\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000564054012298584, AUC: 0.841229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004930779486894607, AUC: 0.863186\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008372350931167603, AUC: 0.8407759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003977454304695129, AUC: 0.384281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005987293124198914, AUC: 0.85103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006257300674915314, AUC: 0.845569\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006932937204837799, AUC: 0.8195870000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007872370779514313, AUC: 0.350788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006057828664779663, AUC: 0.8263730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006112259328365326, AUC: 0.8283559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006349616050720215, AUC: 0.8235249999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006917646646499634, AUC: 0.44224250000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006449313163757324, AUC: 0.7887405000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006819410920143128, AUC: 0.7381384999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007286182641983032, AUC: 0.703646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032825849056243896, AUC: 0.5606095000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007223877012729645, AUC: 0.5009994999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007346769571304322, AUC: 0.4995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005822030901908874, AUC: 0.8145319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028570053577423094, AUC: 0.39856\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006283593475818635, AUC: 0.802624\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007519026100635529, AUC: 0.7897059999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008341757953166961, AUC: 0.814476\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007794376373291016, AUC: 0.535543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006478625535964966, AUC: 0.837015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008032414317131043, AUC: 0.8226374999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031238864660263063, AUC: 0.23527900000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032967061996459963, AUC: 0.42917900000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008274750709533691, AUC: 0.7754829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001166243553161621, AUC: 0.8163694999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001635572910308838, AUC: 0.7409675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003527355074882507, AUC: 0.575935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000727759301662445, AUC: 0.7811670000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008159331381320953, AUC: 0.813043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010636738538742066, AUC: 0.5288815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010099005103111267, AUC: 0.407148\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007055344879627228, AUC: 0.7681625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009500246644020081, AUC: 0.7561589999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009570467174053192, AUC: 0.8258270000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008435581028461457, AUC: 0.56668\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007716293036937713, AUC: 0.7302190000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007936590909957885, AUC: 0.8113389999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011514891982078552, AUC: 0.789098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004441925764083862, AUC: 0.552468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005616406500339508, AUC: 0.845865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008742137551307678, AUC: 0.757724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008098230063915253, AUC: 0.8271345000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005416463375091553, AUC: 0.322748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008798703551292419, AUC: 0.8163475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001042891800403595, AUC: 0.8374635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012445536851882935, AUC: 0.811449\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032596994638442994, AUC: 0.2988985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000649787813425064, AUC: 0.8389544999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007572808563709259, AUC: 0.8568375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00100655996799469, AUC: 0.8292650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004855311870574951, AUC: 0.492294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006765647530555725, AUC: 0.7185819999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000590332567691803, AUC: 0.840542\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006572516262531281, AUC: 0.812251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00361236035823822, AUC: 0.5527855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006038573980331421, AUC: 0.8567425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005837301313877106, AUC: 0.8361989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006171254515647889, AUC: 0.877715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017794038653373718, AUC: 0.4454830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005471282601356507, AUC: 0.8165669999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005562502145767212, AUC: 0.8388249999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005213703513145447, AUC: 0.8629009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019750398397445678, AUC: 0.43024299999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006715696156024933, AUC: 0.7405619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006113595366477966, AUC: 0.8426990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006543617844581604, AUC: 0.816725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010875521302223207, AUC: 0.39853700000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006622656583786011, AUC: 0.7497755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006511387228965759, AUC: 0.783976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005958412289619446, AUC: 0.860274\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00330962872505188, AUC: 0.498438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006847029626369476, AUC: 0.6331249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006394481360912323, AUC: 0.8178559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006548094153404236, AUC: 0.7951695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012689270973205566, AUC: 0.37939700000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006416051685810089, AUC: 0.7959455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006170719861984253, AUC: 0.8120290000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006878231763839722, AUC: 0.691126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010466970801353455, AUC: 0.6155820000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006481670141220093, AUC: 0.7937740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006629240810871125, AUC: 0.7366355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006390831172466278, AUC: 0.843581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011142138838768005, AUC: 0.681295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006397662162780761, AUC: 0.8075905000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006238667070865631, AUC: 0.819248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006083660423755646, AUC: 0.8457475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006451814651489258, AUC: 0.2952255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000608214408159256, AUC: 0.8213570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006442341208457947, AUC: 0.787758\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006486717462539673, AUC: 0.7769544999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013095623016357421, AUC: 0.6491265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005345839560031891, AUC: 0.834114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005302568376064301, AUC: 0.838179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006348582804203034, AUC: 0.8116590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000747450202703476, AUC: 0.5863879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006223531663417816, AUC: 0.8273839999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000611771285533905, AUC: 0.8471180000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006181038916110992, AUC: 0.831364\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.002385180950164795, AUC: 0.4585135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006397717595100403, AUC: 0.793819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006296209692955017, AUC: 0.8043739999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006140455603599549, AUC: 0.8322370000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009520593583583832, AUC: 0.555158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000550226092338562, AUC: 0.825901\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005467916131019592, AUC: 0.83493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005628498792648315, AUC: 0.8450339999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001990069031715393, AUC: 0.598636\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005644693374633789, AUC: 0.8142369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005276755094528198, AUC: 0.826524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006087591052055359, AUC: 0.84587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012775813341140748, AUC: 0.5571980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000588628202676773, AUC: 0.819166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006013973355293273, AUC: 0.831462\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005729582905769348, AUC: 0.8447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011208214163780212, AUC: 0.590324\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000553610622882843, AUC: 0.8147249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005643303692340851, AUC: 0.841808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005828954577445984, AUC: 0.8515640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010201774537563324, AUC: 0.6473549999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005617073774337769, AUC: 0.822189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000557791531085968, AUC: 0.8346199999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005288576781749725, AUC: 0.832971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014852787256240845, AUC: 0.5493699999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005150356590747833, AUC: 0.8521099999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005023057162761688, AUC: 0.8556570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005357258021831512, AUC: 0.8561350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003127989411354065, AUC: 0.508491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005668491125106811, AUC: 0.843055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005651587545871734, AUC: 0.834116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005287276804447174, AUC: 0.8421749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008746980667114258, AUC: 0.335598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006762397587299347, AUC: 0.8154760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006881693005561829, AUC: 0.85953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005904370546340942, AUC: 0.840216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004081874847412109, AUC: 0.405762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005362692475318908, AUC: 0.8581340000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007239201664924621, AUC: 0.873836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007360002100467682, AUC: 0.8821350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004236681699752808, AUC: 0.569302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006161434948444367, AUC: 0.8404489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005993082225322723, AUC: 0.8625345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006588205099105835, AUC: 0.8483934999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011720848679542541, AUC: 0.46001500000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006565907299518585, AUC: 0.7940929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006892484724521637, AUC: 0.7523380000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007209068238735199, AUC: 0.7341789999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015378248691558837, AUC: 0.6067359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006008292138576508, AUC: 0.835787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005758805274963379, AUC: 0.869199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000750200480222702, AUC: 0.8741920000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011264556050300599, AUC: 0.52888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000603682667016983, AUC: 0.8280890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000606196790933609, AUC: 0.8212549999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005979073643684387, AUC: 0.8354800000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003636013388633728, AUC: 0.542108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000590341717004776, AUC: 0.858607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007737080752849579, AUC: 0.8532850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042913587391376495, AUC: 0.8886359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001453067123889923, AUC: 0.374227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006415787935256959, AUC: 0.788293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005861338973045349, AUC: 0.8549469999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006363704800605774, AUC: 0.8430495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008063334822654725, AUC: 0.508506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000643252968788147, AUC: 0.8069750000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000674587219953537, AUC: 0.7919459999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006724282801151276, AUC: 0.8291629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024830992221832274, AUC: 0.6664135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006442120373249054, AUC: 0.8003715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00063533815741539, AUC: 0.8187724999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006592956185340882, AUC: 0.8363200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01082353925704956, AUC: 0.403199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005638903379440308, AUC: 0.8234739999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007711428701877594, AUC: 0.8151535000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022679157257080077, AUC: 0.554256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020114036202430723, AUC: 0.5904119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006723427772521973, AUC: 0.8011245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000661290168762207, AUC: 0.8561759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008998041450977326, AUC: 0.8118310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014949373006820678, AUC: 0.335657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000635597139596939, AUC: 0.8447060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007998767793178558, AUC: 0.8009229999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009754884541034698, AUC: 0.7765585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019332606792449951, AUC: 0.544379\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007243875861167908, AUC: 0.796511\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012052393555641175, AUC: 0.794942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001474994957447052, AUC: 0.75697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010986952185630798, AUC: 0.45257600000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005718754827976226, AUC: 0.8400255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007738214433193207, AUC: 0.800564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008564578294754028, AUC: 0.833237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001723124325275421, AUC: 0.31220499999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008241057097911835, AUC: 0.631775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009601570069789887, AUC: 0.7599395000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007903130054473877, AUC: 0.8251390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003097874879837036, AUC: 0.433907\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005588302910327911, AUC: 0.8342229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006132580637931824, AUC: 0.81554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009641593396663666, AUC: 0.7492730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022863947153091433, AUC: 0.39137900000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006833572983741761, AUC: 0.815432\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008296373188495635, AUC: 0.825833\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011049230694770813, AUC: 0.787827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023146138191223143, AUC: 0.612484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006527947783470154, AUC: 0.8322655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006701681315898895, AUC: 0.851532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001002296805381775, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015248315930366516, AUC: 0.5597829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006903198659420014, AUC: 0.788394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006385721564292908, AUC: 0.8589319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009103609323501587, AUC: 0.8124499999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012130472660064698, AUC: 0.622987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006303849518299102, AUC: 0.824385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000830092191696167, AUC: 0.826541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006519467234611512, AUC: 0.8677790000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019025101065635681, AUC: 0.57595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007926658391952515, AUC: 0.8411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005043565928936005, AUC: 0.8685069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006516150236129761, AUC: 0.891554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028162660598754882, AUC: 0.31895700000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006651666462421417, AUC: 0.7765310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006249960660934448, AUC: 0.8300205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006194896101951599, AUC: 0.83604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007696027040481567, AUC: 0.664795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006456875205039978, AUC: 0.8177749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006051250696182251, AUC: 0.8531465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000642511785030365, AUC: 0.816533\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007216182947158814, AUC: 0.628137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005674745738506317, AUC: 0.8468640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005497297644615173, AUC: 0.856886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008376042544841766, AUC: 0.8382499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030689326524734497, AUC: 0.47973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000624789983034134, AUC: 0.8018845000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006059180498123169, AUC: 0.8152074999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006095174252986908, AUC: 0.819117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026719954013824463, AUC: 0.492266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004913255572319031, AUC: 0.8649659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044897058606147765, AUC: 0.878911\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007488345801830292, AUC: 0.876372\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029769840240478516, AUC: 0.41818900000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005388579368591309, AUC: 0.8791850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004893890768289566, AUC: 0.8862850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006117656230926514, AUC: 0.8823500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002351943850517273, AUC: 0.375954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005192103087902069, AUC: 0.853671\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005405294895172119, AUC: 0.869862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007476703822612762, AUC: 0.8603215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007459208071231842, AUC: 0.6882010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006417210400104522, AUC: 0.806796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006609659790992737, AUC: 0.7884420000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006656427085399627, AUC: 0.798219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00351450252532959, AUC: 0.5154385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006942864060401916, AUC: 0.4964690000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694214791059494, AUC: 0.4970065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943196952342987, AUC: 0.5019864999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027675822973251343, AUC: 0.4842585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006449364721775055, AUC: 0.7723605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006398048400878906, AUC: 0.7484410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006167995035648346, AUC: 0.821967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018405525088310243, AUC: 0.5183705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000667411357164383, AUC: 0.7388410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006669130623340606, AUC: 0.7322875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006586838066577911, AUC: 0.760933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013552693724632264, AUC: 0.476742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006428462266921997, AUC: 0.7657105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006275997161865234, AUC: 0.7979065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006483981609344483, AUC: 0.7750539999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001882489562034607, AUC: 0.5352560000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005304917693138122, AUC: 0.832057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005477966964244843, AUC: 0.8353269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005121610760688782, AUC: 0.838061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008855484008789062, AUC: 0.46778000000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006371288895606995, AUC: 0.786551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006254199147224426, AUC: 0.8001795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000610200971364975, AUC: 0.815499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0089959397315979, AUC: 0.4370770000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006395745277404786, AUC: 0.8024160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006394891738891602, AUC: 0.8162859999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006283487975597381, AUC: 0.8342310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002071466326713562, AUC: 0.44712399999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005432572364807128, AUC: 0.8148315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005822827816009522, AUC: 0.8305629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007516974508762359, AUC: 0.834876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011767864227294922, AUC: 0.5665385000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000584673672914505, AUC: 0.8176019999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005760526657104492, AUC: 0.8395379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000601271003484726, AUC: 0.85162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013936387300491333, AUC: 0.454195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005467769801616669, AUC: 0.8246779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000545716792345047, AUC: 0.829861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005304447114467621, AUC: 0.849877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011210563182830811, AUC: 0.35839299999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006568819284439087, AUC: 0.7265710000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000660137265920639, AUC: 0.721667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006811003983020783, AUC: 0.7348985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016253876090049743, AUC: 0.619723\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006584356427192688, AUC: 0.7780874999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006527307033538819, AUC: 0.813546\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005357475876808166, AUC: 0.8611189999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018487141728401183, AUC: 0.6973935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000670193761587143, AUC: 0.7546675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006709170639514924, AUC: 0.7893754999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006685034334659577, AUC: 0.8260415000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056646733283996584, AUC: 0.2913565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006829882562160492, AUC: 0.6904739999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006611025631427764, AUC: 0.7999915000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007124123275279999, AUC: 0.7661160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012651268005371094, AUC: 0.5401555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006462675333023071, AUC: 0.787847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005802886784076691, AUC: 0.8520660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000652204155921936, AUC: 0.842218\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010454835891723633, AUC: 0.641565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005985937714576721, AUC: 0.8403109999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005885334610939026, AUC: 0.8443469999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000603532612323761, AUC: 0.8402160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001954038977622986, AUC: 0.3197895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006895411014556885, AUC: 0.6215955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006391516625881195, AUC: 0.82538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006115111112594604, AUC: 0.8453449999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036395139694213865, AUC: 0.5027815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006071389615535736, AUC: 0.843925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006772753298282623, AUC: 0.7845360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006886701881885529, AUC: 0.8112610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005201202392578125, AUC: 0.5565695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006266870498657227, AUC: 0.8182830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000649962455034256, AUC: 0.786\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007126467525959014, AUC: 0.715916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024096740484237673, AUC: 0.50988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006624845862388611, AUC: 0.7951140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006250777542591095, AUC: 0.856309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006969436407089233, AUC: 0.8251649999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025441122055053712, AUC: 0.389482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005790171027183533, AUC: 0.8463374999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007519265711307526, AUC: 0.844153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009059397876262664, AUC: 0.820835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001046354651451111, AUC: 0.371633\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006258156597614288, AUC: 0.8374875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007796871662139892, AUC: 0.8298154999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007553868293762207, AUC: 0.8437840000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014685338735580444, AUC: 0.412669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000635105550289154, AUC: 0.8347010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006683356463909149, AUC: 0.840025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007703378796577454, AUC: 0.8510050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002988044857978821, AUC: 0.670228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005888822674751282, AUC: 0.8587345000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007635528445243835, AUC: 0.8263800000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008673565685749054, AUC: 0.8423379999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002603454947471619, AUC: 0.3341105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929450631141663, AUC: 0.5014989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929190456867218, AUC: 0.502497\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929053068161011, AUC: 0.49801049999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003080069303512573, AUC: 0.606691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005935411751270295, AUC: 0.855951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007507493793964386, AUC: 0.8289455\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0007637673318386077, AUC: 0.868422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004009966731071472, AUC: 0.35853350000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006316071748733521, AUC: 0.8411200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006807064712047577, AUC: 0.8418865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000700340211391449, AUC: 0.852107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005758796453475952, AUC: 0.564535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007850680351257324, AUC: 0.7025580000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007985642552375793, AUC: 0.8287899999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00093643718957901, AUC: 0.788198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022677001953125, AUC: 0.716523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005763637721538544, AUC: 0.836851\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009074821174144744, AUC: 0.783124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009487994909286499, AUC: 0.8463384999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014523221850395202, AUC: 0.667135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005363000035285949, AUC: 0.8213550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008451749682426453, AUC: 0.849053\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009694116413593292, AUC: 0.6979110000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036632038354873658, AUC: 0.5036725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000664577692747116, AUC: 0.708959\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006589471101760865, AUC: 0.730665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005824224352836609, AUC: 0.8607319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009999825060367585, AUC: 0.31404550000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007032961547374726, AUC: 0.866438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006734871566295624, AUC: 0.8767369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007967380285263062, AUC: 0.872614\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005410242557525635, AUC: 0.425329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006584107875823974, AUC: 0.7429520000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006317349672317505, AUC: 0.796132\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000621816873550415, AUC: 0.82384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007853160202503204, AUC: 0.5604895000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006578637063503265, AUC: 0.757193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006564335227012635, AUC: 0.776485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006270978450775147, AUC: 0.8109425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001019254893064499, AUC: 0.6503884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006289424896240235, AUC: 0.8217990000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004917082935571671, AUC: 0.862337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007234077751636505, AUC: 0.868086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011077091693878175, AUC: 0.4288120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006395892798900604, AUC: 0.7840549999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006533448100090027, AUC: 0.775678\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005902350544929505, AUC: 0.8532925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008800406455993652, AUC: 0.5852660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000638882964849472, AUC: 0.8199789999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006258010864257813, AUC: 0.8223480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005235700309276581, AUC: 0.877714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023395947217941283, AUC: 0.46925300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005890800654888153, AUC: 0.863647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006089562773704529, AUC: 0.8325840000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007964714765548706, AUC: 0.860861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015488680005073547, AUC: 0.409273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006574678421020508, AUC: 0.7997440000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006310368478298187, AUC: 0.8441635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006257493495941162, AUC: 0.844139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005870892763137818, AUC: 0.455775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006840378940105438, AUC: 0.608349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006483845710754394, AUC: 0.768345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006410985291004181, AUC: 0.7941370000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005682688951492309, AUC: 0.3891835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006200923323631287, AUC: 0.7853619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006778941750526428, AUC: 0.7965090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000550239235162735, AUC: 0.8217030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014341408610343933, AUC: 0.5860409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006539286673069001, AUC: 0.8017855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006460084319114685, AUC: 0.8103250000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006513814330101013, AUC: 0.7927709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005093271732330322, AUC: 0.5416025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006569181084632873, AUC: 0.7883885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006410616934299469, AUC: 0.8322245000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006499916315078735, AUC: 0.8213225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015200076103210449, AUC: 0.579987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005718746781349182, AUC: 0.8123429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005148334354162217, AUC: 0.835817\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005897408425807953, AUC: 0.8456609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001048965334892273, AUC: 0.329143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005442911088466645, AUC: 0.844007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005332401096820831, AUC: 0.852751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005732377767562867, AUC: 0.8543489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007575980722904206, AUC: 0.533112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006313945651054382, AUC: 0.8100995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006245567202568054, AUC: 0.8112389999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006200953722000122, AUC: 0.8168945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008597393631935119, AUC: 0.5988955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005619345605373383, AUC: 0.804696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005395124852657318, AUC: 0.81881\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007834257483482361, AUC: 0.8314659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009793367385864258, AUC: 0.6025250000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006316578090190888, AUC: 0.8293835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006370285749435425, AUC: 0.8403579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006275635063648224, AUC: 0.8501075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010473459362983703, AUC: 0.550819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006189532577991486, AUC: 0.8047570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007311674654483795, AUC: 0.790097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006032804846763611, AUC: 0.8284590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009697910785675048, AUC: 0.40394299999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006592669785022736, AUC: 0.7874935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006509880721569061, AUC: 0.7882585000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006596566140651702, AUC: 0.744482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cosine distance + capped loss using whole class average tensor\n",
    "momentum=0\n",
    "learning_rates = [1e-3, 5e-3, 5e-4, 1e-4]\n",
    "\n",
    "\n",
    "cap_aucs=[]\n",
    "\n",
    "    \n",
    "loss_fn_args = {}\n",
    "loss_caps = [0.75, 1, 5]\n",
    "loss_fn_args['distance'] = 'cosine'\n",
    "\n",
    "start_epoch = 2\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for loss_cap in loss_caps:\n",
    "    \n",
    "    learning_rate_aucs = []\n",
    "    \n",
    "    for learning_rate in learning_rates:\n",
    "        aucs = []\n",
    "        for i in range(10):\n",
    "            model_aucs = []\n",
    "            network = models.ConvNetWithEmbeddingsEarly(NUM_CLASSES_REDUCED)\n",
    "            optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network, embeddings=True) \n",
    "            model_aucs.append(auc)\n",
    "            for epoch in range(start_epoch):\n",
    "                loss_fn_args['loss_cap'] = None\n",
    "                loss_fn_args['avg_tensors'] = None\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, network, optimizer, verbose=False,loss_fn=loss_fns.CappedBCELossAvgDistance,loss_fn_args=loss_fn_args)\n",
    "            for epoch in range(start_epoch, n_epochs + 1):\n",
    "                loss_fn_args['loss_cap'] = loss_cap\n",
    "                loss_fn_args['print_loss']= False\n",
    "                loss_fn_args['avg_tensors'] = []\n",
    "                for k in range(NUM_CLASSES_REDUCED):\n",
    "                    _, avg_tensor = network(avg_tensors_list[k])\n",
    "                    loss_fn_args['avg_tensors'].append(avg_tensor)\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, network, optimizer, verbose=False, loss_fn=loss_fns.CappedBCELossAvgDistance, loss_fn_args=loss_fn_args)\n",
    "                if (epoch + 1) % 10 == 0: \n",
    "                    _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network, embeddings=True)\n",
    "                    model_aucs.append(auc)\n",
    "            aucs.append(model_aucs)\n",
    "        learning_rate_aucs.append(aucs)\n",
    "\n",
    "    learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "    auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "    auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "        \n",
    "    cap_aucs.append([auc_mean, auc_variance])\n",
    "\n",
    "for c in range(len(cap_aucs)):\n",
    "    auc_mean = cap_aucs[c][0]\n",
    "    auc_variance = cap_aucs[c][1]\n",
    "    cap = loss_caps[c]\n",
    "    for i in range(len(learning_rates)): \n",
    "        row = [\"cosine_distance_capped_smote_avg\", 2, nums, ratio, learning_rates[i],\n",
    "                auc_mean[i][0], auc_variance[i][0], \n",
    "                auc_mean[i][1], auc_variance[i][1],\n",
    "                auc_mean[i][2], auc_variance[i][2],\n",
    "                auc_mean[i][3], auc_variance[i][3], cap, norm, None]\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c220d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ff32364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.000691878616809845, AUC: 0.578823\n",
      "\n",
      "Train loss: 2.1152768104699007\n",
      "Train loss: 1.362831683675195\n",
      "Train loss: 1.7595135125384969\n",
      "Train loss: 1.1299688204838212\n",
      "Train loss: 0.6808489777479961\n",
      "Train loss: 0.6694605194838943\n",
      "Train loss: 1.0802323112062588\n",
      "Train loss: 0.6371187286771787\n",
      "Train loss: 0.5292761120826576\n",
      "Train loss: 0.6434453463858101\n",
      "\n",
      "Test set: Avg. loss: 0.0006957791149616242, AUC: 0.3901265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002493227958679199, AUC: 0.686156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002454917073249817, AUC: 0.7115910000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940029859542847, AUC: 0.575422\n",
      "\n",
      "Train loss: 2.1154672890711743\n",
      "Train loss: 2.5143205014763366\n",
      "Train loss: 1.750417664172543\n",
      "Train loss: 0.8689699283071385\n",
      "Train loss: 0.8691085994623269\n",
      "Train loss: 0.5269735884514584\n",
      "Train loss: 0.8888260748735659\n",
      "Train loss: 0.8102662460819171\n",
      "Train loss: 0.4519774074767046\n",
      "Train loss: 0.6589806945460617\n",
      "\n",
      "Test set: Avg. loss: 0.0006968896687030793, AUC: 0.42876899999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00260136079788208, AUC: 0.674204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025564324855804443, AUC: 0.697966\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006938588917255402, AUC: 0.46182699999999993\n",
      "\n",
      "Train loss: 1.3086567331271566\n",
      "Train loss: 1.053911695434789\n",
      "Train loss: 0.9139218698641297\n",
      "Train loss: 1.2159754216291343\n",
      "Train loss: 0.9261100633888487\n",
      "Train loss: 0.8313204418322083\n",
      "Train loss: 0.7631090738970763\n",
      "Train loss: 0.5669812829631149\n",
      "Train loss: 0.44179061377883716\n",
      "Train loss: 0.4565344908434874\n",
      "\n",
      "Test set: Avg. loss: 0.000695683479309082, AUC: 0.372626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002572589039802551, AUC: 0.6752119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002445685029029846, AUC: 0.7053289999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939082741737366, AUC: 0.534087\n",
      "\n",
      "Train loss: 1.805793555299188\n",
      "Train loss: 1.1221733021128708\n",
      "Train loss: 1.1074098724468497\n",
      "Train loss: 0.9763877224770321\n",
      "Train loss: 1.0600596605592472\n",
      "Train loss: 0.8003217661456697\n",
      "Train loss: 0.4612029392248506\n",
      "Train loss: 0.5110203638957564\n",
      "Train loss: 0.45774221382323343\n",
      "Train loss: 0.48238239128878163\n",
      "\n",
      "Test set: Avg. loss: 0.0006925244927406311, AUC: 0.614711\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026676474809646604, AUC: 0.660921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002536210775375366, AUC: 0.69217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006821991801261902, AUC: 0.7783985\n",
      "\n",
      "Train loss: 0.8941235401827818\n",
      "Train loss: 1.0692474006847212\n",
      "Train loss: 0.7602964187883268\n",
      "Train loss: 0.34397010059113714\n",
      "Train loss: 0.6341176165896616\n",
      "Train loss: 0.3126854775058236\n",
      "Train loss: 0.11348872275868799\n",
      "Train loss: 0.23902867743923406\n",
      "Train loss: 0.2692149285298244\n",
      "Train loss: 0.23963973210875394\n",
      "\n",
      "Test set: Avg. loss: 0.0006805727481842041, AUC: 0.7907215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025367852449417116, AUC: 0.657555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025050100088119505, AUC: 0.6867540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006966664493083954, AUC: 0.5272725\n",
      "\n",
      "Train loss: 2.2981165522223064\n",
      "Train loss: 1.6390714751687019\n",
      "Train loss: 0.8116001175467376\n",
      "Train loss: 0.970694779970084\n",
      "Train loss: 0.7223582746116979\n",
      "Train loss: 0.3230966534584191\n",
      "Train loss: 0.519216165041468\n",
      "Train loss: 0.3779412792746428\n",
      "Train loss: 0.41365445381516863\n",
      "Train loss: 0.6110851540686978\n",
      "\n",
      "Test set: Avg. loss: 0.0007031741142272949, AUC: 0.330863\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025204352140426635, AUC: 0.681396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002357369303703308, AUC: 0.712228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006973939538002014, AUC: 0.41183650000000005\n",
      "\n",
      "Train loss: 1.464638371376475\n",
      "Train loss: 1.5085126799382982\n",
      "Train loss: 1.3982740158488036\n",
      "Train loss: 0.8992868942819583\n",
      "Train loss: 0.8791296637741624\n",
      "Train loss: 0.6991475919249711\n",
      "Train loss: 0.6376801588732726\n",
      "Train loss: 0.578121819313924\n",
      "Train loss: 0.4935236113845922\n",
      "Train loss: 0.476264823773864\n",
      "\n",
      "Test set: Avg. loss: 0.0006944063007831573, AUC: 0.496939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002613887310028076, AUC: 0.660552\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002471911907196045, AUC: 0.681807\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006954326033592225, AUC: 0.420621\n",
      "\n",
      "Train loss: 1.0217291166068643\n",
      "Train loss: 0.8398310177645106\n",
      "Train loss: 0.8124669080327271\n",
      "Train loss: 0.5240226228525684\n",
      "Train loss: 1.0120125037090035\n",
      "Train loss: 0.4674160431145103\n",
      "Train loss: 0.608467009416811\n",
      "Train loss: 0.6878768175270906\n",
      "Train loss: 0.5796928534841841\n",
      "Train loss: 0.4338673182353852\n",
      "\n",
      "Test set: Avg. loss: 0.0006963953971862792, AUC: 0.38944949999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002734196066856384, AUC: 0.638499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002614461541175842, AUC: 0.671478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006966802477836609, AUC: 0.480217\n",
      "\n",
      "Train loss: 1.0274633480485078\n",
      "Train loss: 0.6036032563561846\n",
      "Train loss: 0.7498052097429895\n",
      "Train loss: 0.5793269155131784\n",
      "Train loss: 0.5942411908678188\n",
      "Train loss: 0.4980122606465771\n",
      "Train loss: 0.5087973619722257\n",
      "Train loss: 0.41626223864828704\n",
      "Train loss: 0.17880641920551374\n",
      "Train loss: 0.3595501222428243\n",
      "\n",
      "Test set: Avg. loss: 0.0006962110102176666, AUC: 0.4917155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002797717094421387, AUC: 0.632381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025973132848739625, AUC: 0.665613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943588256835937, AUC: 0.5187864999999999\n",
      "\n",
      "Train loss: 1.7967880998447443\n",
      "Train loss: 1.3171652039145207\n",
      "Train loss: 1.0874446478618938\n",
      "Train loss: 1.0912379922380873\n",
      "Train loss: 1.0652349769689475\n",
      "Train loss: 1.1692813915811526\n",
      "Train loss: 0.701363252986009\n",
      "Train loss: 0.7557018251176093\n",
      "Train loss: 0.7205512356606258\n",
      "Train loss: 0.5625066051057949\n",
      "\n",
      "Test set: Avg. loss: 0.000694442868232727, AUC: 0.5134245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002544957876205444, AUC: 0.6593260000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024343621730804443, AUC: 0.684665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006935329437255859, AUC: 0.488192\n",
      "\n",
      "Train loss: 1.191825773685601\n",
      "Train loss: 1.1822920464406348\n",
      "Train loss: 1.2961162025002158\n",
      "Train loss: 1.050709085100016\n",
      "Train loss: 1.0384289842502328\n",
      "Train loss: 0.6984599589542219\n",
      "Train loss: 1.0993291803985645\n",
      "Train loss: 0.8329581606919598\n",
      "Train loss: 0.8215141448245686\n",
      "Train loss: 0.8366762543939481\n",
      "\n",
      "Test set: Avg. loss: 0.0006941790282726288, AUC: 0.458696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024168466329574584, AUC: 0.712275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002401503086090088, AUC: 0.739163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006915232837200164, AUC: 0.581788\n",
      "\n",
      "Train loss: 3.853494891315509\n",
      "Train loss: 3.3750762514248014\n",
      "Train loss: 4.077173090284797\n",
      "Train loss: 3.640851204562339\n",
      "Train loss: 3.32041907728098\n",
      "Train loss: 3.205108270144007\n",
      "Train loss: 3.2279745002461087\n",
      "Train loss: 2.235763757851473\n",
      "Train loss: 1.8435223375915721\n",
      "Train loss: 2.0635985246129858\n",
      "\n",
      "Test set: Avg. loss: 0.0006900885105133056, AUC: 0.6546744999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023624882698059083, AUC: 0.703676\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023180216550827025, AUC: 0.7280245000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006952035129070282, AUC: 0.445865\n",
      "\n",
      "Train loss: 2.0463783342367523\n",
      "Train loss: 2.6233426848794243\n",
      "Train loss: 1.95483059981826\n",
      "Train loss: 2.167438362054764\n",
      "Train loss: 1.6839472655278103\n",
      "Train loss: 1.431237791374231\n",
      "Train loss: 1.143097588211108\n",
      "Train loss: 1.2448801193267676\n",
      "Train loss: 1.2954739070242378\n",
      "Train loss: 1.0881957366208361\n",
      "\n",
      "Test set: Avg. loss: 0.0006943733394145966, AUC: 0.49528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002495369553565979, AUC: 0.695423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002337960481643677, AUC: 0.728788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007060095965862274, AUC: 0.31137950000000003\n",
      "\n",
      "Train loss: 3.239952160674296\n",
      "Train loss: 1.9776098542152696\n",
      "Train loss: 2.189260889010824\n",
      "Train loss: 1.8642128478189943\n",
      "Train loss: 1.860371170529894\n",
      "Train loss: 1.4657617348014929\n",
      "Train loss: 1.4360706809979336\n",
      "Train loss: 1.6815557829134025\n",
      "Train loss: 1.7000290417367485\n",
      "Train loss: 1.1980733985354186\n",
      "\n",
      "Test set: Avg. loss: 0.0007074339985847473, AUC: 0.29834700000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002422186851501465, AUC: 0.710657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002242861032485962, AUC: 0.7280890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006903893947601318, AUC: 0.6115234999999999\n",
      "\n",
      "Train loss: 2.4188849770339433\n",
      "Train loss: 1.747911316194352\n",
      "Train loss: 1.5146126602865329\n",
      "Train loss: 1.3713765679651004\n",
      "Train loss: 1.527752252521029\n",
      "Train loss: 1.9577823695103833\n",
      "Train loss: 1.223649930422473\n",
      "Train loss: 1.8487458225268467\n",
      "Train loss: 1.1588402204452806\n",
      "Train loss: 1.1003730270513303\n",
      "\n",
      "Test set: Avg. loss: 0.0006906653046607972, AUC: 0.5967355\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0024006248712539675, AUC: 0.706141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002390863060951233, AUC: 0.71977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006933940351009369, AUC: 0.5733465\n",
      "\n",
      "Train loss: 1.2468103872742622\n",
      "Train loss: 0.9911186125627749\n",
      "Train loss: 0.708361944954866\n",
      "Train loss: 0.9297731590878432\n",
      "Train loss: 0.7769595031525679\n",
      "Train loss: 0.9345260402958864\n",
      "Train loss: 0.561731690434134\n",
      "Train loss: 0.7298914440877878\n",
      "Train loss: 0.6808384114010319\n",
      "Train loss: 0.6182690114732001\n",
      "\n",
      "Test set: Avg. loss: 0.0006925439834594726, AUC: 0.601132\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025254011154174803, AUC: 0.685949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00238752281665802, AUC: 0.7134469999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006937408149242402, AUC: 0.49135149999999994\n",
      "\n",
      "Train loss: 3.282004968755564\n",
      "Train loss: 2.7901779394240895\n",
      "Train loss: 3.0127792760824703\n",
      "Train loss: 2.410826233162242\n",
      "Train loss: 2.25373038137035\n",
      "Train loss: 2.4250421983421226\n",
      "Train loss: 2.363741488593399\n",
      "Train loss: 2.4345395697909558\n",
      "Train loss: 1.8626488576269453\n",
      "Train loss: 1.8938626381242352\n",
      "\n",
      "Test set: Avg. loss: 0.0006937076449394226, AUC: 0.49137549999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002416808843612671, AUC: 0.719784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002314025044441223, AUC: 0.7474540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006917263865470886, AUC: 0.5954605\n",
      "\n",
      "Train loss: 1.2443594738935968\n",
      "Train loss: 1.3435113251588906\n",
      "Train loss: 1.1094209582183012\n",
      "Train loss: 0.9077699776667698\n",
      "Train loss: 0.876659095287323\n",
      "Train loss: 1.153739529810134\n",
      "Train loss: 0.8709135598437802\n",
      "Train loss: 1.2462858698170656\n",
      "Train loss: 0.7002781914297942\n",
      "Train loss: 0.9109839842577648\n",
      "\n",
      "Test set: Avg. loss: 0.0006918440163135529, AUC: 0.5948365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002479338884353638, AUC: 0.6904570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022942545413970946, AUC: 0.731241\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928797960281372, AUC: 0.5188554999999999\n",
      "\n",
      "Train loss: 1.990530674624595\n",
      "Train loss: 1.6383422347390728\n",
      "Train loss: 1.6454898764373391\n",
      "Train loss: 1.816115777963286\n",
      "Train loss: 1.2267146505367983\n",
      "Train loss: 1.2036739120817488\n",
      "Train loss: 1.341198388937932\n",
      "Train loss: 0.780379173861947\n",
      "Train loss: 1.178998228850638\n",
      "Train loss: 0.750323322168581\n",
      "\n",
      "Test set: Avg. loss: 0.0006914047002792358, AUC: 0.5833119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023868409395217897, AUC: 0.694343\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002241131782531738, AUC: 0.7179515000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006971978843212128, AUC: 0.35560250000000004\n",
      "\n",
      "Train loss: 1.8719606057853455\n",
      "Train loss: 2.5981576063071086\n",
      "Train loss: 1.0115930092562535\n",
      "Train loss: 1.5996206854559054\n",
      "Train loss: 1.7207117923505746\n",
      "Train loss: 1.238445452444113\n",
      "Train loss: 1.7015509480124067\n",
      "Train loss: 1.3273567416865355\n",
      "Train loss: 1.3279752985687012\n",
      "Train loss: 1.1292838549158375\n",
      "\n",
      "Test set: Avg. loss: 0.0006970124244689941, AUC: 0.35826600000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023875041007995605, AUC: 0.711781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002342165946960449, AUC: 0.7317969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006887258887290955, AUC: 0.6912874999999999\n",
      "\n",
      "Train loss: 1.777325954406884\n",
      "Train loss: 1.3174316412324358\n",
      "Train loss: 1.2934034899541527\n",
      "Train loss: 0.7895839259882641\n",
      "Train loss: 0.6003739101112269\n",
      "Train loss: 0.6249035703148812\n",
      "Train loss: 0.6289485749925018\n",
      "Train loss: 0.5207291837710484\n",
      "Train loss: 0.38473462716789003\n",
      "Train loss: 0.3589175632045527\n",
      "\n",
      "Test set: Avg. loss: 0.0006798877120018005, AUC: 0.8147805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017122249603271484, AUC: 0.57369\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025490336418151857, AUC: 0.611746\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007007046639919281, AUC: 0.3225345\n",
      "\n",
      "Train loss: 0.9967906118198565\n",
      "Train loss: 0.8514343705146935\n",
      "Train loss: 0.6111474329498923\n",
      "Train loss: 0.49314411506531347\n",
      "Train loss: 0.669102251909341\n",
      "Train loss: 0.29093501863965565\n",
      "Train loss: 0.39643260817618886\n",
      "Train loss: 0.44470656829275146\n",
      "Train loss: 0.16965017462991605\n",
      "Train loss: 0.21718693804589045\n",
      "\n",
      "Test set: Avg. loss: 0.000702805608510971, AUC: 0.24173000000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002258265256881714, AUC: 0.5048865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027150601148605348, AUC: 0.584609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006926046311855317, AUC: 0.5480970000000001\n",
      "\n",
      "Train loss: 0.9531075517842724\n",
      "Train loss: 0.7405806859587408\n",
      "Train loss: 0.9088346688610733\n",
      "Train loss: 0.5837986271852141\n",
      "Train loss: 0.6054486632347107\n",
      "Train loss: 0.36005976359555675\n",
      "Train loss: 0.43408998524307446\n",
      "Train loss: 0.38540821584166995\n",
      "Train loss: 0.30172061274765405\n",
      "Train loss: 0.25545988113257534\n",
      "\n",
      "Test set: Avg. loss: 0.0006923638880252838, AUC: 0.566743\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00197743558883667, AUC: 0.509293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002579222798347473, AUC: 0.593496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006924857497215271, AUC: 0.55542\n",
      "\n",
      "Train loss: 1.111978521772251\n",
      "Train loss: 0.9493973243768048\n",
      "Train loss: 0.646518815474905\n",
      "Train loss: 0.5131569740119254\n",
      "Train loss: 0.44988532506736223\n",
      "Train loss: 0.4103635272402672\n",
      "Train loss: 0.336121331354615\n",
      "Train loss: 0.35096370300669577\n",
      "Train loss: 0.3520638673168838\n",
      "Train loss: 0.4217581638864651\n",
      "\n",
      "Test set: Avg. loss: 0.0006926847994327545, AUC: 0.5437405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001969771683216095, AUC: 0.5950464999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002501305341720581, AUC: 0.6390355000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939783990383148, AUC: 0.530088\n",
      "\n",
      "Train loss: 1.725970681685551\n",
      "Train loss: 1.6612922621380752\n",
      "Train loss: 0.9704418543038095\n",
      "Train loss: 0.6682990960254791\n",
      "Train loss: 0.37909160222217536\n",
      "Train loss: 0.35923838539487996\n",
      "Train loss: 0.44347210029128253\n",
      "Train loss: 0.348650244770536\n",
      "Train loss: 0.39246908532586067\n",
      "Train loss: 0.12690830914078244\n",
      "\n",
      "Test set: Avg. loss: 0.0006916037499904632, AUC: 0.6356710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002303961157798767, AUC: 0.5015000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026737687587738037, AUC: 0.580739\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006921427547931671, AUC: 0.544127\n",
      "\n",
      "Train loss: 1.1276813506320784\n",
      "Train loss: 0.6507816903150765\n",
      "Train loss: 0.6756972727502227\n",
      "Train loss: 0.4939884030894869\n",
      "Train loss: 0.3478922714852983\n",
      "Train loss: 0.30488453701043583\n",
      "Train loss: 0.395702701085692\n",
      "Train loss: 0.3206455035574117\n",
      "Train loss: 0.3694200625844822\n",
      "Train loss: 0.25948104736911265\n",
      "\n",
      "Test set: Avg. loss: 0.0006913094818592071, AUC: 0.5743385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00218301784992218, AUC: 0.490244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026273837089538575, AUC: 0.5634135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000695708841085434, AUC: 0.41186500000000004\n",
      "\n",
      "Train loss: 3.1153428231834606\n",
      "Train loss: 1.8357075543919945\n",
      "Train loss: 1.71253423971735\n",
      "Train loss: 1.4984649176810199\n",
      "Train loss: 1.1456300005031999\n",
      "Train loss: 1.1196951782627471\n",
      "Train loss: 1.0426948100897917\n",
      "Train loss: 0.7101636855465592\n",
      "Train loss: 0.683331804670346\n",
      "Train loss: 0.8381058213057792\n",
      "\n",
      "Test set: Avg. loss: 0.0006969109475612641, AUC: 0.3259475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020076621770858767, AUC: 0.600457\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025569573640823362, AUC: 0.6241030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006951325833797454, AUC: 0.39480899999999997\n",
      "\n",
      "Train loss: 2.0192777271483355\n",
      "Train loss: 1.6050851944905178\n",
      "Train loss: 1.273674363163626\n",
      "Train loss: 0.7537041279920347\n",
      "Train loss: 1.0107033150211262\n",
      "Train loss: 0.8565997075123392\n",
      "Train loss: 0.8311181049438039\n",
      "Train loss: 0.5456705738784401\n",
      "Train loss: 0.5802980277948319\n",
      "Train loss: 0.5417317934096999\n",
      "\n",
      "Test set: Avg. loss: 0.0006933388113975525, AUC: 0.492004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001826496183872223, AUC: 0.597284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002546107769012451, AUC: 0.61829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007065571546554565, AUC: 0.3759024999999999\n",
      "\n",
      "Train loss: 2.6989622803250697\n",
      "Train loss: 1.824000035881237\n",
      "Train loss: 1.858520693460088\n",
      "Train loss: 1.473468111578826\n",
      "Train loss: 0.9479754043232863\n",
      "Train loss: 0.9424743857353356\n",
      "Train loss: 1.0109802936292758\n",
      "Train loss: 0.8224018106035366\n",
      "Train loss: 0.5836732903863214\n",
      "Train loss: 0.475529909893206\n",
      "\n",
      "Test set: Avg. loss: 0.0007095831632614136, AUC: 0.2561675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019239385724067687, AUC: 0.6272170000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002410018801689148, AUC: 0.653365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006770358979701996, AUC: 0.7614744999999998\n",
      "\n",
      "Train loss: 1.4482147549368014\n",
      "Train loss: 1.0782965049622164\n",
      "Train loss: 0.8715026549472931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1333944349531915\n",
      "Train loss: 0.4936956789842836\n",
      "Train loss: 0.6847197781702515\n",
      "Train loss: 0.6981978735346703\n",
      "Train loss: 0.3060620749831959\n",
      "Train loss: 0.5588422664411509\n",
      "Train loss: 0.36043294410037385\n",
      "\n",
      "Test set: Avg. loss: 0.0006749890446662903, AUC: 0.772106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001904020369052887, AUC: 0.3095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025695160627365113, AUC: 0.533582\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949560046195984, AUC: 0.4225094999999999\n",
      "\n",
      "Train loss: 1.2430606727387494\n",
      "Train loss: 1.7227268856801805\n",
      "Train loss: 1.6863460939401274\n",
      "Train loss: 2.156649841244813\n",
      "Train loss: 1.2017113387964333\n",
      "Train loss: 1.0084415826068562\n",
      "Train loss: 1.0128434061244795\n",
      "Train loss: 1.0255884934382833\n",
      "Train loss: 1.2540636305596418\n",
      "Train loss: 1.2080791615376807\n",
      "\n",
      "Test set: Avg. loss: 0.0006946629583835602, AUC: 0.43576600000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001171343982219696, AUC: 0.5162720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002005854547023773, AUC: 0.579844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006983385980129242, AUC: 0.344113\n",
      "\n",
      "Train loss: 1.3145200291256995\n",
      "Train loss: 1.3682929061021014\n",
      "Train loss: 1.4462096015359187\n",
      "Train loss: 1.35595591926271\n",
      "Train loss: 1.3356326708368436\n",
      "Train loss: 1.04106688157768\n",
      "Train loss: 1.4510122829941428\n",
      "Train loss: 1.0797416195747958\n",
      "Train loss: 1.3923006137465215\n",
      "Train loss: 1.3623929931100007\n",
      "\n",
      "Test set: Avg. loss: 0.0006979204118251801, AUC: 0.355074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008599828481674195, AUC: 0.627731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016151135563850403, AUC: 0.660777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000699857771396637, AUC: 0.4281625\n",
      "\n",
      "Train loss: 1.2813235680768444\n",
      "Train loss: 1.3419604578595252\n",
      "Train loss: 1.891302286819288\n",
      "Train loss: 1.5705284966025383\n",
      "Train loss: 1.4389862592812557\n",
      "Train loss: 1.4407612597866424\n",
      "Train loss: 1.3025785661806726\n",
      "Train loss: 1.3591512741556593\n",
      "Train loss: 1.1317219115366601\n",
      "Train loss: 1.138587892435159\n",
      "\n",
      "Test set: Avg. loss: 0.0006976633369922638, AUC: 0.455136\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009450324773788452, AUC: 0.461024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018912098407745362, AUC: 0.550714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006961932182312011, AUC: 0.458339\n",
      "\n",
      "Train loss: 2.434488802199151\n",
      "Train loss: 1.533459470909872\n",
      "Train loss: 2.4515485581319045\n",
      "Train loss: 2.1286768571586365\n",
      "Train loss: 1.960750796233013\n",
      "Train loss: 1.7489686999351355\n",
      "Train loss: 1.7085098259767908\n",
      "Train loss: 1.7063958439857336\n",
      "Train loss: 1.9022441092570117\n",
      "Train loss: 1.684890338949337\n",
      "\n",
      "Test set: Avg. loss: 0.0006954987347126007, AUC: 0.4890845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007998717427253723, AUC: 0.6445819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001669354796409607, AUC: 0.6557864999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007014391422271728, AUC: 0.34474150000000003\n",
      "\n",
      "Train loss: 0.8563918205583172\n",
      "Train loss: 1.5919063083685128\n",
      "Train loss: 1.3867474205934318\n",
      "Train loss: 0.8619324394092438\n",
      "Train loss: 0.7337055092404603\n",
      "Train loss: 0.898260912697786\n",
      "Train loss: 0.8586751142884516\n",
      "Train loss: 0.494220462574321\n",
      "Train loss: 0.7916753967856146\n",
      "Train loss: 0.7256250476381582\n",
      "\n",
      "Test set: Avg. loss: 0.0007019863426685333, AUC: 0.3311825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014706581830978393, AUC: 0.39354999999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022357897758483888, AUC: 0.497106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947447955608368, AUC: 0.5277535\n",
      "\n",
      "Train loss: 2.3616989562465887\n",
      "Train loss: 1.8631413457499948\n",
      "Train loss: 1.835740126621951\n",
      "Train loss: 1.634288936663585\n",
      "Train loss: 1.559128476935587\n",
      "Train loss: 1.368939300631262\n",
      "Train loss: 1.5546144421692867\n",
      "Train loss: 1.2276957521013394\n",
      "Train loss: 1.225567455883998\n",
      "Train loss: 1.5109694862062004\n",
      "\n",
      "Test set: Avg. loss: 0.0006940247714519501, AUC: 0.5696265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00127134370803833, AUC: 0.530975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021322553157806395, AUC: 0.580528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006907617449760437, AUC: 0.622261\n",
      "\n",
      "Train loss: 2.9240825684966554\n",
      "Train loss: 2.6431627338099632\n",
      "Train loss: 2.3032472589213375\n",
      "Train loss: 2.464867325345422\n",
      "Train loss: 1.8690681077872113\n",
      "Train loss: 2.211456366785013\n",
      "Train loss: 1.8848412879713021\n",
      "Train loss: 1.6584563403372552\n",
      "Train loss: 1.719972511765304\n",
      "Train loss: 1.353394639340176\n",
      "\n",
      "Test set: Avg. loss: 0.0006907846331596374, AUC: 0.6274945000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012276180982589721, AUC: 0.5780829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020206725001335143, AUC: 0.589577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007036864161491394, AUC: 0.23192400000000002\n",
      "\n",
      "Train loss: 1.2570390948064767\n",
      "Train loss: 0.984951165831013\n",
      "Train loss: 1.4404372990511025\n",
      "Train loss: 0.8199655087130844\n",
      "Train loss: 1.2592138488581226\n",
      "Train loss: 0.9959060807896268\n",
      "Train loss: 0.7031627623898209\n",
      "Train loss: 1.0695139325348435\n",
      "Train loss: 0.999868935840145\n",
      "Train loss: 0.8360724080899719\n",
      "\n",
      "Test set: Avg. loss: 0.0007054066359996796, AUC: 0.22296400000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012992565035820007, AUC: 0.337356\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002142788767814636, AUC: 0.46625999999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006944966912269592, AUC: 0.46593850000000003\n",
      "\n",
      "Train loss: 1.903784973226535\n",
      "Train loss: 1.8276025895859784\n",
      "Train loss: 1.3569379240084605\n",
      "Train loss: 1.3916800185373635\n",
      "Train loss: 1.4642921036975398\n",
      "Train loss: 1.1730159456562843\n",
      "Train loss: 1.2589606259279191\n",
      "Train loss: 1.1314294288872153\n",
      "Train loss: 1.2624122306799432\n",
      "Train loss: 1.2851404646399673\n",
      "\n",
      "Test set: Avg. loss: 0.0006962746381759643, AUC: 0.400246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010838989019393921, AUC: 0.554773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019353327751159667, AUC: 0.592867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006937496066093445, AUC: 0.4818985\n",
      "\n",
      "Train loss: 1.39016402754814\n",
      "Train loss: 0.9205983098904797\n",
      "Train loss: 1.1540707524415035\n",
      "Train loss: 0.9942316629324749\n",
      "Train loss: 0.9058758438013161\n",
      "Train loss: 1.2549829707024203\n",
      "Train loss: 1.209640822213167\n",
      "Train loss: 0.8549977419482675\n",
      "Train loss: 0.8735205982900729\n",
      "Train loss: 1.0172500940644817\n",
      "\n",
      "Test set: Avg. loss: 0.0006944300532341003, AUC: 0.4507405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014087097644805908, AUC: 0.475331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022245914936065672, AUC: 0.5413330000000001\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 55\u001b[0m\n\u001b[1;32m     45\u001b[0m auc_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(learning_rate_aucs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(learning_rates)): \n\u001b[1;32m     51\u001b[0m     row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriplet_loss_first_stage_smote\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m, nums, ratio, learning_rates[i],\n\u001b[1;32m     52\u001b[0m             auc_mean[i][\u001b[38;5;241m0\u001b[39m], auc_variance[i][\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     53\u001b[0m             auc_mean[i][\u001b[38;5;241m1\u001b[39m], auc_variance[i][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     54\u001b[0m             auc_mean[i][\u001b[38;5;241m2\u001b[39m], auc_variance[i][\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m---> 55\u001b[0m             auc_mean[i][\u001b[38;5;241m3\u001b[39m], auc_variance[i][\u001b[38;5;241m3\u001b[39m], \u001b[43mcap\u001b[49m, norm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_epoch=10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# triplet loss smote + no smote training \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 5e-3), (1e-6, 1e-2), (5e-6, 1e-3), (1e-6, 5e-4)]\n",
    "\n",
    "loss_fn_args = {}\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "\n",
    "start_epoch = 10\n",
    "\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10): \n",
    "        model_aucs = []\n",
    "        embed_network = models.ConvNetOnlyEmbeddingsEarly(2)\n",
    "        linear_probe = models.ConvNetLinearProbeEarly(2)\n",
    "        complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "        embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "        linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(start_epoch):\n",
    "            _, train_losses = train.train_triplet_loss_smote(epoch, train_loader_tripletloss_smote, embed_network, embed_optimizer, verbose=False)\n",
    "            print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        for epoch in range(start_epoch, n_epochs+1):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, complete_network, linear_optimizer, verbose=False, loss_fn_args=loss_fn_args)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a324ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be959888",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], cap, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2585c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e2c5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26e54a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006957003772258758, AUC: 0.39529899999999996\n",
      "\n",
      "Train loss: 2.310011562648093\n",
      "Train loss: 2.2350221542036457\n",
      "Train loss: 1.7336593600595074\n",
      "Train loss: 1.3570892761467368\n",
      "Train loss: 1.7184112235239357\n",
      "Train loss: 1.1358157290015252\n",
      "Train loss: 1.0679599012538885\n",
      "Train loss: 0.921282701431566\n",
      "Train loss: 1.1848033970328653\n",
      "Train loss: 0.9810460426245525\n",
      "Train loss: 0.9329271555706194\n",
      "Train loss: 0.9048631927769655\n",
      "Train loss: 0.5647244722979843\n",
      "Train loss: 0.5945013852635767\n",
      "Train loss: 0.5329235454273832\n",
      "\n",
      "Test set: Avg. loss: 0.00039782971143722536, AUC: 0.918406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004035674780607224, AUC: 0.927185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037781354784965514, AUC: 0.935988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927546858787537, AUC: 0.530769\n",
      "\n",
      "Train loss: 2.022161154610336\n",
      "Train loss: 1.288486762031628\n",
      "Train loss: 1.399418694957806\n",
      "Train loss: 1.0709760223224665\n",
      "Train loss: 0.8879150535650314\n",
      "Train loss: 0.994375331386639\n",
      "Train loss: 0.9763853713205666\n",
      "Train loss: 0.5693383987542171\n",
      "Train loss: 0.9217924274456729\n",
      "Train loss: 0.8383852824284013\n",
      "Train loss: 0.8140671158292491\n",
      "Train loss: 0.5722766241450219\n",
      "Train loss: 0.6047726167235404\n",
      "Train loss: 0.7253834802633637\n",
      "Train loss: 0.4782866505300923\n",
      "\n",
      "Test set: Avg. loss: 0.00043531887233257295, AUC: 0.902573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000422521635890007, AUC: 0.9201060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003795756101608276, AUC: 0.934749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006942583620548248, AUC: 0.502446\n",
      "\n",
      "Train loss: 1.7677589347408076\n",
      "Train loss: 1.8473584458326837\n",
      "Train loss: 1.7053442684708127\n",
      "Train loss: 1.416161296853594\n",
      "Train loss: 1.141511501400334\n",
      "Train loss: 1.1581196515423477\n",
      "Train loss: 0.9427745911725767\n",
      "Train loss: 1.0230498211399006\n",
      "Train loss: 0.6721523760989973\n",
      "Train loss: 0.5520871099393079\n",
      "Train loss: 0.8345379647175977\n",
      "Train loss: 0.9725911567924889\n",
      "Train loss: 0.5424710143903259\n",
      "Train loss: 0.5316900049045588\n",
      "Train loss: 0.5941856465521892\n",
      "\n",
      "Test set: Avg. loss: 0.00041989779472351076, AUC: 0.9123869999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003987732827663422, AUC: 0.9274910000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003638770878314972, AUC: 0.9362480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689285546541214, AUC: 0.687736\n",
      "\n",
      "Train loss: 1.495846663311029\n",
      "Train loss: 1.267180768547544\n",
      "Train loss: 1.6462099081391741\n",
      "Train loss: 1.0757786248140275\n",
      "Train loss: 1.1906113187978222\n",
      "Train loss: 0.8177587450689571\n",
      "Train loss: 0.8175334740596213\n",
      "Train loss: 0.7203467036508451\n",
      "Train loss: 0.6773714051125156\n",
      "Train loss: 0.5988440695841601\n",
      "Train loss: 0.7361402386313032\n",
      "Train loss: 0.42098387335516085\n",
      "Train loss: 0.5238839247424132\n",
      "Train loss: 0.31308006405071087\n",
      "Train loss: 0.4069526119596639\n",
      "\n",
      "Test set: Avg. loss: 0.00043320918083190917, AUC: 0.9107480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000422193244099617, AUC: 0.9187759999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035831086337566374, AUC: 0.9378759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949281096458436, AUC: 0.48180999999999996\n",
      "\n",
      "Train loss: 1.8548816784172302\n",
      "Train loss: 1.3863887054145716\n",
      "Train loss: 1.6101639115127029\n",
      "Train loss: 1.7781756565828992\n",
      "Train loss: 1.1052604218956772\n",
      "Train loss: 0.9795122097252281\n",
      "Train loss: 0.8326696856006696\n",
      "Train loss: 0.9085525866526707\n",
      "Train loss: 0.9520809946546129\n",
      "Train loss: 0.7201870577350543\n",
      "Train loss: 0.6012145732618441\n",
      "Train loss: 0.5797658304499972\n",
      "Train loss: 0.5518804967023765\n",
      "Train loss: 0.5310744734326746\n",
      "Train loss: 0.5478573209920506\n",
      "\n",
      "Test set: Avg. loss: 0.000391305685043335, AUC: 0.918516\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037205873429775236, AUC: 0.9313560000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034368816018104554, AUC: 0.9376550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007059581279754639, AUC: 0.2546945\n",
      "\n",
      "Train loss: 1.032807933297127\n",
      "Train loss: 0.8298509728377033\n",
      "Train loss: 0.7243748519830643\n",
      "Train loss: 1.0180361548047157\n",
      "Train loss: 0.9950011934444403\n",
      "Train loss: 0.5970637957761242\n",
      "Train loss: 0.632870893569509\n",
      "Train loss: 0.6421500805077279\n",
      "Train loss: 0.3735534647467789\n",
      "Train loss: 0.5433057603562713\n",
      "Train loss: 0.3770814678471559\n",
      "Train loss: 0.47836669994767306\n",
      "Train loss: 0.5512357597138472\n",
      "Train loss: 0.3627752711059182\n",
      "Train loss: 0.4186748475026173\n",
      "\n",
      "Test set: Avg. loss: 0.0004021726548671722, AUC: 0.914386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003833182901144028, AUC: 0.929598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003662377893924713, AUC: 0.9335450000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006975426971912384, AUC: 0.3909895\n",
      "\n",
      "Train loss: 2.0770836582609045\n",
      "Train loss: 1.954999076712663\n",
      "Train loss: 1.2597821559875635\n",
      "Train loss: 1.1962599200048265\n",
      "Train loss: 1.8015421294862297\n",
      "Train loss: 1.2269869610002846\n",
      "Train loss: 1.1497848254100533\n",
      "Train loss: 0.8856590412984229\n",
      "Train loss: 1.0465123585075329\n",
      "Train loss: 0.9539744850176914\n",
      "Train loss: 0.8811213328580189\n",
      "Train loss: 0.7094797613514456\n",
      "Train loss: 0.6675684330569711\n",
      "Train loss: 0.8660271084232695\n",
      "Train loss: 0.7509766274197086\n",
      "\n",
      "Test set: Avg. loss: 0.00043649809062480926, AUC: 0.906458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003919942080974579, AUC: 0.930021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035204361379146575, AUC: 0.93962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006841252148151398, AUC: 0.728719\n",
      "\n",
      "Train loss: 2.792424700442393\n",
      "Train loss: 1.6395947238442246\n",
      "Train loss: 1.7805285658805994\n",
      "Train loss: 1.4789784265931245\n",
      "Train loss: 1.5566897787106264\n",
      "Train loss: 1.299844227019389\n",
      "Train loss: 0.7196527795427164\n",
      "Train loss: 0.9572801836736643\n",
      "Train loss: 1.2006448780655101\n",
      "Train loss: 1.20849530977808\n",
      "Train loss: 0.9535093223972685\n",
      "Train loss: 0.7700273618576633\n",
      "Train loss: 0.44269351480872765\n",
      "Train loss: 0.70063233717232\n",
      "Train loss: 0.6761433846631627\n",
      "\n",
      "Test set: Avg. loss: 0.000415567085146904, AUC: 0.918102\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037865456938743593, AUC: 0.9287039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039964130520820615, AUC: 0.934788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007041244804859161, AUC: 0.3282575\n",
      "\n",
      "Train loss: 1.9345506889045618\n",
      "Train loss: 2.239732494020158\n",
      "Train loss: 1.3338085925503143\n",
      "Train loss: 1.2418701041276288\n",
      "Train loss: 1.0202735499211937\n",
      "Train loss: 0.8250726427242254\n",
      "Train loss: 0.9315003608442416\n",
      "Train loss: 1.4045901177035776\n",
      "Train loss: 0.5085094958353954\n",
      "Train loss: 0.7923745361103374\n",
      "Train loss: 0.8632507863318085\n",
      "Train loss: 0.5996925424618326\n",
      "Train loss: 0.29769950459717187\n",
      "Train loss: 0.6822053456002739\n",
      "Train loss: 0.3885033157221071\n",
      "\n",
      "Test set: Avg. loss: 0.0004146324098110199, AUC: 0.911088\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003962185829877853, AUC: 0.928681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038269555568695067, AUC: 0.9335709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006918051838874817, AUC: 0.6078685\n",
      "\n",
      "Train loss: 1.556321721547728\n",
      "Train loss: 1.3116541933861507\n",
      "Train loss: 1.3728186195823038\n",
      "Train loss: 1.1807150051092645\n",
      "Train loss: 1.3282080304091144\n",
      "Train loss: 1.1629292068967394\n",
      "Train loss: 1.155078321505504\n",
      "Train loss: 1.1272341271114956\n",
      "Train loss: 0.7945121223000204\n",
      "Train loss: 0.8294190396169189\n",
      "Train loss: 0.9098578072657251\n",
      "Train loss: 0.7372154377068684\n",
      "Train loss: 0.8778107838266215\n",
      "Train loss: 0.7533023596569232\n",
      "Train loss: 0.5721017201994635\n",
      "\n",
      "Test set: Avg. loss: 0.0004253978282213211, AUC: 0.912493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040360434353351593, AUC: 0.92855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003604414016008377, AUC: 0.939916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006946688294410706, AUC: 0.5203519999999999\n",
      "\n",
      "Train loss: 2.583174364961636\n",
      "Train loss: 2.4968437822001754\n",
      "Train loss: 2.1837105314443064\n",
      "Train loss: 1.967260580533629\n",
      "Train loss: 2.103243129268573\n",
      "Train loss: 1.9119337064445399\n",
      "Train loss: 2.0439731125619\n",
      "Train loss: 2.4246411581707608\n",
      "Train loss: 1.7226149785290858\n",
      "Train loss: 1.8757968374118683\n",
      "Train loss: 1.873263371598189\n",
      "Train loss: 1.6292909531836297\n",
      "Train loss: 1.47985786009746\n",
      "Train loss: 1.4492073017320815\n",
      "Train loss: 1.815670432558485\n",
      "\n",
      "Test set: Avg. loss: 0.00045680414140224457, AUC: 0.8966700000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040216045081615447, AUC: 0.91575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00041600202023983, AUC: 0.9249080000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006985277235507965, AUC: 0.320307\n",
      "\n",
      "Train loss: 2.4310016673841295\n",
      "Train loss: 1.9460211449367986\n",
      "Train loss: 2.304060568095772\n",
      "Train loss: 1.7767846922206272\n",
      "Train loss: 1.9375786413053038\n",
      "Train loss: 1.9003502024207146\n",
      "Train loss: 1.4759956632450129\n",
      "Train loss: 1.5016104552396543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.970422636551462\n",
      "Train loss: 1.4079155132269403\n",
      "Train loss: 1.4688413837912735\n",
      "Train loss: 1.4076758281440491\n",
      "Train loss: 1.1350592856953858\n",
      "Train loss: 1.8857001426872935\n",
      "Train loss: 1.4556400149491182\n",
      "\n",
      "Test set: Avg. loss: 0.00047363899648189545, AUC: 0.8819830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042409318685531617, AUC: 0.908577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003766205757856369, AUC: 0.922854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006900011897087098, AUC: 0.654073\n",
      "\n",
      "Train loss: 1.9343711790765168\n",
      "Train loss: 1.4965036446881141\n",
      "Train loss: 1.744480819459174\n",
      "Train loss: 1.445263187217105\n",
      "Train loss: 1.3542424216391935\n",
      "Train loss: 1.3084997363910553\n",
      "Train loss: 1.4788874330793975\n",
      "Train loss: 1.3785485469611587\n",
      "Train loss: 1.6266570197548835\n",
      "Train loss: 1.6530657175240244\n",
      "Train loss: 1.117041161105891\n",
      "Train loss: 1.1217445317347339\n",
      "Train loss: 0.7305867747896037\n",
      "Train loss: 1.335534641317501\n",
      "Train loss: 1.165849501539947\n",
      "\n",
      "Test set: Avg. loss: 0.0004729681611061096, AUC: 0.886551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000434605211019516, AUC: 0.9089720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003964823633432388, AUC: 0.921496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948385834693909, AUC: 0.45293300000000003\n",
      "\n",
      "Train loss: 2.838434695438215\n",
      "Train loss: 2.1438076230371075\n",
      "Train loss: 2.4100869370114273\n",
      "Train loss: 2.3277919983408255\n",
      "Train loss: 2.0542441857088902\n",
      "Train loss: 1.932898898413227\n",
      "Train loss: 2.1418099612187427\n",
      "Train loss: 1.8697841486353783\n",
      "Train loss: 1.4413236861775636\n",
      "Train loss: 1.176063375108561\n",
      "Train loss: 1.573230844014769\n",
      "Train loss: 1.1145322140614697\n",
      "Train loss: 1.1721717271075887\n",
      "Train loss: 1.6871109627614356\n",
      "Train loss: 1.3137204996339835\n",
      "\n",
      "Test set: Avg. loss: 0.00045576393604278563, AUC: 0.8993240000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004253361374139786, AUC: 0.9163030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004524254947900772, AUC: 0.921484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694339007139206, AUC: 0.44818199999999997\n",
      "\n",
      "Train loss: 1.902850356071618\n",
      "Train loss: 1.9377130387694972\n",
      "Train loss: 1.8242057926335913\n",
      "Train loss: 1.501140846568308\n",
      "Train loss: 1.5635184444439638\n",
      "Train loss: 1.494578115499703\n",
      "Train loss: 1.3114372070427913\n",
      "Train loss: 0.984448684628602\n",
      "Train loss: 1.0118428742050365\n",
      "Train loss: 1.2679768876664956\n",
      "Train loss: 0.9874832296067741\n",
      "Train loss: 0.8487269920148667\n",
      "Train loss: 0.9704973014296999\n",
      "Train loss: 1.1202531449354378\n",
      "Train loss: 0.8656843410935372\n",
      "\n",
      "Test set: Avg. loss: 0.00047323435544967653, AUC: 0.8815930000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004198194146156311, AUC: 0.9080090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000403200775384903, AUC: 0.9177559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006985858380794526, AUC: 0.402578\n",
      "\n",
      "Train loss: 1.5185066909547065\n",
      "Train loss: 1.303605723912549\n",
      "Train loss: 1.3999682611720576\n",
      "Train loss: 1.5271335122691598\n",
      "Train loss: 1.525771030574847\n",
      "Train loss: 1.2952381581257864\n",
      "Train loss: 1.81612629875256\n",
      "Train loss: 1.8068520772229335\n",
      "Train loss: 1.4788496224743546\n",
      "Train loss: 1.3772668880262193\n",
      "Train loss: 1.2112371359661127\n",
      "Train loss: 0.9699833267813276\n",
      "Train loss: 1.3372103283359746\n",
      "Train loss: 1.5658973444039654\n",
      "Train loss: 1.0090744294178713\n",
      "\n",
      "Test set: Avg. loss: 0.00046936610341072083, AUC: 0.8861859999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040863730013370516, AUC: 0.908681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000389703094959259, AUC: 0.923539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007027014195919037, AUC: 0.44139599999999996\n",
      "\n",
      "Train loss: 4.961532285638675\n",
      "Train loss: 3.8456980422803553\n",
      "Train loss: 3.822131424572817\n",
      "Train loss: 4.261773332668717\n",
      "Train loss: 3.214836978988283\n",
      "Train loss: 2.9650693087820796\n",
      "Train loss: 3.557798695032764\n",
      "Train loss: 2.7855322319231215\n",
      "Train loss: 2.490268556175718\n",
      "Train loss: 3.0649039604861263\n",
      "Train loss: 2.4456994996708668\n",
      "Train loss: 3.189392985052364\n",
      "Train loss: 2.502088221774739\n",
      "Train loss: 2.5820756550807102\n",
      "Train loss: 2.505756460557318\n",
      "\n",
      "Test set: Avg. loss: 0.0004634280651807785, AUC: 0.883039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044609998166561125, AUC: 0.900667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042397844791412353, AUC: 0.91744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006935093700885772, AUC: 0.4911545\n",
      "\n",
      "Train loss: 2.827882004771263\n",
      "Train loss: 2.7604078304995396\n",
      "Train loss: 1.9118825762894502\n",
      "Train loss: 1.9576757216149834\n",
      "Train loss: 1.6423242198433845\n",
      "Train loss: 1.9774705266496937\n",
      "Train loss: 2.4156057853607615\n",
      "Train loss: 1.8582306766206291\n",
      "Train loss: 2.2600067265474113\n",
      "Train loss: 1.7889438856179547\n",
      "Train loss: 2.1400705929015094\n",
      "Train loss: 1.664519857828784\n",
      "Train loss: 2.3582702047505957\n",
      "Train loss: 1.7632667574153584\n",
      "Train loss: 1.589283303850016\n",
      "\n",
      "Test set: Avg. loss: 0.00048163852095603943, AUC: 0.881441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004130743741989136, AUC: 0.910871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039782479405403137, AUC: 0.916774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006909832954406738, AUC: 0.6436289999999999\n",
      "\n",
      "Train loss: 2.4274699498134056\n",
      "Train loss: 1.4709733443655026\n",
      "Train loss: 2.585436264800418\n",
      "Train loss: 1.9941132322997803\n",
      "Train loss: 2.0299238835930065\n",
      "Train loss: 1.449279988267619\n",
      "Train loss: 1.4882808225170063\n",
      "Train loss: 1.4821608377869722\n",
      "Train loss: 1.3700888042996644\n",
      "Train loss: 1.6339233369584296\n",
      "Train loss: 1.4365667962724236\n",
      "Train loss: 1.3266162739437857\n",
      "Train loss: 1.1601651132486428\n",
      "Train loss: 1.2700066080518588\n",
      "Train loss: 1.5300845682241355\n",
      "\n",
      "Test set: Avg. loss: 0.0004493151754140854, AUC: 0.902361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004268527626991272, AUC: 0.9176790000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038585835695266723, AUC: 0.927446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006962308585643769, AUC: 0.6114605000000001\n",
      "\n",
      "Train loss: 2.139595368485542\n",
      "Train loss: 2.0107818059860523\n",
      "Train loss: 2.4498375403653285\n",
      "Train loss: 2.31513741593452\n",
      "Train loss: 1.9138831143166608\n",
      "Train loss: 2.1946495889098783\n",
      "Train loss: 1.992693810705926\n",
      "Train loss: 1.549981985122535\n",
      "Train loss: 1.459531976918506\n",
      "Train loss: 1.66401763744415\n",
      "Train loss: 1.7735859170840804\n",
      "Train loss: 1.8173054764225225\n",
      "Train loss: 1.778051620456064\n",
      "Train loss: 1.4682476342104043\n",
      "Train loss: 1.7584255197245604\n",
      "\n",
      "Test set: Avg. loss: 0.0004657865762710571, AUC: 0.8844319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00041551969945430756, AUC: 0.9141600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003932972252368927, AUC: 0.924954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947956979274749, AUC: 0.5016995\n",
      "\n",
      "Train loss: 1.3341237105381716\n",
      "Train loss: 2.1974878618671636\n",
      "Train loss: 2.050501252435575\n",
      "Train loss: 1.7039758794626612\n",
      "Train loss: 1.8012874642754817\n",
      "Train loss: 1.9536826815574793\n",
      "Train loss: 1.3181599283673961\n",
      "Train loss: 1.7080981807344278\n",
      "Train loss: 1.522159779907032\n",
      "Train loss: 1.818768725653363\n",
      "Train loss: 1.471985999565975\n",
      "Train loss: 1.7699677932793927\n",
      "Train loss: 1.500324511983592\n",
      "Train loss: 1.3309327329799627\n",
      "Train loss: 1.5362904292003365\n",
      "\n",
      "Test set: Avg. loss: 0.00041811206936836245, AUC: 0.906908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039508455991744994, AUC: 0.9253369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003738473653793335, AUC: 0.9314579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006912962794303894, AUC: 0.5875945\n",
      "\n",
      "Train loss: 2.5562263715798688\n",
      "Train loss: 2.054924303179334\n",
      "Train loss: 2.067889763671122\n",
      "Train loss: 1.733651000982637\n",
      "Train loss: 1.9267696768614897\n",
      "Train loss: 1.7586761895258716\n",
      "Train loss: 1.8657160644318647\n",
      "Train loss: 1.719739404073946\n",
      "Train loss: 1.5096439312977397\n",
      "Train loss: 1.4931185518860057\n",
      "Train loss: 1.6661030832369617\n",
      "Train loss: 1.2818263689423823\n",
      "Train loss: 1.7293831174540673\n",
      "Train loss: 1.5203613369328202\n",
      "Train loss: 1.7941524568636706\n",
      "\n",
      "Test set: Avg. loss: 0.0004423072338104248, AUC: 0.9094360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000423960343003273, AUC: 0.9248050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038462673127651216, AUC: 0.9346629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006945312023162841, AUC: 0.5326005\n",
      "\n",
      "Train loss: 1.7690215634692246\n",
      "Train loss: 1.4092736794690417\n",
      "Train loss: 1.6899825239637096\n",
      "Train loss: 1.542519234547949\n",
      "Train loss: 1.5543991391825829\n",
      "Train loss: 1.7196540612324027\n",
      "Train loss: 1.6057658928215124\n",
      "Train loss: 1.3434792328032719\n",
      "Train loss: 1.5152052048664943\n",
      "Train loss: 1.0969433978105048\n",
      "Train loss: 1.7800151591847657\n",
      "Train loss: 1.3823064265737108\n",
      "Train loss: 1.6685189483272043\n",
      "Train loss: 1.069920779033831\n",
      "Train loss: 0.9663466355603212\n",
      "\n",
      "Test set: Avg. loss: 0.0004216569662094116, AUC: 0.9140440000000001\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00036962753534317016, AUC: 0.9312050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004138304591178894, AUC: 0.9353440000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000701473593711853, AUC: 0.40515\n",
      "\n",
      "Train loss: 1.065467907744608\n",
      "Train loss: 1.3622498276886668\n",
      "Train loss: 1.5146699308589766\n",
      "Train loss: 1.1519298059925152\n",
      "Train loss: 1.2872650144965785\n",
      "Train loss: 1.1337903233090783\n",
      "Train loss: 1.0842262722884015\n",
      "Train loss: 1.1602510191073083\n",
      "Train loss: 0.7593976547763606\n",
      "Train loss: 1.2732060164403005\n",
      "Train loss: 1.3662886513266594\n",
      "Train loss: 0.6023548021438015\n",
      "Train loss: 1.124361228791012\n",
      "Train loss: 1.1234989906572233\n",
      "Train loss: 0.8597518346112245\n",
      "\n",
      "Test set: Avg. loss: 0.00041623535752296446, AUC: 0.920745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003963103443384171, AUC: 0.934286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00045862875878810883, AUC: 0.936785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006941128373146058, AUC: 0.5132665\n",
      "\n",
      "Train loss: 3.3644635339451443\n",
      "Train loss: 2.1163280215232994\n",
      "Train loss: 1.979751812044982\n",
      "Train loss: 2.9655603694308335\n",
      "Train loss: 2.335901003354674\n",
      "Train loss: 2.091515109037897\n",
      "Train loss: 2.206679254200808\n",
      "Train loss: 2.734819473734327\n",
      "Train loss: 1.8713578969050364\n",
      "Train loss: 2.6784692695186396\n",
      "Train loss: 1.6861833098587717\n",
      "Train loss: 1.3730688007773868\n",
      "Train loss: 1.534634741628246\n",
      "Train loss: 0.7286027252294456\n",
      "Train loss: 1.3139150590653632\n",
      "\n",
      "Test set: Avg. loss: 0.00042359192669391634, AUC: 0.9082400000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00048334313929080964, AUC: 0.9193760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044934698939323427, AUC: 0.928472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000695196270942688, AUC: 0.5298175\n",
      "\n",
      "Train loss: 3.044659461944726\n",
      "Train loss: 2.551771532957721\n",
      "Train loss: 1.9014595355957178\n",
      "Train loss: 2.7509314641831026\n",
      "Train loss: 2.764628359086954\n",
      "Train loss: 2.745275926438107\n",
      "Train loss: 1.9674844369766817\n",
      "Train loss: 2.536965831449837\n",
      "Train loss: 2.5107981592986235\n",
      "Train loss: 2.899844480927583\n",
      "Train loss: 1.9817434936572031\n",
      "Train loss: 2.260456234786161\n",
      "Train loss: 1.6879900371193126\n",
      "Train loss: 1.92731064140417\n",
      "Train loss: 1.6755265346757926\n",
      "\n",
      "Test set: Avg. loss: 0.00039330087602138517, AUC: 0.9168320000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035143940150737763, AUC: 0.9378569999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034264783561229704, AUC: 0.9414929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689552366733551, AUC: 0.6212285\n",
      "\n",
      "Train loss: 1.5331814262517698\n",
      "Train loss: 1.1389007648085332\n",
      "Train loss: 1.0991159210539168\n",
      "Train loss: 1.3965047176476497\n",
      "Train loss: 1.4320910075667557\n",
      "Train loss: 1.1398993722952095\n",
      "Train loss: 1.6438671938932625\n",
      "Train loss: 1.4221151881157212\n",
      "Train loss: 1.2001555311452052\n",
      "Train loss: 1.0746287483318595\n",
      "Train loss: 1.1720936499583494\n",
      "Train loss: 0.8358631714893754\n",
      "Train loss: 1.1796302647347663\n",
      "Train loss: 1.10521779318524\n",
      "Train loss: 0.7776804186735943\n",
      "\n",
      "Test set: Avg. loss: 0.00048428669571876526, AUC: 0.9118379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005237846672534942, AUC: 0.9262415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000569075345993042, AUC: 0.930221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007029748857021331, AUC: 0.322977\n",
      "\n",
      "Train loss: 1.605328872325314\n",
      "Train loss: 1.5588653919043813\n",
      "Train loss: 1.9121351648288167\n",
      "Train loss: 1.7227350234226058\n",
      "Train loss: 2.212599135128556\n",
      "Train loss: 1.6610165314309915\n",
      "Train loss: 1.7295450454304933\n",
      "Train loss: 1.3934827670929537\n",
      "Train loss: 1.5008799915860414\n",
      "Train loss: 1.5810198168845693\n",
      "Train loss: 1.446541486652034\n",
      "Train loss: 1.4180493168770127\n",
      "Train loss: 1.4187206899284557\n",
      "Train loss: 1.3737571755791926\n",
      "Train loss: 1.5052037675669239\n",
      "\n",
      "Test set: Avg. loss: 0.000428346574306488, AUC: 0.9038660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000408862441778183, AUC: 0.918464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003745451718568802, AUC: 0.9323959999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006958560943603516, AUC: 0.421932\n",
      "\n",
      "Train loss: 2.002201202948382\n",
      "Train loss: 2.4418856721774787\n",
      "Train loss: 1.9039164796756332\n",
      "Train loss: 1.836776056107442\n",
      "Train loss: 1.9867238633951563\n",
      "Train loss: 1.9795862872889087\n",
      "Train loss: 1.8044664111866313\n",
      "Train loss: 2.020744363593448\n",
      "Train loss: 1.4115867785587433\n",
      "Train loss: 1.2793003613022482\n",
      "Train loss: 1.7193037043711183\n",
      "Train loss: 1.0090994785545737\n",
      "Train loss: 1.7226488483939202\n",
      "Train loss: 1.3057370823659715\n",
      "Train loss: 1.5997074652629293\n",
      "\n",
      "Test set: Avg. loss: 0.00039876195788383483, AUC: 0.911627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000370293989777565, AUC: 0.932272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042317914962768555, AUC: 0.9371469999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006970470249652862, AUC: 0.361263\n",
      "\n",
      "Train loss: 1.448426442920782\n",
      "Train loss: 2.0261547238963424\n",
      "Train loss: 1.500613168925996\n",
      "Train loss: 1.696548611874793\n",
      "Train loss: 1.26298499524973\n",
      "Train loss: 1.4457258775735358\n",
      "Train loss: 1.8663959533545622\n",
      "Train loss: 1.6790762638590138\n",
      "Train loss: 1.311977691331487\n",
      "Train loss: 1.110382558433873\n",
      "Train loss: 1.3031481622131007\n",
      "Train loss: 1.2095687112231164\n",
      "Train loss: 1.3323279623013393\n",
      "Train loss: 1.1119391310746503\n",
      "Train loss: 1.1362310928903567\n",
      "\n",
      "Test set: Avg. loss: 0.00042390996217727664, AUC: 0.9123509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004404672384262085, AUC: 0.9210309999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038320353627204894, AUC: 0.933745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006908539235591888, AUC: 0.6276575\n",
      "\n",
      "Train loss: 2.2480395626110634\n",
      "Train loss: 1.1867681301323472\n",
      "Train loss: 1.4849141137615132\n",
      "Train loss: 1.362275172950356\n",
      "Train loss: 0.8740834548215198\n",
      "Train loss: 1.0733056269633543\n",
      "Train loss: 0.8760471575579066\n",
      "Train loss: 1.1791387845756143\n",
      "Train loss: 0.5943953797316096\n",
      "Train loss: 0.9012027902967611\n",
      "Train loss: 0.719067598604093\n",
      "Train loss: 0.780088439868514\n",
      "Train loss: 0.5790081627809318\n",
      "Train loss: 0.4776619718332959\n",
      "Train loss: 0.4154877954987204\n",
      "\n",
      "Test set: Avg. loss: 0.00033546756207942965, AUC: 0.9382889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035798951983451844, AUC: 0.937374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00032517361640930175, AUC: 0.946767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927938163280487, AUC: 0.5568995000000001\n",
      "\n",
      "Train loss: 1.4981148956687587\n",
      "Train loss: 1.2609440695707965\n",
      "Train loss: 1.2108171726488004\n",
      "Train loss: 1.0813258818000744\n",
      "Train loss: 1.2218539077005568\n",
      "Train loss: 0.7958241264531567\n",
      "Train loss: 0.8111746523790299\n",
      "Train loss: 0.8097322211144077\n",
      "Train loss: 0.8614113258708055\n",
      "Train loss: 0.7558070451590666\n",
      "Train loss: 0.5925567305771409\n",
      "Train loss: 0.4964767675490896\n",
      "Train loss: 0.6136222743684319\n",
      "Train loss: 0.4303761568798381\n",
      "Train loss: 0.5412341234790292\n",
      "\n",
      "Test set: Avg. loss: 0.00044493715465068816, AUC: 0.931014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035282617807388304, AUC: 0.9393670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037601666152477264, AUC: 0.9394140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940064132213593, AUC: 0.46464300000000003\n",
      "\n",
      "Train loss: 1.6525405337856074\n",
      "Train loss: 1.4180748227295603\n",
      "Train loss: 1.3354255849388754\n",
      "Train loss: 0.9160423806518506\n",
      "Train loss: 1.1159068854751102\n",
      "Train loss: 1.023386694823101\n",
      "Train loss: 0.7024036383932564\n",
      "Train loss: 0.5737391129420821\n",
      "Train loss: 0.5905510122608987\n",
      "Train loss: 0.5709847253598984\n",
      "Train loss: 0.8043206990904109\n",
      "Train loss: 0.740040373650326\n",
      "Train loss: 0.6739116941288019\n",
      "Train loss: 0.6548642819854105\n",
      "Train loss: 0.5283254354622713\n",
      "\n",
      "Test set: Avg. loss: 0.00042415910959243773, AUC: 0.931735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000426410436630249, AUC: 0.918856\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003601570874452591, AUC: 0.9355960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006934064030647278, AUC: 0.5043955\n",
      "\n",
      "Train loss: 2.4910039184199775\n",
      "Train loss: 1.39337097307679\n",
      "Train loss: 1.7959011645074103\n",
      "Train loss: 1.5066651326076241\n",
      "Train loss: 1.3483489721444002\n",
      "Train loss: 1.2652093870624614\n",
      "Train loss: 1.0816131784657763\n",
      "Train loss: 1.0603626484324218\n",
      "Train loss: 1.095256202919468\n",
      "Train loss: 0.9734524534006787\n",
      "Train loss: 0.8608164954337345\n",
      "Train loss: 0.6773723485363516\n",
      "Train loss: 0.7821790982203879\n",
      "Train loss: 0.8961417135918975\n",
      "Train loss: 0.6812320074458031\n",
      "\n",
      "Test set: Avg. loss: 0.0003696085661649704, AUC: 0.9272989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034005193412303924, AUC: 0.9373729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002953743636608124, AUC: 0.9536279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006980240941047668, AUC: 0.370317\n",
      "\n",
      "Train loss: 2.6104741016770623\n",
      "Train loss: 1.8149374275450494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9346731878389978\n",
      "Train loss: 1.5430769199019025\n",
      "Train loss: 1.4607565668737812\n",
      "Train loss: 1.393643997277424\n",
      "Train loss: 1.3211874517665547\n",
      "Train loss: 0.921329250381251\n",
      "Train loss: 0.9669004671133248\n",
      "Train loss: 0.9917047209800429\n",
      "Train loss: 0.7282513793866345\n",
      "Train loss: 1.0467327958459307\n",
      "Train loss: 0.5617396865680719\n",
      "Train loss: 0.876054488929214\n",
      "Train loss: 0.6982500355714446\n",
      "\n",
      "Test set: Avg. loss: 0.00039860232174396515, AUC: 0.9290079999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047183363139629365, AUC: 0.937491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00032021838426589963, AUC: 0.948357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006923727095127105, AUC: 0.5628065\n",
      "\n",
      "Train loss: 1.5512303265796346\n",
      "Train loss: 1.2353783249855042\n",
      "Train loss: 1.1475682938174836\n",
      "Train loss: 1.4969956195278533\n",
      "Train loss: 0.979395692515525\n",
      "Train loss: 1.053526867726806\n",
      "Train loss: 0.7830445409580401\n",
      "Train loss: 0.7794080646174728\n",
      "Train loss: 0.9118682161258285\n",
      "Train loss: 0.7145632490230973\n",
      "Train loss: 0.9021045573198112\n",
      "Train loss: 0.6404331132864497\n",
      "Train loss: 0.5584030967609138\n",
      "Train loss: 0.7357639848806297\n",
      "Train loss: 0.4938939783223875\n",
      "\n",
      "Test set: Avg. loss: 0.0003621644228696823, AUC: 0.934321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037211982905864717, AUC: 0.93608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003810114860534668, AUC: 0.941255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943982541561126, AUC: 0.56987\n",
      "\n",
      "Train loss: 1.6806978336565055\n",
      "Train loss: 1.7956415847608238\n",
      "Train loss: 1.5534688940473422\n",
      "Train loss: 1.389758839728726\n",
      "Train loss: 1.3698183427191084\n",
      "Train loss: 0.8360725580507024\n",
      "Train loss: 1.1988897866504207\n",
      "Train loss: 0.9091258352729166\n",
      "Train loss: 1.045509720683857\n",
      "Train loss: 0.7474547100674575\n",
      "Train loss: 1.0273564533822854\n",
      "Train loss: 0.6318259064558964\n",
      "Train loss: 0.5475991782109448\n",
      "Train loss: 0.818452742828685\n",
      "Train loss: 0.627023975940267\n",
      "\n",
      "Test set: Avg. loss: 0.0004389137625694275, AUC: 0.9327400000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003822837918996811, AUC: 0.946448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003276159167289734, AUC: 0.951301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927377581596374, AUC: 0.574253\n",
      "\n",
      "Train loss: 1.5772852950794682\n",
      "Train loss: 1.4025484095713137\n",
      "Train loss: 1.0292934209677824\n",
      "Train loss: 1.5213698274011065\n",
      "Train loss: 0.6666313500920679\n",
      "Train loss: 0.7515288648332\n",
      "Train loss: 0.6539147727808375\n",
      "Train loss: 0.7053451397616393\n",
      "Train loss: 0.6444514397602932\n",
      "Train loss: 0.7410922954036931\n",
      "Train loss: 0.7267304210905816\n",
      "Train loss: 0.5181050441067689\n",
      "Train loss: 0.375660929330595\n",
      "Train loss: 0.4891196352661036\n",
      "Train loss: 0.5434732213141812\n",
      "\n",
      "Test set: Avg. loss: 0.0003837060332298279, AUC: 0.936681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003397395610809326, AUC: 0.946446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042534206807613375, AUC: 0.9451959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006931170523166657, AUC: 0.5075235\n",
      "\n",
      "Train loss: 2.0237746056477737\n",
      "Train loss: 1.169994580897556\n",
      "Train loss: 1.530900303345577\n",
      "Train loss: 1.593341377890034\n",
      "Train loss: 1.4924902593254283\n",
      "Train loss: 0.9746312905269064\n",
      "Train loss: 1.018703309973334\n",
      "Train loss: 1.0353986256441492\n",
      "Train loss: 0.9771102123959049\n",
      "Train loss: 0.7796362034834114\n",
      "Train loss: 0.4925922064264868\n",
      "Train loss: 0.7538846028838188\n",
      "Train loss: 0.6389873692184497\n",
      "Train loss: 0.5430046456634618\n",
      "Train loss: 0.5402585753969326\n",
      "\n",
      "Test set: Avg. loss: 0.00037191537022590636, AUC: 0.932969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003247491419315338, AUC: 0.9419019999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003453776389360428, AUC: 0.9490419999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007015862166881562, AUC: 0.3505795\n",
      "\n",
      "Train loss: 3.9646280768570628\n",
      "Train loss: 3.3033991725581466\n",
      "Train loss: 2.5725907102511947\n",
      "Train loss: 1.376922410005217\n",
      "Train loss: 1.9258307036320874\n",
      "Train loss: 1.2071792749082966\n",
      "Train loss: 1.3905717703946836\n",
      "Train loss: 1.1171147922042068\n",
      "Train loss: 1.085816380324637\n",
      "Train loss: 1.1823566867287751\n",
      "Train loss: 1.0678503915762445\n",
      "Train loss: 0.7482025319603598\n",
      "Train loss: 0.6341669468363379\n",
      "Train loss: 1.255767916418185\n",
      "Train loss: 0.7214999483649138\n",
      "\n",
      "Test set: Avg. loss: 0.00038818895816802976, AUC: 0.932067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035361112654209135, AUC: 0.9387269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044564680755138395, AUC: 0.9421510000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 class triplet loss no ratio \n",
    "# no smote \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 1e-2), (1e-6, 5e-3), (1e-6, 1e-2), (5e-6, 5e-2)]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10): \n",
    "        model_aucs = []\n",
    "        embed_network = models.ConvNetOnlyEmbeddingsEarly(2)\n",
    "        linear_probe = models.ConvNetLinearProbeEarly(2)\n",
    "        complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "        embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "        linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(15):\n",
    "            _, train_losses = train.train_triplet_loss(epoch, train_loader_tripletloss, embed_network, embed_optimizer, verbose=False)\n",
    "            print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced, complete_network, linear_optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "    \n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss\", 2, nums, (1, 1), learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, None]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae64538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65cd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb40fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

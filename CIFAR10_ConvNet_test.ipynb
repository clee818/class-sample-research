{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c3c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "378c3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import class_sampling\n",
    "import train\n",
    "import metric_utils\n",
    "import inference\n",
    "import loss_fns\n",
    "import torchvision.ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91dda12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "n_epochs = 30\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "momentum = 0\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "nums = (0, 1)\n",
    "ratio = (10, 1)\n",
    "\n",
    "CLASS_LABELS = {'airplane': 0,\n",
    "                 'automobile': 1,\n",
    "                 'bird': 2,\n",
    "                 'cat': 3,\n",
    "                 'deer': 4,\n",
    "                 'dog': 5,\n",
    "                 'frog': 6,\n",
    "                 'horse': 7,\n",
    "                 'ship': 8,\n",
    "                 'truck': 9}\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b57e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"name\", \n",
    "            \"num_classes\", \n",
    "            \"classes_used\", \n",
    "            \"ratio\", \n",
    "            \"learning_rate\", \n",
    "            \"mean_0\", \"variance_0\",\n",
    "            \"mean_10\", \"variance_10\",\n",
    "            \"mean_20\", \"variance_20\",\n",
    "            \"mean_30\", \"variance_30\",\n",
    "            \"mean_40\", \"variance_40\",\n",
    "            \"mean_50\", \"variance_50\"]\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c2a1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor() ]))  \n",
    "\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()]))\n",
    "\n",
    "train_CIFAR10.data = train_CIFAR10.data.reshape(50000, 3, 32, 32)\n",
    "test_CIFAR10.data = test_CIFAR10.data.reshape(10000, 3, 32, 32)\n",
    "\n",
    "    \n",
    "reduced_train_CIFAR10 = class_sampling.Reduce(train_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "reduced_test_CIFAR10 = class_sampling.Reduce(test_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "\n",
    "ratio_train_CIFAR10 = class_sampling.Ratio(train_CIFAR10, NUM_CLASSES_REDUCED, ratio, nums=nums)\n",
    "\n",
    "smote_train_CIFAR10 = class_sampling.Smote(ratio_train_CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13159c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000  500]\n"
     ]
    }
   ],
   "source": [
    "targets = ratio_train_CIFAR10.labels \n",
    "\n",
    "class_count = np.unique(targets, return_counts=True)[1]\n",
    "print(class_count)\n",
    "\n",
    "weight = 1. / class_count\n",
    "\n",
    "samples_weight = weight[targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "oversampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(max(class_count) * NUM_CLASSES_REDUCED), replacement=True)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "undersampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * NUM_CLASSES_REDUCED), replacement=False)\n",
    "\n",
    "weight *= class_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de0d4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.999 \n",
    "\n",
    "exp = np.empty_like(targets)\n",
    "for i, count in enumerate(class_count):\n",
    "    exp[targets==i] = count\n",
    "effective_weights = (1 - beta) / ( 1 - (beta ** torch.from_numpy(exp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af8cd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_reduced = DataLoader(reduced_train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_ratio = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True) \n",
    "\n",
    "train_loader_oversampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=oversampler)\n",
    "\n",
    "train_loader_undersampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler)\n",
    "\n",
    "train_loader_sampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=sampler)\n",
    "\n",
    "train_loader_smote = DataLoader(smote_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_CIFAR10, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2e8c09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.001968830943107605, AUC: 0.6361665000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006069920063018799, AUC: 0.8331379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005906819999217987, AUC: 0.849458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005717484056949615, AUC: 0.8692640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032240989208221437, AUC: 0.38664699999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006730922758579254, AUC: 0.7028579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000657876968383789, AUC: 0.7713125000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006426167488098144, AUC: 0.808087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006873347997665405, AUC: 0.683021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006474375724792481, AUC: 0.7793890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006305342614650727, AUC: 0.8076369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000615574598312378, AUC: 0.8379340000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001451125681400299, AUC: 0.47390000000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006873179376125335, AUC: 0.5776140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006742987930774689, AUC: 0.676213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006587418317794799, AUC: 0.7383755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031172895431518556, AUC: 0.6896909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006556805670261383, AUC: 0.757577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006247638761997223, AUC: 0.8323059999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006041210293769836, AUC: 0.862076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00219118869304657, AUC: 0.37103100000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006376471817493438, AUC: 0.805021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000608339935541153, AUC: 0.8574674999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006034740805625915, AUC: 0.861424\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006955941677093506, AUC: 0.3322345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006609889268875122, AUC: 0.7414850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006305978298187256, AUC: 0.831365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006132065653800964, AUC: 0.8642630000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028511343002319335, AUC: 0.5939905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00065874445438385, AUC: 0.731923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000620471715927124, AUC: 0.8265395000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006020828485488891, AUC: 0.846889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011438738107681274, AUC: 0.351393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006393368542194366, AUC: 0.7908980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006147348880767823, AUC: 0.8411289999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005975831151008606, AUC: 0.865934\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015125332474708558, AUC: 0.429251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000645305722951889, AUC: 0.7892769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006194020509719849, AUC: 0.844831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000601188451051712, AUC: 0.8644035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034982739686965944, AUC: 0.618384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948932111263275, AUC: 0.4956195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943435370922089, AUC: 0.503277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947636008262635, AUC: 0.5074799999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011465153098106384, AUC: 0.401948\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006497133374214172, AUC: 0.7740210000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006439555287361146, AUC: 0.7921309999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006383517682552337, AUC: 0.8043595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009435354471206665, AUC: 0.577937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928209662437439, AUC: 0.5298780000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006930986940860748, AUC: 0.5251235000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006926796138286591, AUC: 0.5264059999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029533997774124146, AUC: 0.545541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006961712837219239, AUC: 0.44664399999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943851709365845, AUC: 0.47570900000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939733624458313, AUC: 0.48324599999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038374502658843996, AUC: 0.565988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000691389799118042, AUC: 0.527829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006898206174373627, AUC: 0.5408085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006897935867309571, AUC: 0.5353799999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001448841392993927, AUC: 0.5810709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006542717218399048, AUC: 0.636595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000657597154378891, AUC: 0.6381175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006585783958435058, AUC: 0.6478995000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004549663305282592, AUC: 0.44000300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006643029153347016, AUC: 0.663438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000662208467721939, AUC: 0.6842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006584835946559906, AUC: 0.7039535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028102716207504272, AUC: 0.5378565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006754246056079865, AUC: 0.6442350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006785540282726288, AUC: 0.629072\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006808497309684754, AUC: 0.6244835000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018956378698349, AUC: 0.37419199999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006581393480300903, AUC: 0.716816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006612205505371094, AUC: 0.72021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006608555614948273, AUC: 0.726656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001775826096534729, AUC: 0.554507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000690640389919281, AUC: 0.5437550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006901929378509521, AUC: 0.5524899999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006903409361839294, AUC: 0.5511579999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS normal\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"normal\", 2, nums, (1, 1), learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8f1d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "\n",
    "df2.to_csv('results/convnet_aucs.csv', index=False)\n",
    "\n",
    "rows = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d211694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0019287337064743042, AUC: 0.518386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008795691728591919, AUC: 0.725559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007942625284194946, AUC: 0.7863410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007645726501941681, AUC: 0.8171459999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018440639972686767, AUC: 0.5057195000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009616871476173401, AUC: 0.647203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008821539282798767, AUC: 0.760052\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008314119577407837, AUC: 0.798547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011216624975204468, AUC: 0.4446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001142448902130127, AUC: 0.577028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009208276271820069, AUC: 0.749444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000837091475725174, AUC: 0.7970310000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019242210388183594, AUC: 0.582731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00100971981883049, AUC: 0.71405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009351155459880829, AUC: 0.8056760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008753396570682526, AUC: 0.840365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003556872844696045, AUC: 0.656805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011100462079048157, AUC: 0.5719240000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010035705268383027, AUC: 0.6453800000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009386559128761291, AUC: 0.696754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0062002427577972415, AUC: 0.4525135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008204956352710724, AUC: 0.8476659999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007336184084415436, AUC: 0.8675160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007888570725917817, AUC: 0.8771519999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026351059675216674, AUC: 0.5353920000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009317352175712586, AUC: 0.696983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009735948145389556, AUC: 0.7619659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008260755240917206, AUC: 0.7914365000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005974612236022949, AUC: 0.402112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008482859432697296, AUC: 0.7745409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007704689502716065, AUC: 0.8148815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007168322205543518, AUC: 0.842272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001425521731376648, AUC: 0.38954150000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010613923668861389, AUC: 0.597288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008902808427810669, AUC: 0.69229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008396327495574952, AUC: 0.7658069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010539151430130004, AUC: 0.487208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010086527168750763, AUC: 0.750396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009000113010406494, AUC: 0.823762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008028844594955444, AUC: 0.8524640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033204582929611207, AUC: 0.63371\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001395082414150238, AUC: 0.512145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001128212094306946, AUC: 0.48929900000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001079081952571869, AUC: 0.5123150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00566118597984314, AUC: 0.353908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001467447817325592, AUC: 0.436095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013474002480506897, AUC: 0.41431399999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013370943069458009, AUC: 0.42828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031351207494735717, AUC: 0.6227159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016077346801757814, AUC: 0.5227120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011952120661735534, AUC: 0.4669789999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011611527800559998, AUC: 0.4775355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01569214391708374, AUC: 0.4880455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010710386037826537, AUC: 0.633591\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00110848605632782, AUC: 0.647265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001070758819580078, AUC: 0.6537629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003577275276184082, AUC: 0.689155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012243158221244812, AUC: 0.49310699999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012612117528915405, AUC: 0.521293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012297061681747436, AUC: 0.5319969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009256422519683838, AUC: 0.695103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011287822127342224, AUC: 0.495583\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010635228157043458, AUC: 0.563889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010183742046356201, AUC: 0.600632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010769194960594177, AUC: 0.23907699999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011006176471710205, AUC: 0.249223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010621642470359802, AUC: 0.26575099999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010518187284469605, AUC: 0.285358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002513558030128479, AUC: 0.6506315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010019059181213378, AUC: 0.530259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009830892980098723, AUC: 0.561979\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010111158192157746, AUC: 0.5980730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004909023761749267, AUC: 0.439878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010973649621009826, AUC: 0.409358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011081650257110595, AUC: 0.43439900000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010390030145645142, AUC: 0.45061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031085087060928347, AUC: 0.482744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011582040786743163, AUC: 0.6215040000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009333357810974121, AUC: 0.7070970000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008785418570041657, AUC: 0.7413559999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS ratio\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"ratio\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f2d0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f1ccb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0048054039478302, AUC: 0.551255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006570699214935303, AUC: 0.7241254999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006405693292617797, AUC: 0.7878685000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006275400221347809, AUC: 0.816168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015801175236701966, AUC: 0.7138960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006501563191413879, AUC: 0.7620300000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006346423923969268, AUC: 0.8019250000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006165396571159362, AUC: 0.8341529999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012231424450874328, AUC: 0.462604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006932708323001862, AUC: 0.4976065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929941773414612, AUC: 0.519285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000692833960056305, AUC: 0.505828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002317346930503845, AUC: 0.502827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949883997440338, AUC: 0.505665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948157250881195, AUC: 0.5026390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00069463711977005, AUC: 0.50394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009575898349285126, AUC: 0.5360959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000674715906381607, AUC: 0.632713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006511662304401397, AUC: 0.7184265000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006349144577980041, AUC: 0.786098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008235736846923828, AUC: 0.579893\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940934956073761, AUC: 0.5217529999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929182708263397, AUC: 0.532355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000691540002822876, AUC: 0.545363\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008327553868293762, AUC: 0.4560445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006918579638004303, AUC: 0.5085040000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006906694173812866, AUC: 0.5156299999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006897843480110168, AUC: 0.5290985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005272605657577515, AUC: 0.407359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006434414982795715, AUC: 0.748295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006286364495754242, AUC: 0.8078069999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006140626072883606, AUC: 0.845544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037665776014328004, AUC: 0.46347900000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000642070472240448, AUC: 0.809005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006241906881332398, AUC: 0.8379905000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00061829474568367, AUC: 0.8518555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009316586852073669, AUC: 0.47467400000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006898859739303589, AUC: 0.548491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006880662739276886, AUC: 0.564532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006829023957252502, AUC: 0.6036849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027361745834350586, AUC: 0.6254919999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006965326070785523, AUC: 0.539657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006966829895973205, AUC: 0.5162884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006950580775737762, AUC: 0.518446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003271787881851196, AUC: 0.457588\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006548132002353668, AUC: 0.7300375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006526409089565277, AUC: 0.7422765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006494028270244599, AUC: 0.7518045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020445635318756105, AUC: 0.650805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006888214647769928, AUC: 0.5303635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000690723329782486, AUC: 0.50243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006915560066699982, AUC: 0.5153615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009663238227367401, AUC: 0.47497500000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006581699550151825, AUC: 0.7718635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006534149944782257, AUC: 0.7934605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006482869684696198, AUC: 0.8130325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033157585859298704, AUC: 0.44732250000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006804988980293274, AUC: 0.628576\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006787542402744293, AUC: 0.6507404999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006762158870697022, AUC: 0.669156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003072745680809021, AUC: 0.601865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006713438630104065, AUC: 0.673267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006634836792945862, AUC: 0.7162535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006630164682865143, AUC: 0.7243795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008662566840648651, AUC: 0.656558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006930959224700927, AUC: 0.5625155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006945942044258118, AUC: 0.5462750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947198510169983, AUC: 0.537718\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004846441984176636, AUC: 0.5105249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000686543196439743, AUC: 0.6044569999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006824942529201507, AUC: 0.6379915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00067613884806633, AUC: 0.6749769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012209251523017882, AUC: 0.488597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006689891517162323, AUC: 0.7038009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006685732007026673, AUC: 0.7152700000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006675445437431336, AUC: 0.7303765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033155608177185057, AUC: 0.449008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006651174128055572, AUC: 0.652861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000660489022731781, AUC: 0.6839485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006541801393032074, AUC: 0.716063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS oversampled\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_oversampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"oversampled\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52d8c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1541b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.001361272394657135, AUC: 0.5182420000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006831247210502625, AUC: 0.6231269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006858513355255127, AUC: 0.6093769999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006839762032032013, AUC: 0.6354010000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014974244236946107, AUC: 0.397626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006841929852962493, AUC: 0.634284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000684006541967392, AUC: 0.635391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006836210787296295, AUC: 0.6420640000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029681077003479005, AUC: 0.438403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006588656306266785, AUC: 0.7569130000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006624727547168732, AUC: 0.750571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006612907946109772, AUC: 0.754692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009737875759601593, AUC: 0.42999649999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006970759928226471, AUC: 0.4916975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006920590996742249, AUC: 0.5131445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000687617301940918, AUC: 0.553855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008843773901462555, AUC: 0.497519\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006982818841934204, AUC: 0.49997549999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947401463985443, AUC: 0.504527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928717195987702, AUC: 0.5446394999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001415677011013031, AUC: 0.48061000000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006958563029766082, AUC: 0.54859\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006918881833553314, AUC: 0.566136\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006896842122077942, AUC: 0.58399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020146266222000123, AUC: 0.66783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007138862013816833, AUC: 0.46958500000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007063101828098297, AUC: 0.422504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007010048627853393, AUC: 0.4410935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014596596360206605, AUC: 0.539736\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007084104120731354, AUC: 0.508765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949602663516998, AUC: 0.5146\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006925133168697357, AUC: 0.521466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013158952593803406, AUC: 0.610526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006726030707359314, AUC: 0.6443949999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006778903305530548, AUC: 0.6206250000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006790605485439301, AUC: 0.6169750000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030114359855651857, AUC: 0.579712\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007215091288089753, AUC: 0.381967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007094234526157379, AUC: 0.38871700000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007051526308059692, AUC: 0.4019635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008286267518997192, AUC: 0.551199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007626483738422394, AUC: 0.5600229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007362492382526397, AUC: 0.565554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000717087209224701, AUC: 0.5753820000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004645004272460938, AUC: 0.627536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008760614693164825, AUC: 0.5097849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007608487308025361, AUC: 0.499498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000731224775314331, AUC: 0.49960299999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001717905879020691, AUC: 0.441381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008845820426940918, AUC: 0.6047855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007441193461418152, AUC: 0.584798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000700938642024994, AUC: 0.584684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001236832320690155, AUC: 0.4199155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007399575114250183, AUC: 0.5130060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007057792246341706, AUC: 0.5663545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006923246383666993, AUC: 0.5832390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009195330619812012, AUC: 0.364335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007889335751533509, AUC: 0.5389280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006870189905166626, AUC: 0.6043700000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006651701629161834, AUC: 0.654963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003628037929534912, AUC: 0.5153405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929788887500763, AUC: 0.635454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007086754143238068, AUC: 0.557117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006995063722133637, AUC: 0.532604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017299602031707764, AUC: 0.282003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009491462409496307, AUC: 0.372102\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008179627060890198, AUC: 0.352089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007747058868408203, AUC: 0.3362485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009424748718738556, AUC: 0.4566255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009278880655765534, AUC: 0.569231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007582923173904419, AUC: 0.582056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000712300181388855, AUC: 0.582969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008618786633014678, AUC: 0.538937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00083674156665802, AUC: 0.635061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007425586581230163, AUC: 0.5876399999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007133866250514984, AUC: 0.580888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018825936317443848, AUC: 0.357349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007808814942836761, AUC: 0.479167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007086372375488281, AUC: 0.5341195000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00069071826338768, AUC: 0.5762390000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS undersampled\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_undersampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"undersampled\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9eed2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7c5a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00392682933807373, AUC: 0.608166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006436906456947326, AUC: 0.7887475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006319799125194549, AUC: 0.8360875000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006192918419837952, AUC: 0.8520330000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008545547127723694, AUC: 0.590994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006431725919246674, AUC: 0.780115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006292569637298584, AUC: 0.8135020000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006201825439929962, AUC: 0.8270049999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013260830402374267, AUC: 0.45235649999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006229948401451111, AUC: 0.803364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006227455139160156, AUC: 0.8083864999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000606639415025711, AUC: 0.822162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028494004011154176, AUC: 0.497351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006307647228240967, AUC: 0.7854829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006063108146190644, AUC: 0.823493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005951615273952484, AUC: 0.8432499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009267190098762512, AUC: 0.625533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005391398966312408, AUC: 0.835958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005140160918235779, AUC: 0.854081\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000506060004234314, AUC: 0.863858\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005952283620834351, AUC: 0.6057669999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006916028261184692, AUC: 0.550143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006842453181743622, AUC: 0.625521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006509733200073242, AUC: 0.8006925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014545314311981202, AUC: 0.505441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006235511898994446, AUC: 0.8198730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006205186545848847, AUC: 0.8259219999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006224922239780426, AUC: 0.822631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010346195697784424, AUC: 0.39435400000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943635940551757, AUC: 0.496475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006941328942775726, AUC: 0.49899399999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940026879310608, AUC: 0.498518\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00434240198135376, AUC: 0.625289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006944181621074677, AUC: 0.487479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939679086208344, AUC: 0.48753900000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006937822997570038, AUC: 0.4890425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014699572920799256, AUC: 0.47559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006334327757358551, AUC: 0.783369\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006292214095592499, AUC: 0.8088734999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006151509284973145, AUC: 0.8276629999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001209519326686859, AUC: 0.44195700000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006806661486625672, AUC: 0.618737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000674956738948822, AUC: 0.662876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006676428020000458, AUC: 0.7060945000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004880978107452393, AUC: 0.465984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006632062196731568, AUC: 0.6847675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006526895761489868, AUC: 0.74197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006448651850223541, AUC: 0.76981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005944673538208008, AUC: 0.639527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006231625676155091, AUC: 0.7393459999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006222508549690247, AUC: 0.75784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006199325025081635, AUC: 0.7786535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012202975749969482, AUC: 0.6109345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006518029272556305, AUC: 0.7442000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006481515467166901, AUC: 0.75189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006438162922859192, AUC: 0.7607395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003775996685028076, AUC: 0.36967249999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006586503684520721, AUC: 0.698742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006548727750778198, AUC: 0.7207215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006515067219734191, AUC: 0.736803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003638801574707031, AUC: 0.43072900000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006984515190124512, AUC: 0.4740594999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006970266699790954, AUC: 0.4772960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006963912844657898, AUC: 0.4927230000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033344231843948366, AUC: 0.617663\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006587540507316589, AUC: 0.6797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006516081690788269, AUC: 0.7191069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006474694907665253, AUC: 0.7437205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020451717376708985, AUC: 0.42892\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006481530964374542, AUC: 0.6747685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006400389075279236, AUC: 0.715742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006335148215293884, AUC: 0.7436480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008710843026638031, AUC: 0.534767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006471023857593536, AUC: 0.7043879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006376094818115234, AUC: 0.7413759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006341409981250763, AUC: 0.757341\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002445031523704529, AUC: 0.405818\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006528952121734619, AUC: 0.7163275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006481814086437225, AUC: 0.7578965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000641876220703125, AUC: 0.7683315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS SMOTE\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_smote, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edcf4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "563f22d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0016703126430511475, AUC: 0.502707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008640770018100739, AUC: 0.4535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008134927153587341, AUC: 0.5995950000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000739108681678772, AUC: 0.6680075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00121213698387146, AUC: 0.44127250000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008791627585887909, AUC: 0.427161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008808626532554627, AUC: 0.4839875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008660988509654999, AUC: 0.5037349999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019614633321762085, AUC: 0.47862899999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009047038555145264, AUC: 0.42100249999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008650421500205994, AUC: 0.4492385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008351796269416809, AUC: 0.48053500000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024454493522644044, AUC: 0.46927300000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008800350725650788, AUC: 0.52539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007984228134155273, AUC: 0.549548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007786697447299957, AUC: 0.5539689999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001660624325275421, AUC: 0.35707300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001068075180053711, AUC: 0.388455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009706946015357971, AUC: 0.435289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009020018577575684, AUC: 0.46044399999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011947511434555055, AUC: 0.521147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010468592643737792, AUC: 0.42102699999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009510384500026703, AUC: 0.45357600000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008952549397945404, AUC: 0.507124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011255061626434327, AUC: 0.46537649999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000985347092151642, AUC: 0.501829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008923705220222473, AUC: 0.586878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008447875380516053, AUC: 0.664131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014675825834274292, AUC: 0.669159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008684511482715606, AUC: 0.47710949999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000777911365032196, AUC: 0.4947245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007632842361927032, AUC: 0.517747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002308388710021973, AUC: 0.504496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007785505652427673, AUC: 0.701813\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007503507137298584, AUC: 0.703748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007347195744514466, AUC: 0.7021850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010729927420616149, AUC: 0.45661799999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001016470193862915, AUC: 0.457384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009469316601753235, AUC: 0.55109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009142382740974426, AUC: 0.5976515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011306936740875245, AUC: 0.473933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012058745622634888, AUC: 0.45248199999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011811978220939636, AUC: 0.4342285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001152018427848816, AUC: 0.43963599999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026148154735565186, AUC: 0.6901600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029031620025634767, AUC: 0.708366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014518088698387147, AUC: 0.648581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010919058918952942, AUC: 0.61409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007521816968917847, AUC: 0.66364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038151946067810057, AUC: 0.5308630000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016146827340126038, AUC: 0.399938\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001281152606010437, AUC: 0.374827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009335494637489319, AUC: 0.638177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014621745347976685, AUC: 0.551572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009599381685256958, AUC: 0.45358099999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009225580990314484, AUC: 0.44168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004014822483062744, AUC: 0.331642\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007824084460735321, AUC: 0.471691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008029072284698487, AUC: 0.524219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008069021701812744, AUC: 0.526386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001401176393032074, AUC: 0.540603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011434717178344727, AUC: 0.462675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009721387326717376, AUC: 0.41912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009681347608566284, AUC: 0.42538000000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001643649935722351, AUC: 0.63566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012423597574234009, AUC: 0.566494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009369251132011414, AUC: 0.542745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008797657787799836, AUC: 0.55058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021847230195999145, AUC: 0.522699\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003505303621292114, AUC: 0.5491440000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018441606760025025, AUC: 0.46433399999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013028420209884645, AUC: 0.40884600000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013823137283325195, AUC: 0.39950399999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00349859356880188, AUC: 0.49138999999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016547440886497497, AUC: 0.304848\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011019692420959472, AUC: 0.312974\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034349721670150755, AUC: 0.480804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006857394456863403, AUC: 0.6039650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041930356025695805, AUC: 0.552071\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002709782361984253, AUC: 0.495128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 CLASS Focal Loss\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "loss_fn_args = {}\n",
    "loss_fn_args['reduction'] = 'mean'\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.ConvNet(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, network, optimizer, verbose=False, loss_fn=loss_fns.SigmoidFocalLoss, loss_fn_args=loss_fn_args)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"focal_loss\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d438d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names[0:13]) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_aucs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9c9d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>classes_used</th>\n",
       "      <th>ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>variance_0</th>\n",
       "      <th>mean_10</th>\n",
       "      <th>variance_10</th>\n",
       "      <th>mean_20</th>\n",
       "      <th>variance_20</th>\n",
       "      <th>mean_30</th>\n",
       "      <th>variance_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal_loss</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.486575</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.477467</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.565553</td>\n",
       "      <td>0.006784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal_loss</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(10, 1)</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.537682</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>0.538864</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.474367</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.458953</td>\n",
       "      <td>0.007102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  num_classes classes_used    ratio  learning_rate    mean_0  \\\n",
       "0  focal_loss            2       (0, 1)  (10, 1)        0.00010  0.486575   \n",
       "1  focal_loss            2       (0, 1)  (10, 1)        0.00001  0.537682   \n",
       "\n",
       "   variance_0   mean_10  variance_10   mean_20  variance_20   mean_30  \\\n",
       "0    0.005565  0.477467     0.007103  0.530767     0.006378  0.565553   \n",
       "1    0.012789  0.538864     0.005410  0.474367     0.008302  0.458953   \n",
       "\n",
       "   variance_30  \n",
       "0     0.006784  \n",
       "1     0.007102  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1dd64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c1e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4998b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

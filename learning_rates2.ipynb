{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f98900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9287bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import class_sampling\n",
    "import train\n",
    "import metric_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f74638",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "n_epochs = 20\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "momentum = 0.5\n",
    "\n",
    "ratio = (100, 1)\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "nums = (6, 8)\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6889203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = torchvision.datasets.MNIST('mnist', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor() ]))\n",
    "                             \n",
    "\n",
    "\n",
    "test_mnist = torchvision.datasets.MNIST('mnist', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor() ]))\n",
    "                             \n",
    "                            \n",
    "\n",
    "reduced_train_mnist = class_sampling.Reduce(train_mnist, NUM_CLASSES_REDUCED, nums=nums)\n",
    "reduced_test_mnist = class_sampling.Reduce(test_mnist, NUM_CLASSES_REDUCED, nums=nums)\n",
    "\n",
    "\n",
    "reduced_train_mnist_ratio = class_sampling.BinaryRatio(train_mnist, 2, ratio, nums=nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4cff2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_reduced = DataLoader(reduced_train_mnist, batch_size=batch_size_train, shuffle=False) \n",
    "train_loader_reduced_ratio = DataLoader(reduced_train_mnist_ratio, batch_size=batch_size_train, shuffle=False)\n",
    "train_loader_normal = DataLoader(train_mnist, batch_size=batch_size_train, shuffle=False)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_mnist, batch_size=batch_size_test, shuffle=False) \n",
    "test_loader_normal = DataLoader(test_mnist, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4911fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.022128139716991478, AUC: 0.4259660355034659\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04033211496799382, AUC: 0.5191803166247272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043917573016622795, AUC: 0.5174253985673438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04541367872407964, AUC: 0.5122774603147384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045970036129526964, AUC: 0.5130174730894703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04626579561095307, AUC: 0.5101474452679907\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046569111431113926, AUC: 0.5094026098176814\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04679030858705256, AUC: 0.5121338517530962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04698643773238852, AUC: 0.5122924641943131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04714291337607564, AUC: 0.5139059171014219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04730513475943303, AUC: 0.5132066291426783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0474383608895059, AUC: 0.5166682385016697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04755849423615829, AUC: 0.5177560197708264\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04762760107068048, AUC: 0.5177067213093671\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0476365513929916, AUC: 0.518720554886335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04760954049309835, AUC: 0.5197183128780442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04757185949795488, AUC: 0.5199481937472403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04751933435475604, AUC: 0.520553171605801\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047466852650138905, AUC: 0.5207557239800576\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04739252133892683, AUC: 0.5206624855855585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04732212911728253, AUC: 0.5216425604334836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047251804027991756, AUC: 0.5219399587607653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047181771161886966, AUC: 0.5232645869860636\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047123136974516366, AUC: 0.5238856404298825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047048975468669124, AUC: 0.5259931496572686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047015174328663825, AUC: 0.5258098879853219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04697812911639796, AUC: 0.5271012933344194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046966268409112964, AUC: 0.5275594475142859\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04695889964607192, AUC: 0.5276312517951071\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04694765102789269, AUC: 0.528074402095399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469440910386743, AUC: 0.5281451346705363\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04694145115759556, AUC: 0.5282019350717828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046939423365622575, AUC: 0.528263022295765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693781811258067, AUC: 0.5283123207572245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693652087857264, AUC: 0.5283509021618447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693545268435903, AUC: 0.5283884118607811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046934566142396154, AUC: 0.5284205630312981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693381386514036, AUC: 0.528452714201815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693318005674374, AUC: 0.5284880804893837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693263115102954, AUC: 0.5285213033655844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046932161224554785, AUC: 0.5285459525963142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469317544814716, AUC: 0.5285716735327277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693140499833701, AUC: 0.5286038247032447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046931096979303144, AUC: 0.5286306173453421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04693083239885097, AUC: 0.5286488363419685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692476284429894, AUC: 0.5290555486490078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046924553549314386, AUC: 0.5290834129967893\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046924375846025615, AUC: 0.5291048471104672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692421591306572, AUC: 0.5291316397525646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692408362283963, AUC: 0.5291477153378231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692396317949946, AUC: 0.5291648626287655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692386840441212, AUC: 0.5291884401538113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04692378152724872, AUC: 0.5292023723277018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691745134120649, AUC: 0.529602654400638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046917390132295914, AUC: 0.5296219451029482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691734471923323, AUC: 0.5296433792166261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691730917857547, AUC: 0.5296615982132524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691727956136068, AUC: 0.5296841040326142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691725784206983, AUC: 0.5296948210894532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691724796966489, AUC: 0.5297087532633439\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691724796966489, AUC: 0.5297141117917634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691725586758884, AUC: 0.5297323307883895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691100071182409, AUC: 0.5301304694499578\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691101058422902, AUC: 0.5301519035636357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691102243111494, AUC: 0.5301711942659459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691104415040579, AUC: 0.530190484968256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691106981865861, AUC: 0.5302054888478307\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691109746139242, AUC: 0.5302237078444569\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691113497653116, AUC: 0.5302301380785603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691117051718892, AUC: 0.5302472853695027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691121198128963, AUC: 0.5302633609547612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691125739435231, AUC: 0.5302719346002324\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046911306756376975, AUC: 0.530285866774123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691135611840163, AUC: 0.530296583830962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691141337835024, AUC: 0.5303040857707494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691147261277983, AUC: 0.5303158745332721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469115338216904, AUC: 0.5303276632957952\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691159108163901, AUC: 0.5303362369412662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469116503160686, AUC: 0.530348025703789\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691171744842213, AUC: 0.530360886171996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691177865733271, AUC: 0.5303673164060992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046911853687610194, AUC: 0.5303769617572545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469119247689257, AUC: 0.530390893931145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691199190127924, AUC: 0.5304058978107197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691207088051869, AUC: 0.5304262602187138\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0469121419618342, AUC: 0.5304369772755528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046912220941073654, AUC: 0.5304412640982883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691229202238916, AUC: 0.5304455509210239\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046912374950590585, AUC: 0.5304519811551274\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691245195534906, AUC: 0.5304541245664951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691253290906949, AUC: 0.5304659133290179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046912615837270924, AUC: 0.5304723435631213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691269679099136, AUC: 0.530486275737012\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691277971919279, AUC: 0.530498600352377\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691286067291323, AUC: 0.5305119966734256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046912945575595645, AUC: 0.530518426907529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691303442724003, AUC: 0.5305248571416324\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691311538096047, AUC: 0.5305377176098391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691320225812387, AUC: 0.5305441478439427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046913289135287264, AUC: 0.530550578078046\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04691337996141264, AUC: 0.5305580800178333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03785119540449502, AUC: 0.24150566074942237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0482120889067403, AUC: 0.3936739356890853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049170523696804636, AUC: 0.4136130199380126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049467363219330276, AUC: 0.41493764816331075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049643873921585875, AUC: 0.41826797357602474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04977568632327251, AUC: 0.4216926090889216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049869602511388174, AUC: 0.42616269349646124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04995185938927944, AUC: 0.426701761455462\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04998813060499867, AUC: 0.4264381218572231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05000359671456473, AUC: 0.4264692013220562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05001510991319613, AUC: 0.42740158526704763\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050035984126183805, AUC: 0.4271197266721824\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05004939875000505, AUC: 0.42676016941523454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05005594217999381, AUC: 0.4272172518894171\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050067510664092825, AUC: 0.4268485851341561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05007845916116213, AUC: 0.42649170714141793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050083063650822296, AUC: 0.4269584349667556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05009890293729478, AUC: 0.42621788633918195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050102739353851254, AUC: 0.42622967510170484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05010630724099359, AUC: 0.4262339619244404\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.050109632266974596, AUC: 0.4262361053358082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05011276181933796, AUC: 0.42624896580401495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05011570577048861, AUC: 0.4262521809210666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05011850163556528, AUC: 0.42625325262675057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050121151389048955, AUC: 0.42625325262675057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05012367280126852, AUC: 0.42671783704072047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05012607377014792, AUC: 0.42671890874640434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05012837798945899, AUC: 0.42672855409755944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050130585459201724, AUC: 0.42718670827742594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050132702102819095, AUC: 0.42810194493147513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050134743716158975, AUC: 0.42902039670257597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05013670437577842, AUC: 0.42902468352531153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050138605800968274, AUC: 0.42902254011394375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05014626876167629, AUC: 0.42864583556605357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05014802210079217, AUC: 0.4291077407158137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050149726077883386, AUC: 0.42910881242149757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050151374769506984, AUC: 0.4291077407158137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05015297409910593, AUC: 0.42910666901012984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050154531964604156, AUC: 0.42910452559876205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05015604639152069, AUC: 0.42956321563147043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05015751737985552, AUC: 0.42956428733715435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05016520798329734, AUC: 0.42964466526344663\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050172430634745406, AUC: 0.429726114895423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050173767358373166, AUC: 0.42972933001247476\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05017508433719106, AUC: 0.4297304017181587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050182613033192006, AUC: 0.42934941034753277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05018385103277045, AUC: 0.4298139947615026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05018506336409606, AUC: 0.4298139947615026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050186240154763924, AUC: 0.4298139947615026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05018739522614094, AUC: 0.42981506646718654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05019478570847284, AUC: 0.42943461094940266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05019587957093928, AUC: 0.42943353924371874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05019695368859585, AUC: 0.4303562778375551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05019801201040454, AUC: 0.43082246981005085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05019904268947941, AUC: 0.4308256849271026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020005954718738, AUC: 0.4308246132214187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020105271112351, AUC: 0.4308246132214187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020203205369274, AUC: 0.4308246132214187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0502029916514521, AUC: 0.4312865183711788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020393742784457, AUC: 0.4312875900768627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050204865433908154, AUC: 0.4312875900768627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050205777644123845, AUC: 0.43128866178254655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020667405849165, AUC: 0.4312918768995983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020755665149254, AUC: 0.43129294860528217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020842739760752, AUC: 0.43129294860528217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05020928234787461, AUC: 0.4312940203109661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050210123476774796, AUC: 0.4312940203109661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021095275878906, AUC: 0.43129509201664995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021177019391741, AUC: 0.43129616372233387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021257380767886, AUC: 0.43129830713370165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021336754903537, AUC: 0.4313004505450694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021415339246793, AUC: 0.43130045054506944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021492344005261, AUC: 0.43129937883938557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021568164075137, AUC: 0.4313004505450695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021643194352618, AUC: 0.43130152225075336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021717237389606, AUC: 0.4313015222507534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021790293186101, AUC: 0.4313015222507534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05021862164294004, AUC: 0.4313036656621212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050219336405057095, AUC: 0.4313068807791729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022003734580725, AUC: 0.4313090241905406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050220732363114445, AUC: 0.4313122393075923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022141750801671, AUC: 0.4313133110132762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022209080603306, AUC: 0.4313143827189601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050222766078530386, AUC: 0.43177628786872035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022342358069884, AUC: 0.43223926472416435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022407713390532, AUC: 0.43223926472416435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05022472278918785, AUC: 0.43224140813553225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050225354623103485, AUC: 0.4327011698739245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050225988431500106, AUC: 0.4327054566966601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023244893328744, AUC: 0.43232017850329874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023305707343123, AUC: 0.43232125020898265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023366521357503, AUC: 0.43232125020898265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050234255583389946, AUC: 0.43232339362035044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023484595320486, AUC: 0.43232446532603436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023543632301978, AUC: 0.43232339362035044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0502360128714678, AUC: 0.43232339362035044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023658547095384, AUC: 0.4323223219146665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0502371541214779, AUC: 0.4323223219146665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023771092511606, AUC: 0.43232339362035044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05023826575427322, AUC: 0.4323223219146665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050238818608949395, AUC: 0.43232446532603436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010989265659087439, AUC: 0.7675990148881354\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015328336206282147, AUC: 0.816356264977087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013313213984171549, AUC: 0.8636693916569855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009908433286299617, AUC: 0.9011780188877411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008468783666875299, AUC: 0.9256054065408341\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007575441838298031, AUC: 0.9377896284610735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006013902077763717, AUC: 0.9493029626231926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005180470691704602, AUC: 0.9572662717073988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004674514875155304, AUC: 0.9631418981193708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004360116540028195, AUC: 0.9672079494840808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00393660196853227, AUC: 0.9708881868025876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003771350990911448, AUC: 0.9733434645243985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003380959695417195, AUC: 0.97528753863499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003085175532978761, AUC: 0.9770788946856258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030370565675060203, AUC: 0.9780712941489157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002961729624256584, AUC: 0.9787604009036622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028626446151338502, AUC: 0.9792389174915227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00271203805447612, AUC: 0.9801723731421983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00262763510086028, AUC: 0.9807044750142536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002635523646020988, AUC: 0.9809568617028117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002666875935982967, AUC: 0.9808084304655919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026416078857753587, AUC: 0.9809600768198634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002616107710646793, AUC: 0.9811176175553964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002612612323978179, AUC: 0.9809841901977512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026259043448706837, AUC: 0.9811176175553965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026451001873174316, AUC: 0.9812397920033609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002657420023134283, AUC: 0.9813512493944864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026650073982420423, AUC: 0.9814766389595024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002674574807563924, AUC: 0.9815923831733634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026886639634521358, AUC: 0.9817134859156439\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002702725414904008, AUC: 0.9818249433067693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027150136590250776, AUC: 0.9819053212330618\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027270246119726273, AUC: 0.9819942728048252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027388131272965584, AUC: 0.9820596468515431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002702876647807056, AUC: 0.9825124425029902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027124699104893527, AUC: 0.9825735297269722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002721075068843044, AUC: 0.9826233640412736\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027283502908473675, AUC: 0.9826807002953623\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027348844037539716, AUC: 0.9827273194926117\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0027396120516656594, AUC: 0.9827830481881744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027421110658665377, AUC: 0.982840920295105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027416843928658938, AUC: 0.9828800375525673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002755345456595253, AUC: 0.9829304077197104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002754001513771389, AUC: 0.9829952459135861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00274894030197807, AUC: 0.983050438756307\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002740795506206852, AUC: 0.9830884843080854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002728406378447886, AUC: 0.9831313525354413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027069938108787773, AUC: 0.9831967265821591\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002665396679509007, AUC: 0.9833076481204426\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002642290439171327, AUC: 0.9833907053109446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026244393416813444, AUC: 0.9834694756787112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002608017583317885, AUC: 0.9835525328692133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025929158271963304, AUC: 0.9836371976182413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025793454044847506, AUC: 0.9836918546081203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002568491065477486, AUC: 0.9837465115979989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025616579421065115, AUC: 0.9838102780861909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025593609419915495, AUC: 0.9838413575510239\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025608831434269625, AUC: 0.9838579689891244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025637614430848114, AUC: 0.9838761879857506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025665095504026235, AUC: 0.9838858333369056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025685623936031175, AUC: 0.9839136976846871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025695954173741626, AUC: 0.9839388827682586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002587900892301129, AUC: 0.9839153052432129\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025959427065484026, AUC: 0.9839281657114196\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026007719168258257, AUC: 0.9839270940057356\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002603082491497569, AUC: 0.9839522790893074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026037746704883455, AUC: 0.9839774641728789\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026034507322015227, AUC: 0.9839844302598244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026024712662272324, AUC: 0.9839956831695051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026010559952777366, AUC: 0.9840165814303413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00259939490144544, AUC: 0.9840348004269677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002597624409025994, AUC: 0.984051411865068\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025958489804040817, AUC: 0.9840610572162231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002594177088628891, AUC: 0.9840969593566337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025927341132430557, AUC: 0.9841189293231536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026297547679016557, AUC: 0.9840476608951743\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002643594275350156, AUC: 0.9840331928684417\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026581025765302514, AUC: 0.9839967548751892\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026739559928822963, AUC: 0.9839737132029854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026919705403764304, AUC: 0.9839292374171037\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027128427788831186, AUC: 0.9838751162800667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002736308991785622, AUC: 0.9838226027015557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002760982476406216, AUC: 0.9837604437718896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002785352261170097, AUC: 0.9837277567485306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028085197721208844, AUC: 0.9836693487887583\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028301439793707176, AUC: 0.9836227295915088\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028501844677619064, AUC: 0.9835841481868883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028686980036228093, AUC: 0.9835573555447908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002885734442598331, AUC: 0.9835300270498515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029012446077714056, AUC: 0.9835096646418574\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002914954416500115, AUC: 0.9834850154111275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029263401377028313, AUC: 0.9834689398258692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029349808367142767, AUC: 0.983450184976401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029411187576704636, AUC: 0.9834496491235591\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029454869266375746, AUC: 0.9834357169496685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029487366755309805, AUC: 0.9834416113309297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029512775857502877, AUC: 0.9834400037724039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002953348199279659, AUC: 0.9834314301269327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029550905553450495, AUC: 0.983440003772404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029565942460212154, AUC: 0.9834410754780879\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002957916407851699, AUC: 0.983449649123559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03236824829385888, AUC: 0.30056521757768795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045100802466982885, AUC: 0.4781361323427914\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046579019376703425, AUC: 0.4873892392175691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04718276630030409, AUC: 0.4870173573452564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04743284813859201, AUC: 0.48801993801254323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047645588592466113, AUC: 0.4935161806124154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0477733888487885, AUC: 0.4948043708444612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047843032742138976, AUC: 0.49675166007210436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04787290663946243, AUC: 0.4978088977292701\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04788281458505192, AUC: 0.49926213063663616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047871459344899434, AUC: 0.5022404007321893\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04787230442276159, AUC: 0.5039963904952566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04785792230325703, AUC: 0.5065700916951383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04783465304483291, AUC: 0.5083635911571421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04781857682064206, AUC: 0.5104823532942089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04782377760356011, AUC: 0.5113927672726805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047840246749467234, AUC: 0.513030869410519\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04789419746793822, AUC: 0.5125796813175979\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04791023222802836, AUC: 0.5136181641252953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04791868498113091, AUC: 0.5138239316166038\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04792371595868413, AUC: 0.5143201313482486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04792722856035884, AUC: 0.5144090829200121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04792995334412, AUC: 0.5148784900095597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04793222004829233, AUC: 0.5149567245244842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047934186631354736, AUC: 0.5150306722166731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04794219710071635, AUC: 0.5146925490734033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04794380235375825, AUC: 0.5147332738893914\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04794527926553604, AUC: 0.5151678505442121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04794666732566944, AUC: 0.5151967865976774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04794798233000635, AUC: 0.5152353680022979\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047949234150951696, AUC: 0.5156538690718601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047950426737467446, AUC: 0.5156731597741703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04795156996195855, AUC: 0.5156956655935321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047952677645791884, AUC: 0.5157192431185778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047953741891043525, AUC: 0.5157503225834109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04795478046804234, AUC: 0.5157749718141406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04795578350438341, AUC: 0.5157921191050829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04795675692350968, AUC: 0.5165851813111676\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04795770664886411, AUC: 0.5166076871305294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04796445739935644, AUC: 0.5166167966288426\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047965351839243255, AUC: 0.516633408066943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04796622061087725, AUC: 0.5166500195050434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04796707358666335, AUC: 0.5166693102073536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047967908792120574, AUC: 0.5166843140869282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047968722278286954, AUC: 0.5167100350233418\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047969519968605434, AUC: 0.5171119246548036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047970303837557016, AUC: 0.5171226417116426\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797108178306564, AUC: 0.5175213162260528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797183406032143, AUC: 0.5175363201056273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047972576465172306, AUC: 0.5175481088681502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047973307023137256, AUC: 0.5175577542193053\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797402770869727, AUC: 0.5175684712761442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797473457289038, AUC: 0.5175899053898222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797542959019758, AUC: 0.5175995507409773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047976108811656884, AUC: 0.5176081243864484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0479767860586352, AUC: 0.5176177697376035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047977451458727595, AUC: 0.5176327736171782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04797810303745309, AUC: 0.518412975355056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047978750667216616, AUC: 0.5184204772948434\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.04797938250113225, AUC: 0.5184301226459984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798001236056689, AUC: 0.5184408397028374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798063432207759, AUC: 0.5184504850539925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047981244436702375, AUC: 0.5184569152880959\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798184467892222, AUC: 0.518466560639251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798243899769911, AUC: 0.5184815645188255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798302739303305, AUC: 0.518486923047245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047983611839405006, AUC: 0.5184987118097679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798418443889105, AUC: 0.5185062137495552\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798474914045314, AUC: 0.5185158591007103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798531186753425, AUC: 0.518520145923446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0479858686711724, AUC: 0.5185255044518654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047986411653443646, AUC: 0.5185330063916527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047986954635714896, AUC: 0.5185372932143882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798749564350515, AUC: 0.518551225388279\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047988022829928506, AUC: 0.518560870739434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798854606738989, AUC: 0.5185683726792214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04798906338140831, AUC: 0.5185769463246925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047989576746464764, AUC: 0.5185833765587959\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799008616255924, AUC: 0.5185951653213188\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799058965521076, AUC: 0.518991696424361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799108722441932, AUC: 0.5190024134812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799157887018492, AUC: 0.5190099154209874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047992064592507565, AUC: 0.5190184890664586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799255228931119, AUC: 0.5190270627119298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799302419026693, AUC: 0.5190302778289815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799349806570365, AUC: 0.519034564651717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0479939679921784, AUC: 0.5190431382971883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799443396969118, AUC: 0.5194375259888628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047994895998241985, AUC: 0.5194460996343341\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799536000127378, AUC: 0.5194493147513858\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047995808208457676, AUC: 0.5194557449854891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047996260364603555, AUC: 0.5194621752195926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799669869938252, AUC: 0.5194686054536959\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799713900864248, AUC: 0.5194750356877993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799757931790243, AUC: 0.5194857527446383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799801370371943, AUC: 0.5194900395673738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047998444140574456, AUC: 0.5194975415071611\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799886865398652, AUC: 0.5195029000355806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0479992911929176, AUC: 0.5195082585640001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04799971175736769, AUC: 0.519509330269684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04800012639837482, AUC: 0.5195189756208392\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013672017656251263, AUC: 0.8152518722698299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03030574395789863, AUC: 0.7823901608844573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03195145510245061, AUC: 0.7804450150681819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03229240156848979, AUC: 0.7881880886343469\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031781545090132375, AUC: 0.7988879981823871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031166798332956762, AUC: 0.8073319672658218\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030853033559416144, AUC: 0.8127848057854958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030610291854194973, AUC: 0.8174135026342526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030410824848751596, AUC: 0.8216092303867142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02991942885499563, AUC: 0.8272313984044447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02903681314756658, AUC: 0.8382292421326086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02766924812680199, AUC: 0.8503711316783338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02566852036470212, AUC: 0.8674503693097785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022568620756792973, AUC: 0.8930346632486401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017364554276871138, AUC: 0.9215468571159113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011149905976795015, AUC: 0.9479911948661012\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010006005719581747, AUC: 0.9570278171927312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00845533473644691, AUC: 0.9654208802561806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008061653338604091, AUC: 0.9694317387781699\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006991693692177719, AUC: 0.9739897030517891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006409312874140453, AUC: 0.9767509527463529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005222366216513434, AUC: 0.9800566289283372\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004142961640288864, AUC: 0.982545665379191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035785342842402173, AUC: 0.9841205368816794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032103765084876778, AUC: 0.9856375362772375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029836504355720854, AUC: 0.9868287371448904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031167611819123138, AUC: 0.9868169483823674\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032338028615552694, AUC: 0.9870227158736761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032880413606300118, AUC: 0.9872440230974009\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033880554864618843, AUC: 0.9873270802879031\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003440882848656696, AUC: 0.9876400183476014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003478648129457272, AUC: 0.9876501995515984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034747015121807468, AUC: 0.9880456589489569\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034957647817228646, AUC: 0.988107282025781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035192005135751413, AUC: 0.9881753353367084\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035456843504500933, AUC: 0.988201592125964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035663526003898794, AUC: 0.9882278489152194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035858607193451244, AUC: 0.9882996531960407\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003617481045101, AUC: 0.9879615300527709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00365402362855078, AUC: 0.9879540281129835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036934872098097395, AUC: 0.9879518847016159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003721910604038594, AUC: 0.9879358091163573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037430286654280827, AUC: 0.9879240203538344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003758637431245413, AUC: 0.9879422393504607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003769081942042949, AUC: 0.9879518847016158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00377481176246027, AUC: 0.987971175403926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003776413066540199, AUC: 0.9879936812232877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003774271988720627, AUC: 0.9880172587483335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037683568139007125, AUC: 0.9880483382131665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037580876616957765, AUC: 0.9880622703870573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003742066722972546, AUC: 0.988096564968942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037167987961699996, AUC: 0.9881469351360852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036669814068338146, AUC: 0.9881940901861768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003637223880483497, AUC: 0.9882208828282742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036093474174878613, AUC: 0.9882433886476361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035422360428124973, AUC: 0.9886640331285661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034455158448861004, AUC: 0.9887846000180047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003381682108648075, AUC: 0.9888756950011361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033299133150720694, AUC: 0.9889935826263649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032802568459362716, AUC: 0.9890771756697089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032329811072497635, AUC: 0.9891634479772626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003188516535867569, AUC: 0.9892288220239804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003146734667120513, AUC: 0.9893108075087989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031071333658127557, AUC: 0.9893649286458356\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003069202475419449, AUC: 0.9894292309868695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030326713686404023, AUC: 0.9894806728596965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030037624988990294, AUC: 0.9892014935290411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029749430978273507, AUC: 0.9892390032279773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029705256902406428, AUC: 0.9892561505189198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002991660411313454, AUC: 0.989264724164391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030089964777786538, AUC: 0.9892657958700749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030151555010003825, AUC: 0.9892690109871266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030142751292905946, AUC: 0.989296875334908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030098483429192016, AUC: 0.9893172377429021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003004496635610766, AUC: 0.9893333133281604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003000665155256757, AUC: 0.9893461737963672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030004612900949167, AUC: 0.9893483172077351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003004410375472675, AUC: 0.9893536757361545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003016739281561557, AUC: 0.98902251867983\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00302380385112565, AUC: 0.9890305564724592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003030308161709866, AUC: 0.9890364508537207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030359209941287464, AUC: 0.9890412735292982\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030406876380399146, AUC: 0.9890519905861374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00304474889861871, AUC: 0.9890552057031889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003048245704445533, AUC: 0.9890627076429763\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00305129023072142, AUC: 0.9890696737299216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003053972809951498, AUC: 0.9890707454356056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003056356502122267, AUC: 0.9890744964054992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030584927671444342, AUC: 0.9890819983452864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030604210946377267, AUC: 0.989086285168022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003018664400523247, AUC: 0.9894367329266568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030202616322361413, AUC: 0.989444770719286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030217249694571486, AUC: 0.9894485216891796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030230718122999612, AUC: 0.9894554877761248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003024315365106176, AUC: 0.9894576311874927\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030254679683819567, AUC: 0.9894587028931766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003026539000911989, AUC: 0.9894629897159122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030275366074303416, AUC: 0.9894710275085414\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030284697965065146, AUC: 0.9894779935954868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030293431341277886, AUC: 0.9894801370068547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030301641480029247, AUC: 0.9894833521239064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02153763465012576, AUC: 0.5791797593377717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03218420099767839, AUC: 0.7173129766411029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03190674594223623, AUC: 0.7442202912467367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030375271356870917, AUC: 0.7711265341466864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029234666014803616, AUC: 0.791073656188243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027797714770457265, AUC: 0.8084218919463461\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025200975114020748, AUC: 0.8320283530455731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019449098756841497, AUC: 0.8674407239586236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012943656795019935, AUC: 0.9076854158003714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012638117215648201, AUC: 0.924393307412345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010801884451761503, AUC: 0.9353043429801134\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00987706692816061, AUC: 0.9444770719285989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009211838368796908, AUC: 0.9508692604802098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008057318859218811, AUC: 0.9582731391974211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00767119997036383, AUC: 0.9625160219999742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069361569718544526, AUC: 0.9665847526288941\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006694295391532945, AUC: 0.9691589896816177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006064090669525336, AUC: 0.9720424138241459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005470861559328826, AUC: 0.9748567129500628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005330893687333133, AUC: 0.9763217346199518\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00529908924122528, AUC: 0.9775354413069667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005325311952989788, AUC: 0.978119520904691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005366481239010829, AUC: 0.9787175326763062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005299186114198673, AUC: 0.9792882159529823\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005204818386962448, AUC: 0.9798342499989284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005082160542963948, AUC: 0.9804113635097076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005041159704852055, AUC: 0.9805908742117606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049943363691215435, AUC: 0.9810109828398486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00498939695812407, AUC: 0.9813158831069176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004963821629312961, AUC: 0.9815377261834846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004902307661423772, AUC: 0.9821410964835193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004836088875559299, AUC: 0.9823822302623965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004767037203099664, AUC: 0.9826287225696929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004693545416521977, AUC: 0.98318600952532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046348960503287935, AUC: 0.9834051733376773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004590663727272618, AUC: 0.9835686084544717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004583843623135648, AUC: 0.9837047150763267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046405737938101, AUC: 0.9837438323337891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004676951261287397, AUC: 0.9837620513304154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004700712288882174, AUC: 0.9837668740059929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004720522503428331, AUC: 0.9837690174173608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004738128703573476, AUC: 0.9837775910628319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047533166581305904, AUC: 0.98377705520999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047659226085828696, AUC: 0.9837856288554612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004776252969698382, AUC: 0.9837968817651421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004784835791735916, AUC: 0.9838065271162972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00479214852887898, AUC: 0.9838193875845039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004798524498199084, AUC: 0.9838242102600815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004804189654364102, AUC: 0.9838359990226043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004809293564308751, AUC: 0.9838445726680756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048139386542341974, AUC: 0.9838515387550208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048181989671774285, AUC: 0.9838633275175438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004822128554555447, AUC: 0.9838686860459633\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004825771718785382, AUC: 0.9838783313971183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004829163506904744, AUC: 0.9838858333369056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00483233156164734, AUC: 0.9838933352766929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004835294887392664, AUC: 0.9838997655107963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004838080139634032, AUC: 0.9838976220994285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004840696697156128, AUC: 0.9839040523335318\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004843162330287831, AUC: 0.9838997655107963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004845487775269502, AUC: 0.9838997655107963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00484768549601237, AUC: 0.9839051240392158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004849763884060625, AUC: 0.9839083391562674\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004851729479882535, AUC: 0.9839083391562674\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00485359437717414, AUC: 0.9839179845074225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004855359439770874, AUC: 0.9839190562131064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004857034169862482, AUC: 0.9839254864472098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004858620788740075, AUC: 0.9839254864472098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048601278113529055, AUC: 0.9839265581528936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004861555114295912, AUC: 0.9839287015642615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004868740127200172, AUC: 0.9835734311300494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004870012186575627, AUC: 0.9835734311300492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004871218347648163, AUC: 0.9835809330698365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004872359844468395, AUC: 0.9835820047755204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048734395153527425, AUC: 0.9835830764812044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004874458841161945, AUC: 0.9835846840397302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048754239921490845, AUC: 0.9835889708624658\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004876333240643298, AUC: 0.9835857557454141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004877189301555941, AUC: 0.9835895067153078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004877995877038865, AUC: 0.9835970086550951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048787511160161435, AUC: 0.9835991520664628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004879455635513084, AUC: 0.9835991520664628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004880111656820799, AUC: 0.9836012954778305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004880722141660765, AUC: 0.9836012954778306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004881286226197552, AUC: 0.9836012954778306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048818053912919, AUC: 0.9836045105948822\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004882280747589364, AUC: 0.9836077257119339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004882713035520313, AUC: 0.9836141559460373\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048831007742240065, AUC: 0.983618442768773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004883444580725755, AUC: 0.983618442768773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004883745442266049, AUC: 0.9836238012971925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884004222680323, AUC: 0.9836238012971925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048842189474875885, AUC: 0.9836270164142442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884391344358709, AUC: 0.98362862397277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884519438812698, AUC: 0.9836329107955055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884604958520419, AUC: 0.9836350542068734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884646299216071, AUC: 0.9836361259125573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884641486418667, AUC: 0.983639341029609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884590643533269, AUC: 0.9836404127352929\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004884493400344691, AUC: 0.9836446995580286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004884348893017502, AUC: 0.9836511297921318\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015126606445628417, AUC: 0.8113572938145435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016198973231187273, AUC: 0.8358666669524548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012961417251492139, AUC: 0.8715266018784856\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00935599596604057, AUC: 0.9035041560746422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007272851639899654, AUC: 0.927861882858282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006483518435594705, AUC: 0.9419483823674406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005588623430911552, AUC: 0.9533668705765348\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005146331298425331, AUC: 0.9608607725711935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004351531990319799, AUC: 0.9664754386491363\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004148733912047392, AUC: 0.9700479695464113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038648984447029067, AUC: 0.9726473916827066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003834835614230075, AUC: 0.9742131536868819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003764488126920617, AUC: 0.9753154029827713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003723629698249864, AUC: 0.9759857548880496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037047521791596346, AUC: 0.9767697075958212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003675768464248373, AUC: 0.9776399326111466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003691352117135658, AUC: 0.9784120965563954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036959332215366404, AUC: 0.9790444029098953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036817503395041077, AUC: 0.9796204447149907\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036693627543084124, AUC: 0.9800984254500094\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036576745672996, AUC: 0.9805555079241919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036478555350570206, AUC: 0.9809686504653347\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003632375727529111, AUC: 0.9813399964848053\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036394962612886607, AUC: 0.9816031002302023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003673470044975202, AUC: 0.9818163696612981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037040736364281697, AUC: 0.9819674801627278\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037303819913054597, AUC: 0.9821260926039447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037541779425326834, AUC: 0.9822739879883229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037839471923638577, AUC: 0.9820671487913304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003807081815865716, AUC: 0.9821769986239299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003836035605049528, AUC: 0.9819830198951442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038586194717612574, AUC: 0.9820441071191265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003887436774946888, AUC: 0.9818388754806601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003911457693601494, AUC: 0.9818913890591711\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003936966383679313, AUC: 0.981945510196208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003960362008886554, AUC: 0.981986770865038\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003975845395161251, AUC: 0.9820521449117559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003986292250654959, AUC: 0.9820976924033215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003993954717742731, AUC: 0.982143775747729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003999312225089063, AUC: 0.982186643975085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004002783362663064, AUC: 0.9822268329382311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004004929746900286, AUC: 0.9822546972860126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040062665939331055, AUC: 0.9822857767508455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004007132280440558, AUC: 0.9823082825702074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004007718701293503, AUC: 0.9823500790918795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008127542262738, AUC: 0.9823758000282931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008412978170328, AUC: 0.9823897322021837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008599443218476, AUC: 0.9824202758141748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008700388558903, AUC: 0.982439566516485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040087182822928415, AUC: 0.9824567138074275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008652754205108, AUC: 0.9824738610983696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008499731928666, AUC: 0.9824899366836283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008252181375002, AUC: 0.9825070839745706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004007901587594864, AUC: 0.9825188727370935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004007439188828873, AUC: 0.9825370917337198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040068477083684, AUC: 0.9825408427036134\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004006113941871848, AUC: 0.9825435219678231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004005215429617999, AUC: 0.9825585258473976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004004127860809705, AUC: 0.9825735297269723\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004002819643751188, AUC: 0.9825874619008629\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004001250795202472, AUC: 0.9825960355463342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003999364919050386, AUC: 0.9826121111315926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003997095253156579, AUC: 0.982620684777064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039943428266616095, AUC: 0.9826351528037964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039909749791242075, AUC: 0.9826464057134774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003986791053914135, AUC: 0.9826635530044198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003981493274617639, AUC: 0.9826774851783106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003974598880633558, AUC: 0.9826951683220948\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003965273777150219, AUC: 0.9827208892585083\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003951933072960895, AUC: 0.9827492894591316\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003931106124111831, AUC: 0.9827841198938584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038933482476149533, AUC: 0.9828661053786765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003800546654016088, AUC: 0.9829695249771727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003706099824135348, AUC: 0.9830992013649245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003594300761726332, AUC: 0.9835332421669033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035008455532184544, AUC: 0.9836747073171777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034591652468371342, AUC: 0.9837722325344125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003431150323362331, AUC: 0.9838161724674523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003405145051316445, AUC: 0.9838590406948082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003379982203923891, AUC: 0.9839083391562676\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003355681896209717, AUC: 0.9839613885876206\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033323206393121437, AUC: 0.9839988982865571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033099038013513537, AUC: 0.9840476608951743\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032884016417074895, AUC: 0.9840964235037917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032677992900706225, AUC: 0.9841419709953574\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032481095188646334, AUC: 0.9842078808949172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003229388107177387, AUC: 0.9842266357443854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003211865760771631, AUC: 0.9842662888546895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00319680022403567, AUC: 0.9843220175502523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031897135649655425, AUC: 0.9843589913963469\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003202435454473239, AUC: 0.9843825689213925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003229134756585826, AUC: 0.9843847123327603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032532913591057123, AUC: 0.9844243654430644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003275122886859112, AUC: 0.9844479429681102\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032980191534844, AUC: 0.9844495505266362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033211055873096852, AUC: 0.9844565166135815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033422405551926195, AUC: 0.9844586600249493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033606551818966125, AUC: 0.9844640185533688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033765117450777296, AUC: 0.9844645544062107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003390209768623052, AUC: 0.9844704487874724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003402125144350356, AUC: 0.984483309255679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03301163983394394, AUC: 0.6043814543474813\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018743690743456224, AUC: 0.8087176827151021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01735728473149965, AUC: 0.8352713344450493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015379357288589636, AUC: 0.8582385231038312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012551140834579309, AUC: 0.883405923531656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011333125471821977, AUC: 0.9005376747416116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009864196520661221, AUC: 0.9165173423413768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008596479028895281, AUC: 0.9301247894098332\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007467473515812654, AUC: 0.940366008925165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00597263345066805, AUC: 0.9520529594080755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005390412565590679, AUC: 0.9609679431395832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004387335994475623, AUC: 0.9688106853343507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004293485951473007, AUC: 0.97267579188333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004405712489015568, AUC: 0.9741847534862585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004488351675787821, AUC: 0.9750255065952768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004451411357824353, AUC: 0.9760082607074115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004123246200830053, AUC: 0.9776677969589279\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036972783367085903, AUC: 0.979374488260536\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0036090727178206355, AUC: 0.9804778092621093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003442402581990876, AUC: 0.981640609929139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003405658601480488, AUC: 0.982292742837791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033142263104456553, AUC: 0.983166182970168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033445080614978484, AUC: 0.9834807285883921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033419317340258486, AUC: 0.9837073943405368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00330912042602002, AUC: 0.9839297732699455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003264153966252108, AUC: 0.9841585824334578\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032141077839316296, AUC: 0.9843638140719243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031673951425414152, AUC: 0.9845910156769109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031433418917606584, AUC: 0.9847474847067599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003168526890361778, AUC: 0.9848021416966388\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00319199149899848, AUC: 0.984820896546107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003214320781068032, AUC: 0.9848235758103167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003247684573534853, AUC: 0.9848042851080064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032865637084218535, AUC: 0.9847699905261218\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033174278079599576, AUC: 0.9847421261783404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033260193917568673, AUC: 0.9847276581516078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003390690431338166, AUC: 0.9846590689878384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00345920689604544, AUC: 0.9845958383524883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035297806465354273, AUC: 0.9845079584864086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035983288263435444, AUC: 0.9844249012959064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003664552918625668, AUC: 0.9840246192229705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003722510846258444, AUC: 0.9836661336717065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003769353679988695, AUC: 0.9836446995580286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038104178248972134, AUC: 0.9836136200931954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003846929186866397, AUC: 0.983280319625503\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038684228932635385, AUC: 0.983271745980032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003892869806190949, AUC: 0.9829411247765494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003910043101379837, AUC: 0.9829325511310781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003926042197407156, AUC: 0.9829566645089659\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003946902589027926, AUC: 0.982640511332216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003960449009455015, AUC: 0.982630865981061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003978077422511257, AUC: 0.98230345989463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00399256381929291, AUC: 0.9819631933399923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003998387921177329, AUC: 0.981966944309886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004001902744143152, AUC: 0.981977125513883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004003672742942352, AUC: 0.9820028464502965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004004469569425405, AUC: 0.9820157069185034\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004004504739867975, AUC: 0.9820210654469228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004003920787116262, AUC: 0.9820339259151294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004002772256207515, AUC: 0.9820553600288073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004001026321395337, AUC: 0.9820633978214367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003998594131035341, AUC: 0.9820730431725917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003995322909661208, AUC: 0.9820896546106923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003990859965606753, AUC: 0.9821057301959507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003984964535596701, AUC: 0.9821260926039448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00397679919288272, AUC: 0.982146455011939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039649504558887045, AUC: 0.9821850364165592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003946333568288673, AUC: 0.9822053988245533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003912748510546319, AUC: 0.9822675577542193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038267735615526914, AUC: 0.9827460743420798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037319587377781208, AUC: 0.9832170889901533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036564369379363444, AUC: 0.9840117587547637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003616977182234296, AUC: 0.9837920590895646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035806380937311714, AUC: 0.9838751162800667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003548497122020208, AUC: 0.983976392467195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035187763703782614, AUC: 0.9840562345406454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003484157671839554, AUC: 0.9844666978175786\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034571223377441026, AUC: 0.9845744042388103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00343108658464799, AUC: 0.9846435292554216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034060713914116966, AUC: 0.9847378393556047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033821180987308732, AUC: 0.9848133946063196\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033589922369883915, AUC: 0.9848873422985085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033369300034722434, AUC: 0.9849752221645882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033156123960980718, AUC: 0.9850389886527801\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003295326578444329, AUC: 0.985134370458647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003275619530529709, AUC: 0.9852104615622039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003256767062666994, AUC: 0.9852881602242866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003239434698353643, AUC: 0.9853422813613234\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032240632404698594, AUC: 0.9854167649063543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032139459998958104, AUC: 0.9854649916621298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003213732755949285, AUC: 0.9855083957423276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032301326716168326, AUC: 0.9852286805588303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003245292489819892, AUC: 0.9852629751407149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032598051718796756, AUC: 0.9852795865788155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003272076447804769, AUC: 0.9852929828998641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003282187024505489, AUC: 0.9853015565453352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003290558453672421, AUC: 0.9853224548061713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032975695888448208, AUC: 0.9853401379499558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033031534210742138, AUC: 0.9853513908596367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033082398075001086, AUC: 0.9853749683846824\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033126178488721513, AUC: 0.985389972264257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04350912398186283, AUC: 0.45218317164866917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039693020885775546, AUC: 0.5775405854942492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04080370790469721, AUC: 0.5798045637514844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04124992678624503, AUC: 0.5820122774603147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04153052027921499, AUC: 0.5835946509025906\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04202424517329435, AUC: 0.5823686196002109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04239093196071206, AUC: 0.5845961598641934\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04267581994982733, AUC: 0.5845704389277799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042907007979556884, AUC: 0.585021627020701\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04315179425983942, AUC: 0.5840345860858307\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04335642552030259, AUC: 0.5857396698289128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04350889494206841, AUC: 0.585346889695764\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043576801292150906, AUC: 0.5877839484209487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043620210256635775, AUC: 0.5891841318969621\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043651403107258104, AUC: 0.5905092959751022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04367247476834441, AUC: 0.5908699249377339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04367544833670985, AUC: 0.591805523999777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043671939683997116, AUC: 0.5923306597848872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0436615282457561, AUC: 0.5929302791150284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043657421325304493, AUC: 0.5930996086130842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043654015345603044, AUC: 0.5932335718235714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043651247123260184, AUC: 0.593660646538605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043649006087340673, AUC: 0.5937806775752016\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04364718166690929, AUC: 0.5938835613208558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363984449556402, AUC: 0.5943497532933517\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043638602547023606, AUC: 0.5944279878082762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363757976587268, AUC: 0.5947837940953304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363672481560559, AUC: 0.5951438872051202\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043636019925893464, AUC: 0.5952081895461541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043635439428483476, AUC: 0.5952735635928719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043634955680641824, AUC: 0.5953175035259118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363455091203962, AUC: 0.5953753756328423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0436342211737149, AUC: 0.5954225306829338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363395659326273, AUC: 0.595461647940396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043639573991668894, AUC: 0.5951342418539651\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043639398262861104, AUC: 0.5951706798472176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0436392541257491, AUC: 0.5952017593120507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.04363330698901822, AUC: 0.5959230172373142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043633218137373836, AUC: 0.5959530249964633\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043633158902944245, AUC: 0.5962895405812075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363311743884353, AUC: 0.596621769343216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043633103617476625, AUC: 0.5966646375705719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363310164299564, AUC: 0.5966967887410887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04363311546436255, AUC: 0.5967235813831862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362731246474367, AUC: 0.5971474409811679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362734405643945, AUC: 0.5971656599777942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362740131638805, AUC: 0.5971935243255755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362745857633666, AUC: 0.5975273606461099\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362752965765217, AUC: 0.5975466513484201\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362760863689162, AUC: 0.5975766591075693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362769353957403, AUC: 0.5975916629871438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362778634018039, AUC: 0.5976184556292412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362788506422971, AUC: 0.597643104859971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043627987737241, AUC: 0.597663467267965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04362809633369525, AUC: 0.5976870447930108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043628210853592454, AUC: 0.5977116940237405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043628329322451635, AUC: 0.5977266979033151\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     16\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mtrain_sigmoid(epoch, train_loader_reduced_ratio, network, optimizer, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m     _, auc \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauc_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     model_aucs\u001b[38;5;241m.\u001b[39mappend(auc)\n\u001b[1;32m     19\u001b[0m aucs\u001b[38;5;241m.\u001b[39mappend(model_aucs)\n",
      "File \u001b[0;32m~/Downloads/ML/numbers mnist/metric_utils.py:15\u001b[0m, in \u001b[0;36mauc_sigmoid\u001b[0;34m(test_loader, network)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauc_sigmoid\u001b[39m(test_loader, network):\n\u001b[0;32m---> 15\u001b[0m     test_losses, y_preds, y_true \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_inference_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     network_auc \u001b[38;5;241m=\u001b[39m auc(y_preds, y_true)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest set: Avg. loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnetwork_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)   \n",
      "File \u001b[0;32m~/Downloads/ML/numbers mnist/inference.py:17\u001b[0m, in \u001b[0;36mrun_inference_sigmoid\u001b[0;34m(dataloader, network, binary)\u001b[0m\n\u001b[1;32m     13\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     18\u001b[0m         output \u001b[38;5;241m=\u001b[39m network(data)\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS RATIO \n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 1e-7]\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced_ratio, network, optimizer, verbose=False)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "            model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "        plt.plot(np.arange(-1, n_epochs), aucs[i])\n",
    "    plt.title(\"Logistic Regression 2 Classes \" + str(ratio) + \" with Sigmoid \\n Learning Rate = \" + str(learning_rate))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff8243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.020422892047258143, AUC: 0.48866349727572417\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 94.77835468426501, AUC: 0.5005219206680585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.119651462720788, AUC: 0.9610617173869243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.681824867769798, AUC: 0.9506586703133239\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.894738870624677, AUC: 0.9486052822229747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.154787430852096, AUC: 0.9347449126131184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.189647982579581, AUC: 0.9239903460751995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.381907713832815, AUC: 0.9219283843393792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.68438480606237, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.02172649375647, AUC: 0.9316819777685373\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.737649921551501, AUC: 0.9337353658588864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.3144725854846016, AUC: 0.9373287950169973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.574415882181677, AUC: 0.9352754069266482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.91912070959498, AUC: 0.948613855868446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.734696603463056, AUC: 0.9398955301299337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.971919531654374, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.142798761403339, AUC: 0.9291238163010722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.8483098190023295, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018510591416131882, AUC: 0.5220417708007355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 47.26801484860248, AUC: 0.5276617954070981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 13.249487456327639, AUC: 0.8966768550153683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.696722121465774, AUC: 0.9624313572509464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.971945563211698, AUC: 0.9383469154167006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.846273797392598, AUC: 0.9465690414235681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.017986289709498, AUC: 0.9357887539492354\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.339570797748447, AUC: 0.9342487128814736\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.602677560494307, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.984988384365295, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.881656243934394, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.094690421600026, AUC: 0.9409222241751082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.0884702694342, AUC: 0.9455423473783936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.524060740974379, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.071911798007246, AUC: 0.9547740201394932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.703954471564441, AUC: 0.9481090824913299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.274817425271739, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.313691638764881, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03421749288744561, AUC: 0.4922665717849901\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.998832118190347, AUC: 0.9626960685548691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.733711953488936, AUC: 0.957811234047661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.780403974386969, AUC: 0.9527120584036729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.36024768900427, AUC: 0.9414355711976954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.5881994654179605, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.046575510723991, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.984120244565218, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.224545686141305, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.065226236979166, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.661123587724831, AUC: 0.9501710442271502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.569169259713056, AUC: 0.9496491235590918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.343108562208851, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.387209937686012, AUC: 0.9496491235590918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.5010378503898165, AUC: 0.9491443501819756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.856986667798913, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.148786145954645, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.035668288205228, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024035819075369193, AUC: 0.5580982368298089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 69.9835055965321, AUC: 0.610125260960334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.468262982417832, AUC: 0.9367640061215828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.464582676226061, AUC: 0.9470652411552128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.5803677576669255, AUC: 0.9475785881778003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.903966046761775, AUC: 0.9296285896781882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 10.240119886694487, AUC: 0.9280971222558976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.177202623576605, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 10.11954929517663, AUC: 0.925017040120374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.958570144684913, AUC: 0.9265570811881358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.27774635457104, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.4493213598278984, AUC: 0.9434889592880444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.82459911401721, AUC: 0.9393821831073463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.407284691220238, AUC: 0.9393821831073463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.826266144620212, AUC: 0.9440023063106319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.495533566050401, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.691305409307065, AUC: 0.9440023063106319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.598949234924948, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.20836795783191, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.498904399990295, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04452432510028468, AUC: 0.29610585022698727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 109.63870018115942, AUC: 0.5328810020876826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.9443695510643115, AUC: 0.9460042525281537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.909349018989389, AUC: 0.9465518941326256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.761751099896481, AUC: 0.9491272028910334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.468088848990684, AUC: 0.934762059904061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.578351954742494, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 10.586035307890139, AUC: 0.9245036930977868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.68313377490942, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.236955915178571, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.955143077526527, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.132881496263588, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.391499963606367, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.637307871942935, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.894717767371894, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.38049114219397, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.973105483914014, AUC: 0.9511891646268535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.823862901138717, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.924940405425078, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.780280008572722, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.731782711810947, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.757228685461956, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030464108192649195, AUC: 0.3528451642496131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 27.6263839690088, AUC: 0.75\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.368978622784032, AUC: 0.9526777638217883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.383018983323629, AUC: 0.9537216051579052\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.121736198725414, AUC: 0.946560467778097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.222588264670678, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.718940055641822, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.759187117866848, AUC: 0.9393821831073463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.107215391676371, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.309435605509188, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.710920061383929, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.933741346402692, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.118047299592392, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.557815709716292, AUC: 0.9532425527172027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.860015426856884, AUC: 0.9506843912497375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.631590280473603, AUC: 0.9506758176042662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.019501174705616, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.651817811448629, AUC: 0.934770633549532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.111458535520186, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.389907236671842, AUC: 0.9291323899465433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02455853823549259, AUC: 0.49324718248575705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 60.22723173848344, AUC: 0.5929018789144049\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.354024377668867, AUC: 0.9495891080407933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.878921034913626, AUC: 0.9552787935166093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.226631748997153, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.746100573806289, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.700930008977096, AUC: 0.9265570811881358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.227123315783514, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.850581388295808, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.7233070389331, AUC: 0.9296371633236594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.101838737787914, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.599173156864648, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.066339781072076, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.739767702469915, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.5646845025799045, AUC: 0.9496491235590918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.553522145526009, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.139014834449405, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.449262725640528, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.734217041521092, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03993758207522564, AUC: 0.3527572843835335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 38.06489692514234, AUC: 0.6268267223382046\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.751222788176922, AUC: 0.9610359964505109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.3190551505078933, AUC: 0.9700886943623993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 3.561094043170937, AUC: 0.9563054875617838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.17716850454516, AUC: 0.9280885486104264\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.440640846394604, AUC: 0.9465690414235681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.455240000849185, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.673132854959239, AUC: 0.940408877152521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.395054913949275, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.083078198798201, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 4.186534178676566, AUC: 0.9450375740012775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198836616848, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.946198962983631, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024229322160993303, AUC: 0.4407839741418853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 27.15446469008799, AUC: 0.7651356993736952\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.5278368331877585, AUC: 0.9516424961311425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.85890087182971, AUC: 0.9496319762681492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.719080575504658, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.215093450763458, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.258259332945135, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.7679129969752845, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.02500823911426, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.875366716404633, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.425489089997412, AUC: 0.950162470581679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.992570138619306, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.830760252895316, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.1371473861283645, AUC: 0.949657697204563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.9530077316252585, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.85404674458948, AUC: 0.9517196589403831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.1081579615117105, AUC: 0.9470909620916266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.268762181757894, AUC: 0.9378592893305269\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.683429725915502, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02116810263560672, AUC: 0.5089744633969641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 134.46681304994823, AUC: 0.5031315240083507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.027446486194681, AUC: 0.9598217539106542\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.026516173937306, AUC: 0.9511720173359112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.9326660914450695, AUC: 0.9532254054262602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.853445365068581, AUC: 0.9450204267103351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.953536197512293, AUC: 0.934762059904061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.969950737173265, AUC: 0.9239817724297283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.131297615003882, AUC: 0.9321953247911245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.561103647046455, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 7.245643378784938, AUC: 0.9383554890621719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.906304337716744, AUC: 0.9481090824913299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.93505214904406, AUC: 0.9465690414235681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.090841542119565, AUC: 0.9450204267103351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.0540768957039335, AUC: 0.9506672439587951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 5.928215832443711, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 6.869113835241977, AUC: 0.9373459423079397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 8.149404711358049, AUC: 0.928619042923956\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.031180436073129467, AUC: 0.46544713704543605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 10.725756785390788, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.3297071753081329, AUC: 0.8977206963514852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6240366112371409, AUC: 0.9542520994714346\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8042642976433101, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8116719184701734, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.725692970165308, AUC: 0.9470909620916266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7471484703553636, AUC: 0.9450375740012775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.871377948895251, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9552693495345659, AUC: 0.9280971222558976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6967434616562742, AUC: 0.9450375740012775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7053548208675029, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.672302972702753, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7014610337914887, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5437368704912332, AUC: 0.9542692467623772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5765468368372315, AUC: 0.9511891646268535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.592270418723918, AUC: 0.9506843912497375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7183370017610475, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6300444830031622, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.754370079277465, AUC: 0.9363192482627651\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7178237314796843, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047385912751065525, AUC: 0.4087914160661543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 9.831586944390528, AUC: 0.5005219206680585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.182198471164111, AUC: 0.9180756024057649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6093085784596193, AUC: 0.9537301788033763\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6646181189495585, AUC: 0.949118629245562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.705542838844947, AUC: 0.9455252000874511\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8585908625190055, AUC: 0.9337353658588864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.867923681286798, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8940038582306225, AUC: 0.9296371633236594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8148790758342229, AUC: 0.9357973275947067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7578021063320879, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7033518757632554, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6372170774092586, AUC: 0.9455423473783936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7209102559533919, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6394837499898907, AUC: 0.9445070796877478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5669916125311367, AUC: 0.9506758176042662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5743938785655651, AUC: 0.9496491235590918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7082160965502879, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.782752011380087, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7489688470496895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028704797259028653, AUC: 0.5633335190956519\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.38908297378824364, AUC: 0.9526423975342195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.47028380842189116, AUC: 0.9614046632057717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6073800160030894, AUC: 0.9532425527172027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.685848875815824, AUC: 0.9475957354687427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8089902889654503, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7531280517578125, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7394577089550579, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7146359714168445, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6502596142375938, AUC: 0.9465776150690393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6793165976956764, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6073526417986946, AUC: 0.9476043091142139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5619050967767372, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.628771163908838, AUC: 0.9445328006241613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5130192537485443, AUC: 0.9547911674304357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.589447748093378, AUC: 0.9486395768048596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5382890563080276, AUC: 0.9532511263626737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7149964326657123, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025212768688952208, AUC: 0.5385310344531943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.32043383580557305, AUC: 0.9594702344463355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.43030867171830517, AUC: 0.963971398318708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5492716408170775, AUC: 0.9552787935166093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7836115424430642, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8107659002268537, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6819726853143602, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.785043594012843, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7450768764961827, AUC: 0.9357973275947067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7131728336184168, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6983772577953141, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5972827413807744, AUC: 0.9470909620916266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5438531911151009, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5465862361047086, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5069568863072997, AUC: 0.9511891646268535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6650658048704791, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.704498875461997, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009730721112363828, AUC: 0.6670939199993141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 19.531499700763458, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9640482395085243, AUC: 0.9367554324761117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8980535977128623, AUC: 0.9419146236383978\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9444402848711665, AUC: 0.9398869564844624\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9383245748515948, AUC: 0.9404003035070497\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1351254228232563, AUC: 0.9280971222558976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1712029498556387, AUC: 0.925017040120374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1561000974035165, AUC: 0.9239903460751995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.1090876735268667, AUC: 0.9255303871429612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.150716777667249, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9641109806163464, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.940912029511193, AUC: 0.9363106746172939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9362522227917152, AUC: 0.9357973275947067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8537515517840968, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7047055325399522, AUC: 0.9481005088458587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7799045570642065, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7003389915324146, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7712842731989196, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7858340340371458, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8654283796037946, AUC: 0.9363192482627651\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9226678883807259, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016051734703174537, AUC: 0.531160914465026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 13.376873261193063, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.33693021375446836, AUC: 0.9648437667454014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.38596258696562014, AUC: 0.9649980923638828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4748697853483275, AUC: 0.9552787935166093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5405132854453772, AUC: 0.9501538969362079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6178656315457993, AUC: 0.9414355711976954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7417992696505402, AUC: 0.9255303871429612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.571753776344947, AUC: 0.9434889592880444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5631714499021415, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.47019659954568616, AUC: 0.9501538969362079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4735115951632861, AUC: 0.9496405499136207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5451538054345805, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5203488272909792, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6018985092763328, AUC: 0.9357973275947067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.713514134503793, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135141502996409, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009710696419820529, AUC: 0.7182689381111401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 12.730598655053054, AUC: 0.5005219206680585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.681728702647839, AUC: 0.9470309465733282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6370429913696541, AUC: 0.9527034847582018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6892153343058521, AUC: 0.9475871618232714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8212726664098894, AUC: 0.9373287950169973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7750622925057421, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9991337241099735, AUC: 0.9255303871429612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9129192913047522, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9531707763671875, AUC: 0.9260437341655485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8851459258338186, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7064580028841955, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7526304035700133, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6757631163666213, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6699417303807987, AUC: 0.9434975329335157\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.6693883860333366, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.672588040369638, AUC: 0.9435061065789869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7396617913098069, AUC: 0.9373459423079397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8587495791986122, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03873777192078268, AUC: 0.303862855967043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6885653193692983, AUC: 0.922772888418291\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5052438108076961, AUC: 0.961918010228359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6306121541846613, AUC: 0.9532425527172027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6440112980749789, AUC: 0.9517025116494409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7662022118736251, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7135548719955034, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6648116496779164, AUC: 0.9491443501819756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7556055041326992, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6784080995042379, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6739053035127944, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6380199961533951, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5610654526862545, AUC: 0.9522158586720281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5521229493198434, AUC: 0.9527292056946153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5391250831493433, AUC: 0.9532511263626737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5297172025123739, AUC: 0.9537558997397899\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6032094224886371, AUC: 0.9470909620916266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5865434919084821, AUC: 0.9517196589403831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7144822936127151, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02288169841095034, AUC: 0.5671112816313933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 22.818458446557973, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.35947811529503104, AUC: 0.9558167897699262\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3198384192172538, AUC: 0.9639542510277658\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.43120961949445197, AUC: 0.9552787935166093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8172741054748156, AUC: 0.9142281790005703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5949849035922539, AUC: 0.9363021009718228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6814691610711455, AUC: 0.9255218134974902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6852541621427358, AUC: 0.9244951194523156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6087740311711471, AUC: 0.9316819777685373\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6236966687946833, AUC: 0.930663857368834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5501601256692384, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.528061434348918, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4208790007091704, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6478212565862367, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6113291043425693, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013396617541895642, AUC: 0.671497558654452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 12.236118861607142, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.5523160693561562, AUC: 0.8773657902972054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6044423989874482, AUC: 0.9562883402708414\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7555409307065217, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8537813427532188, AUC: 0.9409222241751082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.763610113234747, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8906903000351805, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.0860804208317159, AUC: 0.9203969169170886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.8967108874587539, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9550410047574567, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.732215044167718, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7820068422558392, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6785480033290066, AUC: 0.9455423473783936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6582910130976644, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5911786886969461, AUC: 0.9486224295139172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5997240528556871, AUC: 0.9475957354687427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6454300811325294, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7143308272272904, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7166913587360896, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.7656714713844947, AUC: 0.9352839805721194\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.03238237373083521, AUC: 0.5110321383100487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09061510469108881, AUC: 0.906593347708479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06558186469857984, AUC: 0.9490929083091485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06415636248223283, AUC: 0.9527120584036729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06795530141510578, AUC: 0.9506758176042662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08100908093817732, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08376035828521286, AUC: 0.9363106746172939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07930143921024804, AUC: 0.938364062707643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.068249163420304, AUC: 0.9465776150690393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07504951682396804, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07202389719076532, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06704596012028602, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06955141458452119, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.058359479805450754, AUC: 0.9506758176042662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05157306722479084, AUC: 0.9547825937849644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051943333746236796, AUC: 0.955809287830139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05764684617889594, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06286879355863015, AUC: 0.9450461476467487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07666112177120232, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07667117977734678, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0766790599309633, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07668556189685134, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07669111808634693, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07669596938613038, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767002915250095, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07670416545670472, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07670769977767028, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07671094384993085, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07671393913758714, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07671672907922085, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767193255217179, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07672176598021703, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767240701995281, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07672623620517012, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07672830941020578, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07673026414638227, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07673213792883832, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07673392088516899, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767356406581081, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07673726763044085, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07673884129178697, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674036361662744, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674183065600029, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674323056301963, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674459098041922, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674591388268007, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674718149947331, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674841949905174, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07674961603452947, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675078690175438, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767519123559166, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675300424390205, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675408625948256, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675513273440533, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675614366867034, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767571328836445, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675809643036584, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675905010468224, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07675997218730286, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676087649959462, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676175909259551, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676261996630557, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676347096761067, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676429827514396, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676511176131033, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676590747714783, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767666794992135, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676744164887422, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676820379853495, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07676893238201891, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767696589910219, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.076770365855215, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677108061733207, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677174601742447, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677243313680772, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677308866449518, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767737362942587, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677438589850322, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677501773241885, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767756456173725, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677625178303531, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767768599231791, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677745226747501, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767780465862519, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677862116021893, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.076779189810743, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07677975451230509, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678031131594325, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678085034925251, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678139728048573, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678191854346612, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678244375540849, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678296106942692, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767834704855214, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678397397817292, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678447944530542, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678496516762806, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767854528644317, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678592673986842, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0767864065387481, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678687646522285, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020053017460287974, AUC: 0.5883728506942509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 1.833717235620471, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09960346340392687, AUC: 0.9352239650538211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08830518900237469, AUC: 0.9434546647061597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1007762024368065, AUC: 0.9362935273263515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09311750265875712, AUC: 0.9409136505296369\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10124790199548314, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11796263779665866, AUC: 0.9229636520300251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11253256629959643, AUC: 0.9239903460751995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11908514603324559, AUC: 0.9188568758493268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11722597868546196, AUC: 0.9193702228719141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08776638868185797, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09064409402093038, AUC: 0.9363106746172939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08046584000992232, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08722498796988225, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08824492784267134, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07885406130836123, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07543758921494889, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06751390026716465, AUC: 0.9475957354687427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08056923963021541, AUC: 0.9399126774208759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08433635190406942, AUC: 0.9378592893305269\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08905526273739264, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09811094532842221, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0261576723608171, AUC: 0.5904766089517433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 2.0318880258880045, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038584687941809866, AUC: 0.9552691481654543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03768895427632776, AUC: 0.9603779691605974\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05831994872162308, AUC: 0.9424536915973989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05833955531781752, AUC: 0.9409222241751082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07961380210228836, AUC: 0.9183349551812683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0841548832800571, AUC: 0.915263446691216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06409704907340293, AUC: 0.9306552837233628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05722626198399388, AUC: 0.9378421420395846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.054456387000547925, AUC: 0.9378421420395846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05153303561003312, AUC: 0.9409222241751082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05377902352785225, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05497316001118093, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06722248069494655, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968390802418963, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07968391197315161, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015599282878773059, AUC: 0.5407698276268578\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.5524260716408677, AUC: 0.5015657620041754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11978564844862027, AUC: 0.9139088107067685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07340439111302852, AUC: 0.9480919352003875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07707412790807878, AUC: 0.9465690414235681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09149119770057947, AUC: 0.93681544799441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09437108089217981, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10226070411950658, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10844649241824575, AUC: 0.9234769990526122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09961208398791327, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08762902009067575, AUC: 0.9363106746172939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08431077250289128, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08795604547852068, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06707655075420751, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07084632857739308, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06297408868067013, AUC: 0.9491357765365045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.060657404471134796, AUC: 0.950162470581679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0643150870597634, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07200358175589677, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08006703434029969, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06999738073250275, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08281496889102533, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0463973059170488, AUC: 0.46369811336931405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02979510862141169, AUC: 0.9606769750464048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04302833193824405, AUC: 0.963971398318708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05525272085059504, AUC: 0.954260673116906\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06357253017386047, AUC: 0.9475871618232714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0654430665831635, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06500816542662942, AUC: 0.9445156533332191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06618620001751443, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06827274662120496, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07164887414462325, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06036619814286321, AUC: 0.9450375740012775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051713994817950956, AUC: 0.9516939380039696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.053290361203021885, AUC: 0.9511977382723247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051698676794458866, AUC: 0.9517025116494409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.053830346212130405, AUC: 0.9486224295139172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061091101194267194, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07678412008976591, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0357409293607155, AUC: 0.509280971222559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.9069048326701604, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12669682354660508, AUC: 0.9034618237001282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06777129953198799, AUC: 0.9516767907130272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08346871164768133, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0887531868912912, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06713460246968714, AUC: 0.9527292056946153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1044485514702017, AUC: 0.9265570811881358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1014305375377584, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09451355549119274, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09119383296611146, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08017094337668725, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07318942344460182, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07237565492744524, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06677350938690375, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06499191347363079, AUC: 0.9486224295139172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06250119850995871, AUC: 0.9486224295139172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06571368499819043, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07334378441915256, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07249819714090099, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07715264511898191, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08941518100398915, AUC: 0.9311857780368924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01376787081021453, AUC: 0.5789032592713259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.6267676185623706, AUC: 0.5026096033402923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03714513285066277, AUC: 0.96163507992781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052500705047670605, AUC: 0.9542435258259636\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07611975857436533, AUC: 0.9337267922134151\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09940229143415179, AUC: 0.9183349551812683\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.077038660306121, AUC: 0.9321953247911245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08238154464626904, AUC: 0.9265485075426646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09581089612119686, AUC: 0.9162901407363905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07546073013210888, AUC: 0.9296285896781882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06830857160422125, AUC: 0.9357887539492354\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.058108918168283154, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06455781987982014, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05512310802072719, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08048488585351664, AUC: 0.9286104692784849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07641082274000591, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07374612440974075, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.080895735857156, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089573980611797, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089573980611797, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089573980611797, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089573980611797, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089573980611797, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574375507995, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574770404191, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089574770404191, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575165300389, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575165300389, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575165300389, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575362748487, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575362748487, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575362748487, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575362748487, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575362748487, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575560196587, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089575560196587, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957634998898, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957634998898, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957654743708, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089576942333276, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089576942333276, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089576942333276, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089576942333276, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089576942333276, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577139781376, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577139781376, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577337229474, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577337229474, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577337229474, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577337229474, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089577732125672, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957792957377, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957792957377, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957792957377, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0808957792957377, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578324469968, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089578719366164, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579114262362, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579114262362, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579114262362, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579114262362, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579114262362, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579706606657, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08089579706606657, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021925456282021343, AUC: 0.5853302782576638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05767826214586973, AUC: 0.9295750043939933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0575150337772093, AUC: 0.9552444989347246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06295039490883395, AUC: 0.9532254054262602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07426535762368275, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08625460362088853, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07900854667521412, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07069210779099237, AUC: 0.9434975329335157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08088975515424834, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.074849205727903, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07851006723091963, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05886623035059706, AUC: 0.951711085294912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0604118896073683, AUC: 0.9475957354687427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05768344713293988, AUC: 0.9491443501819756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04851468799030312, AUC: 0.9573493288979007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.054393318128881984, AUC: 0.9527377793400866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.059288680430031215, AUC: 0.9486310031593884\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07124958670163994, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712498098179914, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125003293434286, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125025605069431, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125047719256478, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125069833443526, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125091750182473, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125113469473324, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125135781108469, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125157895295517, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712517902224207, AUC: 0.9347792071950033\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.07125200938981019, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125222065927572, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125243192874127, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125264714716878, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125285051871037, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125307166058084, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125327898108441, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125347840366403, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712536857241676, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125389699363313, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125410628861768, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125431360912125, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125451500618186, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125471837772346, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125491187686012, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125510142703481, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125530874753838, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.071255508170118, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125570364373564, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125589319391033, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125609261648995, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125628611562662, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125648356372526, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125667311389994, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125686068959365, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125705221424931, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125723781546203, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125743921252264, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125761691581142, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125780844046709, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125799009271784, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125816582152562, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712583553717003, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125854689635598, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125872065068278, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712589062518955, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125909185310822, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125927153087798, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125946897897661, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125964273330342, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125982043659218, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07125999813988096, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126016597076479, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126033380164863, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712604976835705, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126065761653039, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126081360052831, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712609755079692, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126112754300515, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126129142492701, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126145925581084, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126160734188483, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126176332588274, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712619291822856, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126208714076451, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126224312476243, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126239713427937, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126255904172024, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126271305123719, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126287298419708, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126303094267598, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126318100323095, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126333896170986, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126349692018877, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126364698074372, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126379309233671, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712639549997776, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0712640991368896, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126425117192554, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126439925799952, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126456313992138, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126470135359043, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126484943966441, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05485869934840232, AUC: 0.46945638800889944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03072969118754069, AUC: 0.9591283603331717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05307405878544841, AUC: 0.9537130315124339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.056597901180417395, AUC: 0.9532254054262602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05680078107624567, AUC: 0.9527120584036729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06832636760135122, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07699386920494569, AUC: 0.9342487128814736\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07012202576820895, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07843851006549338, AUC: 0.9322038984365958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06288916033000433, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06548559690360944, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05988451955728156, AUC: 0.9450461476467487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05159035775478829, AUC: 0.9511805909813824\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05315757538220897, AUC: 0.9501710442271502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05746263105183161, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04986040834067525, AUC: 0.9522158586720281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000717810715701, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700072373415866, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000729855049717, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000736963181269, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700074407131282, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700074979730768, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000755918198738, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000762236537894, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700076855487705, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000775663008602, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000781981347758, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000788694583111, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000794223129873, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000800936365226, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000806662360087, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000812980699243, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000818706694104, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700082502503326, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700083094847622, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000837069367276, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000843585154531, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700084970604559, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000855234592351, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000860565691014, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700086688403017, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000873004921228, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000878928364188, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000884456910948, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000890775250106, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000896698693064, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000902819584122, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000908348130884, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000914271573842, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000919997568703, AUC: 0.9337439395043577\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0700092611845976, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700093204190272, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000937373001383, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000942704100047, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000949022439203, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700095514333026, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000960869325121, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000966595319981, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000972518762939, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000977652413505, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000983180960266, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000988906955127, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000994632949988, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700099996404865, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700100569004351, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001011021142174, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001017142033232, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001022078235697, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001028001678657, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001032937881123, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001038663875983, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001044192422744, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700104912862521, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700105505206817, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001060383166832, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001065911713594, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001071835156553, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001077166255217, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001082497353879, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001087631004443, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001093159551205, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700109849064987, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001103821748532, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001109350295294, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700111408904966, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001120209940719, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001125146143185, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001130477241847, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001136203236709, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001140941991076, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700114607564164, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.070011518016365, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001156540390868, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001161476593333, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001166807691997, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700117213879066, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001177272441224, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0700118220864369, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001187737190452, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001192870841016, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07001198004491581, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029936047074217233, AUC: 0.47315698773540016\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052764141288109696, AUC: 0.9400219914006336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.048908656181509205, AUC: 0.9629447042735336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06151289969497586, AUC: 0.9537558997397899\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07290824550525989, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07679675874255952, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06801490704712167, AUC: 0.9486310031593884\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08028752068308323, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06908213771401478, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07686189292133719, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0651835941133045, AUC: 0.9455509210238647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06682060668187112, AUC: 0.9429841859109285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0554295830104662, AUC: 0.9522244323174993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05248101947223671, AUC: 0.9527292056946153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05272247875205725, AUC: 0.9522158586720281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05556624473745532, AUC: 0.950162470581679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06273211998475511, AUC: 0.9435061065789869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05698397144767808, AUC: 0.9501710442271502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06632226742572667, AUC: 0.9409393714660506\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.020360056164348595, AUC: 0.565892752268801\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10311835942554672, AUC: 0.5020876826722338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018450313966960393, AUC: 0.8721465836166209\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007610927210584684, AUC: 0.9470652411552128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008284045302349588, AUC: 0.9393650358164038\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009023732033328733, AUC: 0.9373202213715262\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007552950278572414, AUC: 0.9434718119971021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009972232962740628, AUC: 0.9301419367007755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011294158595936145, AUC: 0.921415037316792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01173164977790406, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010671385573551028, AUC: 0.9265485075426646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010545500070165156, AUC: 0.9265485075426646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009865750437197477, AUC: 0.9291152426556011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010036579076794611, AUC: 0.9280885486104264\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009229626961623166, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009148996068824152, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007930288156860857, AUC: 0.940408877152521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009503829306450443, AUC: 0.9260437341655485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00829987150788554, AUC: 0.9363106746172939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00835624491452677, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009202688377096046, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008626718205201207, AUC: 0.9296371633236594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009618620447984146, AUC: 0.9255303871429612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01130957139451558, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011308716937868737, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011307891111196199, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011307097863459932, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011306332258457476, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011305591334467348, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011304877065970538, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011304185997625315, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011303519610292422, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01130287346138964, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011302250512638447, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011301647308697118, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011301061875084666, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01130049569266183, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011299946786947625, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011299414664321805, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011298900312024861, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011298400768335316, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129791553963292, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011297444625917676, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011296990495290815, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011296546730689134, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011296117281074602, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129569967834599, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011295293428883049, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129490001354652, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011294515483374427, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011294144280948994, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011293782457308246, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011293430999692676, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011293088920861791, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129275770167633, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129243240593383, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011292117476216508, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129181340614461, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011291515753135918, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011291226985291664, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129094562175111, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011290670675273761, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011290403626720357, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129014299523016, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011289890261663906, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01128964394516086, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011289404045721018, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011289171550584875, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011288944485271447, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011288720381679496, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011288505163251984, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011288293400166198, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011288088547763864, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287887150703257, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287694638807088, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287504595012151, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287319487419682, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287138328789184, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011286963093601646, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01128679032651534, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011286622989251746, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011286459600950127, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01128630016161048, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01128614664571379, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285997572399321, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285849486325345, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285704361972848, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285566148303804, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285429415495499, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285298112509907, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285166809524315, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011285040936361436, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284918024920034, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284797087959621, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01128468158082192, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284568048165204, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284458464470463, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284348880775721, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284244233283443, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284141066651907, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011284041848982343, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05264693313503858, AUC: 0.5132109159654139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005579612084797451, AUC: 0.9447964402224004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005140378238251491, AUC: 0.9583074337793057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006375994494736318, AUC: 0.9506500966678526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006201600436098087, AUC: 0.9501367496452654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008525227661211792, AUC: 0.9378421420395846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008342254976308123, AUC: 0.9383554890621719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009771963577586425, AUC: 0.9280885486104264\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00915296378836622, AUC: 0.93116863074595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007678759517630188, AUC: 0.9383554890621719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008568668217392442, AUC: 0.9327086718137119\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066823949478181, AUC: 0.9450290003558063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007357698296414646, AUC: 0.940408877152521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006243003821521072, AUC: 0.9470823884461554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006139795602478596, AUC: 0.9486224295139172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006483936655348626, AUC: 0.9434889592880444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006281285305694517, AUC: 0.9465690414235681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007355000661767047, AUC: 0.9337353658588864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006517041790806235, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006957698559415513, AUC: 0.9383554890621719\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.006214706794075344, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006384726883708567, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007002416111174084, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007347306602983494, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007347672128776093, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00734803395241684, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00734838985261463, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007348742791090939, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00734909054655466, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007349433612626038, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007349771742494951, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007350104689351274, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007350435414916486, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007350760463848864, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007351080329768653, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007351397974397332, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007351711670064038, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007352019935908031, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007352325486840668, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00735262758243158, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007352925235440272, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007353219433107238, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007353511656293218, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007353798943276731, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007354083021728642, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00735436389164895, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007354641553037655, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007354916252704881, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007355186262979764, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007355454792393907, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073557208537068175, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007355982719247632, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073562408826365975, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007356497071544576, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007356751039161445, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007357002045056835, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073572505828509915, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007357495665303422, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007357738526464742, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007357978179094461, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007358214623192576, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007358450326860321, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007358684549667327, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00735891334265162, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007359142629256159, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073593672264683566, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007359590589629938, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007359810497449792, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073600299116494, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007360245623697159, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007360459361263931, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073606716179699634, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073608806661443925, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007361089714318822, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007361296541202142, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007361499912743736, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007361701803424591, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007361901719624458, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00736209892091297, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073622961222014815, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007362491102198883, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007362684848145669, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007362877853662084, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073630659229760335, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073632542391001065, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007363441567983686, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007363624947905293, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007363806106535791, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007363988005596659, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364165955695553, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364344893034941, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364521855893342, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364697091080881, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364869858167186, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007365041884823122, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007365211196567701, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007365380508312281, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007365546858335381, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00736571320835848, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007365877337090471, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073660409722022145, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04957388449406278, AUC: 0.3247439695121167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037070518941859525, AUC: 0.9500327941939273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005270868724917773, AUC: 0.9572893133796024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00679345086494588, AUC: 0.9470738148006842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008803719319171788, AUC: 0.9332220188362992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007747943603720971, AUC: 0.940408877152521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010073184720230893, AUC: 0.9209016902942047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009578009816677181, AUC: 0.9260437341655485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074000348709138035, AUC: 0.9414355711976954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008904697485345245, AUC: 0.9321953247911245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008003174394801043, AUC: 0.9373287950169973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007699569313175683, AUC: 0.9373287950169973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007073320957444469, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00691066148611823, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006174854610277259, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007150653973376035, AUC: 0.938868836084759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008440827237399716, AUC: 0.9291238163010722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007707749094281878, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00794451676046873, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008465107923709088, AUC: 0.9275837752333104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010052285332610641, AUC: 0.9147500996686286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00976712289063827, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009766887186970523, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009766651730112902, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009766421209457745, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009766189701562096, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009765964610729651, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009765740013517455, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009765518871646985, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00976530044468787, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009765083498589493, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009764869267402476, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009764657257506566, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009764447468901767, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009764239901588076, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009764035049185743, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763829703163163, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763629786963294, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763430364383674, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763233656715409, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763038429907884, AUC: 0.917316834781565\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.009762844930771222, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00976265439335604, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009762465089991472, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009762277514297769, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009762092900325547, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009761908533163445, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009761726387292455, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009761545969092327, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009761367278563063, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009761189081654045, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00976101409327663, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009760840585759954, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009760668065483773, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009760498013308824, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009760328948374367, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009760161857920897, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759994520657305, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759830145115191, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759666510003448, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759505342992936, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759344669602673, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759184983452901, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759029246265103, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758872521836812, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758718512319877, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758565243233312, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00975841370181761, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758263394452524, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758113087087439, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757964754203338, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757818395800226, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757673271447729, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757527159854739, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757384256793351, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00975724258778258, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009757102152822427, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756961717862273, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756824491433723, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756685784144431, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756549544956373, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756414786629055, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00975627953468149, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756146750835158, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009756013966988827, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00975588241719311, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755752348258135, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755622526133283, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755494678489416, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755366584035427, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755239723632054, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009755115331329915, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754990198597404, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754866793535757, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754742894853865, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754622204703575, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754500280502667, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754379590352377, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754259887442579, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754141418583398, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009754022949724217, AUC: 0.9178301818041522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04913886684315052, AUC: 0.5157347828509944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00558070767493475, AUC: 0.9468584019582207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006306897409213996, AUC: 0.9536873105760204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00776064321861504, AUC: 0.9470738148006842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01011334665073371, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009453642689169811, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008769628177271619, AUC: 0.9409307978205793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009415543844487603, AUC: 0.9337439395043577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010112119510800696, AUC: 0.9270704282107232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008320103274122281, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074732128384197224, AUC: 0.9434975329335157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008245592778760701, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006617108363789308, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00677272844018403, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066221392179374615, AUC: 0.9460642680464522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00682890686682786, AUC: 0.9445242269786902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007219838553087065, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007077722569183286, AUC: 0.9404260244434632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007089892282742645, AUC: 0.9404260244434632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007860850103153206, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007533065774179146, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007536372042590787, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00753943495622086, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007542288821676503, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075449617753117725, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007547478991759243, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007549854539195943, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007552107915621613, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007554251708352541, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007556296036603781, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007558251266400513, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007560123567995818, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007561922566984504, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007563653199569038, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00756531990833164, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007566927382664651, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007568481299200907, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007569984372851764, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00757144079938932, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007572853046914805, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075742235835294545, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007575556111385116, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007576850630481791, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007578111336591574, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007579338723334713, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075805340247618236, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007581702423885495, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075828414526044954, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007583953579020056, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007585039543562547, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075861020611433265, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007587143106243378, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007588161198001964, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075891585577101935, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007590134198127573, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007591089846924966, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007592028959444098, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007592949067583735, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075938546139261, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007594740909078847, AUC: 0.9368325952853523\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007595611408383703, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007596466111840668, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007597305266259867, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007598132573793146, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007598943838668413, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00759974325665776, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007600528112849834, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007601301862586359, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007602062037766103, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007602811600110546, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007603549068758947, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007604274690521429, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076049926611700906, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007605695823211354, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007606389853278056, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007607074257749948, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00760774804938654, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007608415177149802, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007609071198457516, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007609718581410916, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007610358066440369, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007610987925875014, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007611609393765467, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007612224444592715, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007612831597496017, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007613430852475373, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007614022703151031, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007614606655902744, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007615184438401374, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007615752842115319, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007616317296867291, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007616872619644702, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076174222657892764, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007617965248060523, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007618502800509056, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00761903368908426, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007619559147836752, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007620077202285545, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007620590073721749, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076210989961959805, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00762160100798676, AUC: 0.9368325952853523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034283287530113206, AUC: 0.3598337570143137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01638102482071081, AUC: 0.8418666112237594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006226068698101162, AUC: 0.9506072284404968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00685599008208723, AUC: 0.9486052822229747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008216145616140424, AUC: 0.9398955301299337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009419712961090277, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008669853457259341, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009789448593961032, AUC: 0.9296371633236594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008697490761245506, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009655764877919578, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008449491753588058, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007891745300766844, AUC: 0.9373459423079397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006989239659121811, AUC: 0.9435061065789869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006935212676322732, AUC: 0.9435061065789869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00703928436058155, AUC: 0.9404260244434632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008180043958975909, AUC: 0.9322124720820669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008091743935215794, AUC: 0.9337525131498288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008188032955856798, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008189081158450425, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008190091599095188, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008191068226753062, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00819200857332281, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008192918809057516, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008193799180767304, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008194651416123036, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008195476995985454, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008196274192683692, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008197047942420217, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008197797011144413, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00819852287971702, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008199227522619023, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008199911680280792, AUC: 0.9327258191046544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008200577573993438, AUC: 0.9322124720820669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008201222242035481, AUC: 0.9322124720820669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00820184938655877, AUC: 0.9322124720820669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008202458267132935, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008203052585909826, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008203630862028702, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008204193095489564, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008204739533102537, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00820527486425996, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008205793905949247, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008206302828423478, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008206796201859943, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008207278222030734, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008207748888935855, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008208207708955058, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008208656162949083, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008209095238158421, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008209523206912213, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008209942784121812, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008210350514445493, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008210749853224982, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008211138085548922, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008211517926328672, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008211889622374352, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00821225440773658, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008212611541984985, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008212959791068952, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008213301869899837, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0082136362976169, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00821396529551125, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008214287876342395, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008214603299679964, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008214914527245437, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008215216622836348, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008215514769465287, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008215806252220896, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008216094032824656, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008216375643175334, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008216653057753917, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008216923068028799, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008217190363392326, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008217452722553387, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008217710885942352, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008217965100369345, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008218212157302762, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008218458226995686, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00821869911367602, AUC: 0.9316991250594797\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.008218936545014629, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008219169533771017, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008219399560805926, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00821962613249911, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008219846040318965, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008220064960898327, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008220280919756209, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008220491695601502, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008220700990586053, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008220907817469373, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008221109461340104, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008221307649869109, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008221504604347498, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00822169884391453, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008221888887709465, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222078437884155, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222264285906994, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222448159448848, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222629071269224, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222807021368118, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008222985958707506, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008223158478983687, AUC: 0.9316991250594797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018476145608084544, AUC: 0.5439688690932941\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09103534532629926, AUC: 0.5020876826722338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043352746074984535, AUC: 0.9584178194647474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004800809096105351, AUC: 0.9557664196027831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006323644586725018, AUC: 0.94246226524287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007105405039422014, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007303276170608173, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009094724003572642, AUC: 0.9198835698945014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008242177913894812, AUC: 0.9255303871429612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074770778849504995, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007825267487677975, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006911183983149242, AUC: 0.9347792071950033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007230500009982976, AUC: 0.9301590839917179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00641890761768349, AUC: 0.9337525131498288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065199218181349475, AUC: 0.9337525131498288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0071789391539358455, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007186029268347699, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070234418655774605, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008045925116687088, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00801959590635438, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008009105735684034, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008000989384779526, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007994312677324188, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00798862197631141, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007983649492757414, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007979226161727746, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007975239190996063, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007971606886411553, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007968270753974993, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007965182912522469, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007962307574586098, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007959618825102939, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007957089514959426, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007954704341927918, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007952446769730151, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007950302976999224, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007948261363659339, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00794631156368532, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007944448887684825, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007942662229202303, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007940948626516274, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007939300922133167, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007937712452179651, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007936180501744368, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00793470136867547, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00793327011677049, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007931883290687704, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007930542618097973, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007929239954267229, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007927975546005597, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007926747418832088, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007925552611025224, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007924388654483772, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007923256536448224, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007922151814336363, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00792107473495831, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007920023077022956, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007918994619239192, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007917993310568989, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007917011006278282, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007916053382999902, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007915114764101016, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007914195149581625, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00791329552668222, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007912415895402801, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007911550825920658, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007910705748058501, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007909874244753125, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007909059524536133, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007908259612926538, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007907473769493972, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007906701253808063, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007905943546729553, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007905197686536958, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007904465154091024, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007903746443011993, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007903036370287277, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007902339131688974, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007901652752736094, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007900976246188147, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007900310105665376, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007899656305648772, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789901015674599, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007898373386627893, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789774599529448, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007897128476366, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007896518361741219, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007895918859951738, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789532700927608, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007894741575663628, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789416478040549, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007893596129881423, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0078930353772813, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789248079493426, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789193312327067, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007891392609100658, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007890858018373604, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00789033009151988, AUC: 0.9214321846077342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007889810309400223, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00788929595710328, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007888788021869542, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03448933054448161, AUC: 0.3165754287894441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006433423261464752, AUC: 0.9264692013220561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005368376987567846, AUC: 0.9562540456889567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006442728496733166, AUC: 0.9527120584036729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006763167016007638, AUC: 0.9501538969362079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006992706847733839, AUC: 0.946560467778097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068638709761341165, AUC: 0.9460556944009809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008477408693443914, AUC: 0.9352839805721194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008379075838171917, AUC: 0.9342572865269448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007617931681883755, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007052800916983721, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007195518870778212, AUC: 0.9368240216398812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007660847026122036, AUC: 0.9337525131498288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007599677605164964, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006566793775459747, AUC: 0.9424794125338123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006046131037283635, AUC: 0.9440108799561029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065849849155970985, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006811798482701398, AUC: 0.9373459423079397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007912871013270154, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007930437970605697, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007944665586973076, AUC: 0.928619042923956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00795665364828169, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007967026337333347, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007976177563084826, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007984367216595952, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00799178287356043, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007998560032735948, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008004803588424904, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008010591779436384, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0080159840870101, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008021035549803551, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008025786891487073, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00803027241866781, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008034518540028953, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008038551911063816, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008042393017012634, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008046060615444776, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008049567787296777, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008052927613505172, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008056153421816618, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008059256812306912, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00806224296798864, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008065123242127476, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008067905532647364, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008070594282130524, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008073199116171765, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00807572052839133, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00807816715714354, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008080541470529624, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008082848898372295, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008085092649203157, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008087276425174058, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008089402941196354, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008091477380282637, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008093498755192411, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008095472002128143, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00809739687427971, AUC: 0.9281056959013688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008099278801469822, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00810111753688836, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008102916535877046, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008104677772916869, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008106399767147087, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00810808819520054, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008109741576216483, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008111360897435412, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00811295084824967, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008114509947798514, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008116040170562933, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008117541516542929, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008119016207029607, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008120464735643217, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008121887102383757, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008123286022162585, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008124661248169577, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00812601401445535, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008127345308260394, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008128655376394836, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008129944218858676, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008131214303753144, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008132463656597255, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008133694251871998, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008134907076817861, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00813610213143485, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008137280402963453, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008138441397783426, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008139587090375754, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008140717727550562, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008141832815687602, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008142931861166628, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008144016838468627, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008145087500783474, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00814614384811117, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008147186620882086, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00814821804038733, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008149236872576284, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008150243364259076, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008151237021815456, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008152218338865671, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008153189043080584, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008154149134460196, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008155096144903274, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03265158730264036, AUC: 0.4455176981476639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004041561120291921, AUC: 0.9484927531261654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007135966796559083, AUC: 0.9450118530648639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005808332938832032, AUC: 0.956314061207255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007532906581649622, AUC: 0.9424708388883412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00904625049535779, AUC: 0.9332305924817703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009343620166028261, AUC: 0.9311772043914214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008370712677144116, AUC: 0.934770633549532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009133715560470802, AUC: 0.9291238163010722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008176763852437338, AUC: 0.9357973275947067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009014822187877837, AUC: 0.9301505103462466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008292977113901458, AUC: 0.9332391661272416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007771622813759877, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007465737453405408, AUC: 0.9358059012401778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007775213160623428, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006523123685864435, AUC: 0.9435061065789869\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.006389501919163927, AUC: 0.9460728416919232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006722068687897044, AUC: 0.9435061065789869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007762929173976985, AUC: 0.9352925542175905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009586327317832172, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00958775017819296, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009589010143872374, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009590131402262496, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009591128021540355, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009592018265655075, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009592817190024177, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009593533186191851, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959417612656303, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009594757858023634, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009595285291257112, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009595761634795068, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009596196514232313, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959659289129032, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959695323407033, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009597284206445667, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959758877013781, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009597868652817625, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959812607577622, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009598365234785692, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009598586623466287, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009598793943969853, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009598986949486268, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959916761449652, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959933618581073, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00959949365066939, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009599642477173737, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009599783899374383, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009599916930030839, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600044530864582, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600165221014872, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960027900048171, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600387350125836, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600492984858607, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960059294295854, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600689198906625, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600783480373722, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600874306499094, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600959209181506, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960104337143355, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601122350673005, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601199849051719, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601277347430432, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601350896847174, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601422718593053, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960149305947819, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601561425882343, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601628311425756, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601692728867935, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601756652689869, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601819095651063, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601881785422378, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009601942747522832, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602001241522053, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602061216382013, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602116748659753, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602174749038728, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602228553645606, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0096022835923031, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602338137340348, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960238996746624, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960244475931361, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960249708305975, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602549159995763, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602601483741903, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960265454791841, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602705637613932, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960275499963859, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602806089334113, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602855204548648, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602904319763184, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009602952941357473, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603002303382131, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960305092497642, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603098559330215, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603147180924504, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603192840797314, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960324047515111, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603286135023918, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00960333204170685, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0096033791824404, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603423855072717, AUC: 0.9224588786529089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049260889768106844, AUC: 0.42213522353637156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003478883401207302, AUC: 0.9516757190073434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00466739168818693, AUC: 0.9634666249415921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00559030260358538, AUC: 0.9542692467623772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006014064232014721, AUC: 0.9511977382723247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006102104858335254, AUC: 0.9506843912497375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010020210135797536, AUC: 0.9193702228719141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01018617686277591, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010259471571470146, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00877130303076829, AUC: 0.9280971222558976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007882124642160862, AUC: 0.932717245459183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007996070212212162, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008036322475220105, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006803960780426089, AUC: 0.9399041037754048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007782962504874599, AUC: 0.9316905514140085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006860007904084326, AUC: 0.9388859833757015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007269810692370555, AUC: 0.9342658601724161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00795770431897655, AUC: 0.9306724310143051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007568332225886438, AUC: 0.9337525131498288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008454835933187733, AUC: 0.926565654833607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008396751145151584, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008386258012759759, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008378119202134032, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008371484699209777, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008365900620170261, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008361095967500107, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008356891063429553, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008353161022036218, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008349820200207317, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008346800725158945, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008344050519955085, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008341529107735517, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00833920785852594, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008337057401921685, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00833505848673313, AUC: 0.9270790018561943\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.008333190874530168, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00833144419928762, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008329801184296855, AUC: 0.9270790018561943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008328252944393435, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008326789607172426, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008325404508760504, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00832408901080335, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008322840398389608, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0083216483054941, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008320511498066209, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008319422571802237, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008318381526702185, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00831738219251297, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008316422841563729, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00831550051213298, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008314611255258753, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008313754577320802, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008312928503838139, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008312131060329776, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008311358544643868, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008310610463160166, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008309886322258422, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008309183653837406, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008308499496175636, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008307838045045209, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008307194857863905, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00830656944101148, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008305959326386699, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008305365748040177, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008304786484680807, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008304221042688343, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008303669175252658, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008303131622804124, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008302606904482002, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008302094773476168, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008301591280824649, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008301101115919788, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008300619342559119, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008300147935223628, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008299687387533563, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008299234737767443, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008298791219975885, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00829835560010827, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008297928618594973, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008297508794575251, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008297097115289597, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00829669185306715, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008296294488768646, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008295903788343472, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008295518764551136, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008295139911011879, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008294767721345953, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008294399974262245, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00829403987829236, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008293684965335064, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008293334494959987, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008292989948027869, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008292648609627355, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008292313194669798, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008291981481864092, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008291655692501345, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008291334098910693, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008291016454282015, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008290703252235555, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008290394245961192, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008290088695028553, AUC: 0.9275923488787815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061714282934216484, AUC: 0.48462423855311165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13275880596405723, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014244692419379888, AUC: 0.8914662219802549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007615262924020582, AUC: 0.9450204267103351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008134265617307422, AUC: 0.9445070796877478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00818761584674843, AUC: 0.9429756122654572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008473283509043186, AUC: 0.9419489182202827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009180616888200275, AUC: 0.9327086718137119\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008622483190295613, AUC: 0.9332220188362992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007794336749406582, AUC: 0.9414355711976954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008022410035380172, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007374629964492829, AUC: 0.9434975329335157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006491863456078445, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0067336408741479085, AUC: 0.9465776150690393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007204615551492442, AUC: 0.9414441448431666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007243586869960492, AUC: 0.9404174507979921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007023850829951758, AUC: 0.941957491865754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007238388308333561, AUC: 0.9393907567528175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007207918611372479, AUC: 0.9388774097302303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006106690096805802, AUC: 0.9481176561368011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007454009776776869, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074456453816984505, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007441460222437762, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007439018036267772, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007437535201047025, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007436630888755277, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007436100987420566, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007435816908968655, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074357031295018165, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074357085593245295, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007435800372690394, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00743594993962511, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007436144672812389, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007436373959416928, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074366234844515785, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074368907798151055, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007437168688013934, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074374552345670775, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007437744742841701, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00743803918731879, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007438334372226249, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074386332592855575, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00743892943143351, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007439224863151093, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007439519060818058, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074398112840040375, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007440102026329278, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007440389560122915, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007440674132195072, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074409564829761195, AUC: 0.9373373686624684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007441235625225565, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00744151180575353, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007441785764990386, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007442055281645023, AUC: 0.9378507156850558\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007442323564249042, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007442586170220227, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007442849023001534, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00744310570552976, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007443362634868109, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007443614134383745, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007443864399848764, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007444112444022675, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007444355058373871, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007444596932294699, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007444835597683924, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007445074756693396, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007445308485880155, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007445543202307407, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007445772242101824, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074459983201747605, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007446222917386957, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007446445540118168, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007446664954317776, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074468841217072606, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007447102548666376, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007447316286233148, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007447528049318934, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007447740306024966, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007447949601009519, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007448154700221976, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00744836029305468, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007448562430545657, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007448763087175895, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007448962016135269, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074491611919047665, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007449359133623649, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007449552879570434, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007449749340428575, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007449939137413388, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007450131896119681, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00745032144629437, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007450510749658936, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007450695363631159, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007450880224413507, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007451063604335113, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007451246490636474, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007451426168406231, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007451606586606359, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007451784289895131, AUC: 0.9378507156850558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007451962980424396, AUC: 0.9378507156850558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074521399432827965, AUC: 0.9378507156850558\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.01358366753003612, AUC: 0.6782589498141662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006157473500964557, AUC: 0.8113187124099231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036347206088079924, AUC: 0.8869436239942042\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003718408862009305, AUC: 0.8900580007116125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003705520560775978, AUC: 0.8895618009799677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035029232625388702, AUC: 0.8947124184967827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003581276221304947, AUC: 0.8947124184967827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003708448839483794, AUC: 0.8921456833838464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003623495314185417, AUC: 0.8936857244516082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003668522242433536, AUC: 0.8916323363612592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037191137517214316, AUC: 0.8890656012483228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003765161980259739, AUC: 0.8880389072031483\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814869539091059, AUC: 0.8870122131579737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003846834905399299, AUC: 0.8864988661353865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003798147536212613, AUC: 0.887525560180561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037115150850505316, AUC: 0.88957894827091\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037287801936052847, AUC: 0.8885522542257356\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003770579956086279, AUC: 0.887525560180561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003841925605236867, AUC: 0.8859855191127992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00391415668570477, AUC: 0.8829054369772756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00396786293874863, AUC: 0.8823920899546883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004028943261251193, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004097278320517846, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004142232563184655, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004171168828849713, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004190260085506716, AUC: 0.8772671933742868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041963367975523256, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004193941258495639, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004188569312757093, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004182311565486047, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004175533419070037, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00416730476955943, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00415548564978021, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041382180731242245, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004118253108630763, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004098716483106278, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004079241930327801, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004060108222329592, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004041880924509179, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004024804008673437, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008886853607051, AUC: 0.8829140106227468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003994009139374917, AUC: 0.883427357645334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003980005256384303, AUC: 0.883427357645334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003966731067523206, AUC: 0.8839407046679213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003954171270563983, AUC: 0.885480745735683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003942819979373466, AUC: 0.885480745735683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003935588195950842, AUC: 0.885480745735683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003944979938167469, AUC: 0.885480745735683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003997304548141132, AUC: 0.8844540516905087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004067069748667209, AUC: 0.8829140106227468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004103019987821086, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004120007681797257, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004130461818189601, AUC: 0.8808606225323976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004138455134247648, AUC: 0.8803472755098104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004145638913101291, AUC: 0.8803472755098104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004152712367829822, AUC: 0.8803472755098104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041600038793022836, AUC: 0.8803472755098104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00416778888761627, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004176714775725181, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004188785024804852, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00420861856290766, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004238963497351415, AUC: 0.8793205814646359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004270344293882635, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0042945603159397034, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004312672230027477, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004326822348016143, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004338334312596923, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004347988537379673, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004356262599952966, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00436347636623659, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043698517185313855, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004375544764240336, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043806776743744716, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043853453474261995, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043896135582933765, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004393538579684113, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043971743396103505, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044005546510589785, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004403709131244794, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004406665546306665, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004409445738940506, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004412069453956178, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004414550759530709, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044169066855626075, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004419146857646682, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004421281888618232, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004423322144502438, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00442527515300806, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004427148688653982, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044289473174274835, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044306769627715245, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004432345522610051, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004433954354398739, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004435509504985612, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004437012578636469, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004438468264743655, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004439879648433709, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004441248210567372, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004442578517131924, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004443870321317243, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004445127572085299, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012547605032753007, AUC: 0.6420395845211404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048996918443320455, AUC: 0.8081936186356757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028449723315781936, AUC: 0.8943437517415216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003508335746840167, AUC: 0.8884579441255523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004176309883717918, AUC: 0.8792948605282223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004414510529480612, AUC: 0.8777805403968741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003901537407505833, AUC: 0.8906142159615558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038115285938570957, AUC: 0.8936942980970796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003876291323399198, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038894695031223337, AUC: 0.8906142159615558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037446979656969785, AUC: 0.8947209921422539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037992716329191536, AUC: 0.8942162187651379\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003926139564000795, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003882519576860511, AUC: 0.8931980983654345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038865006241492355, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003908943932495749, AUC: 0.89217140432026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003896146704197917, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038681500446722376, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038631373310681455, AUC: 0.8937114453880217\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0038461243390543365, AUC: 0.8947381394331964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003850038871014834, AUC: 0.895773407123842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003896840981074742, AUC: 0.895773407123842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003857188590071463, AUC: 0.8968001011690165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038406683544688095, AUC: 0.8973134481916039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038899865703306336, AUC: 0.8962867541464292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003966753033624179, AUC: 0.8952600601012548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004016225629218123, AUC: 0.894224792410609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004077302743189083, AUC: 0.8931980983654345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004140633356990775, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0042136943364982525, AUC: 0.8916580572976727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004289366320300053, AUC: 0.8901180162299109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004338614071871676, AUC: 0.8890913221847364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004374570851493819, AUC: 0.8890913221847364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004405569339144057, AUC: 0.8896046692073236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004428068426578435, AUC: 0.8890913221847364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00444179292050948, AUC: 0.8885779751621492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004450774340896133, AUC: 0.8880646281395619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004457620113285926, AUC: 0.8885779751621492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004463708302002269, AUC: 0.8880646281395619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004470334166572208, AUC: 0.8880646281395619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004480512492651772, AUC: 0.8880646281395619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004504806630112863, AUC: 0.8880646281395619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004558887417518821, AUC: 0.8875512811169746\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004612426950324396, AUC: 0.8870379340943872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004638872901845423, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004651386668716652, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046582052919928825, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00466236638726655, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004665111779673005, AUC: 0.8854978930266255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004667013945293229, AUC: 0.8854978930266255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004668373498857391, AUC: 0.8854978930266255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00466940750986893, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046704512698803385, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004672426861512241, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004678074370753444, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004692799926544569, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004716686210276918, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004737932612930519, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004751897623326715, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047608891629284215, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00476697550056884, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004771310596979429, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004774527026506191, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004776994510713818, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004778935178713275, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004780496622958292, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004781779295169049, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004782850697914265, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004783759082573048, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00478454159406895, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004785223160224425, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004785826117355631, AUC: 0.8849931196495093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004786362188943425, AUC: 0.8849931196495093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004786844826139525, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004787284765184295, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047876880529257575, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004788059255351191, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004788407257625035, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004788731319316919, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004789036253224249, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00478932489766344, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004789598610090173, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004789861092656295, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00479011246876687, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004790353602257328, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004790585233558038, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004790809460555051, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791025296007871, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791233727156992, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791437592318833, AUC: 0.8855064666720968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791635904252899, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791827922528822, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004792016485463018, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004792201222840303, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004792380777204999, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047925561357976, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004792727422023165, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047928952529070045, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004793059134828872, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004793220795459629, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047933778901031055, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027686804224492108, AUC: 0.37013499204794387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0225743872285136, AUC: 0.5903394306242041\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056027243102806205, AUC: 0.8069633005105605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005720937720983912, AUC: 0.8304497305731912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004699240806927098, AUC: 0.8613019938012543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050970779936259335, AUC: 0.8592829002927899\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00464219620015557, AUC: 0.8757185786610538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004963761654453001, AUC: 0.8700717614125939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004744336224984431, AUC: 0.8782853137739901\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047485529759409015, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045984629271686945, AUC: 0.8839407046679213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004472014943511836, AUC: 0.8901008689389686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004374064397120821, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043551582480562895, AUC: 0.8936942980970796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044005729150081024, AUC: 0.8911275629841431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045377939137366, AUC: 0.8890827485392652\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00454658183498659, AUC: 0.8890827485392652\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044657137576590905, AUC: 0.8895875219163812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004394856669147563, AUC: 0.8921542570293176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044430363499106335, AUC: 0.8921542570293176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004517841166344242, AUC: 0.8906142159615558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004530987260751349, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004554683747498885, AUC: 0.8911275629841431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004624789175779923, AUC: 0.8885608278712067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004638040781514739, AUC: 0.8885608278712067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004626020758295158, AUC: 0.8885608278712067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004604578511808723, AUC: 0.889074174893794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004580178739614862, AUC: 0.8901008689389686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004559811968240679, AUC: 0.8901008689389686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045816424470510545, AUC: 0.8885608278712067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004636129854135138, AUC: 0.887020786803445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046409491920076295, AUC: 0.887020786803445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00463850774626801, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004641862142653693, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004661536488226975, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004695885670111046, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004731989425161611, AUC: 0.8844540516905087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004773418478837418, AUC: 0.883427357645334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004814068599764111, AUC: 0.8829140106227468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00485017494632097, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004891369406974587, AUC: 0.8808691961778689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004951374871390206, AUC: 0.8798425021326943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005009250241036741, AUC: 0.8798425021326943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005047445711882218, AUC: 0.8798425021326943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005074461177762744, AUC: 0.8798425021326943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050955661582156985, AUC: 0.879329155110107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005113275895207565, AUC: 0.8788158080875198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005128957593416328, AUC: 0.8788158080875198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005143391296236658, AUC: 0.8783024610649326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005157029530029613, AUC: 0.8777891140423453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00517013440714613, AUC: 0.8777891140423453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005182873635064988, AUC: 0.8777891140423453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051953551932151275, AUC: 0.877275767019758\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005207700141962024, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005220104078328388, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005232981766726413, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005246793014415796, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005260583900270008, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00527164481935047, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005279652944015913, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005285831465237383, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005290899340904031, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005295219875517346, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005298991504416456, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005302343556105967, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053053587119771825, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053080984277508025, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005310606512223712, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005312919986914404, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053150689626579204, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00531706824806166, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005318936724100054, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005320693395152595, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005322348133624217, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00532391081191985, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005325391919469734, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005326798983982631, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005328136077825574, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005329412949998433, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053306333026530575, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005331799110270435, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005332918640989694, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005333994856532316, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005335026769657807, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005336024869796405, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005336985084581079, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053379114863788615, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005338807160316293, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005339671736178191, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005340510150167019, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053413249937890725, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005342114909588674, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005342881008211377, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005343626744998908, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005344351009305713, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005345056269233025, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005345744869477013, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005346414712151632, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005347069005788483, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005347706022716704, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00534832995870839, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033704700430481085, AUC: 0.41411243478670917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01681344010568307, AUC: 0.6328100551714085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005648539056442292, AUC: 0.8363098172527468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005374314868919104, AUC: 0.858649522233606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004732655812494503, AUC: 0.8756242685608708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005899949350218842, AUC: 0.8592657530018476\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059762648914171304, AUC: 0.8597791000244348\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006314428696721237, AUC: 0.8582733535385579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006493180188086215, AUC: 0.8552018450485055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006283213879997932, AUC: 0.8587952742066163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006113947054861002, AUC: 0.8623972770101984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00610878674880318, AUC: 0.8623972770101984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00619647418983728, AUC: 0.8618839299876111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006201998540826959, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006080232298398857, AUC: 0.8618839299876111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005973570835516319, AUC: 0.8618839299876111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005989937061602038, AUC: 0.8618839299876111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005961984581088427, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005928831811277022, AUC: 0.8634239710553728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058987397338045805, AUC: 0.8639373180779601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00587159506282451, AUC: 0.8644506651005475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005841007390624494, AUC: 0.8649640121231348\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005797428003749492, AUC: 0.865477359145722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005747160802963605, AUC: 0.8665040531908965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005696711086091541, AUC: 0.8670174002134838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005646329859028692, AUC: 0.8680440942586582\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005595428603036063, AUC: 0.8690707883038329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005543665362687832, AUC: 0.8700974823490074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005490148042793353, AUC: 0.8706108293715946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005434632054520443, AUC: 0.8700889087035362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005376256524159054, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005302716856417449, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005207550945242493, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005137829430108238, AUC: 0.8767624199971706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005143449543425755, AUC: 0.8767624199971706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052367078591577755, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052760200224060945, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005266129230120167, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00524639910545902, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005229407832736061, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005217292787619013, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005208178336575905, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052000781517344725, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005192452582760134, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051891802507404465, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005227993487324527, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005307998099435684, AUC: 0.8736823378616472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005360261006878523, AUC: 0.8731689908390599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005432651526686074, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005480270454849022, AUC: 0.8721422967938852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00549113775138776, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005488571913346001, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0054820161428510775, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005474562847342797, AUC: 0.8731689908390599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00546700033835496, AUC: 0.8731689908390599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005459134252915472, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005450462949448737, AUC: 0.8741956848842344\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.005440972112967608, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005432539228079975, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005429400667147113, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005431940590125927, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005431285432653644, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005422973854941611, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005409968935925028, AUC: 0.8741956848842344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005395377644840975, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053813920257994845, AUC: 0.8757357259519963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005371981526013487, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00538142238344465, AUC: 0.8762490729745834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005439360689672624, AUC: 0.8752223789294089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005518960286371456, AUC: 0.8747090319068216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005561793319433619, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005584625477129381, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005600722433370587, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005613042207484906, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005623035425972001, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005631438693644838, AUC: 0.8726556438164725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005638691702738065, AUC: 0.8721422967938852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005645080752994703, AUC: 0.8716289497712981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056507881136908045, AUC: 0.8711156027487108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005655950764444797, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005660661629268101, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005664997095893876, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005669016645561835, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005672759644486642, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005676266199313336, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005679563335750414, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005682675858215269, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005685621537036777, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005688420980860235, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005691086900406989, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005693630402132591, AUC: 0.8706022557261235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005696063703138142, AUC: 0.8700889087035362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005698398403499437, AUC: 0.8700889087035362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005700638452178449, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005702792734339618, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005704868160666393, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005706868063095441, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005708799352310212, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057106668411081125, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057124696656537105, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005714219179212677, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02300099556490501, AUC: 0.48841807667411147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013714954719780395, AUC: 0.6559438940640366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005513011051754527, AUC: 0.813542501704012\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004461362988805672, AUC: 0.8518988481307309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036589594608014663, AUC: 0.8812625121638595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046700767355182405, AUC: 0.8638773025596618\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004411964066033531, AUC: 0.8695326934535929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00437074381372203, AUC: 0.871586081543942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004530726505856089, AUC: 0.8715946551894133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004294107172553337, AUC: 0.8777548194604604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041884023457086856, AUC: 0.8823749426637458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00419564239727044, AUC: 0.8823749426637458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004290387743995303, AUC: 0.8813568222640425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004552079036862707, AUC: 0.8757100050155826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046068642203605445, AUC: 0.874683310970408\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004650141635049698, AUC: 0.8736566169252334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004681722717995969, AUC: 0.874683310970408\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004722992332332129, AUC: 0.8731432699026462\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004791205220587752, AUC: 0.8716118024803556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004850276755496829, AUC: 0.8710984554577683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004892735994627264, AUC: 0.8690450673674194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004929736287450691, AUC: 0.8675050262996575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004968243109266704, AUC: 0.8680183733222449\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005014502483865489, AUC: 0.8675050262996575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005073478750066974, AUC: 0.8654516382093085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005142228697150884, AUC: 0.8633982501189594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005210726897909034, AUC: 0.8613448620286104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005265393859357814, AUC: 0.8598048209608484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005308956586549494, AUC: 0.8593000475837325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005343157805764651, AUC: 0.8587867005611451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053479646797259155, AUC: 0.8582733535385579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005305729297377308, AUC: 0.8587867005611451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00526128841976695, AUC: 0.8587867005611451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005220844632103329, AUC: 0.8593000475837325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005181233334985579, AUC: 0.8598133946063197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005141579833336745, AUC: 0.8603267416289069\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005101896467662993, AUC: 0.8613534356740815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005062317255861271, AUC: 0.8634068237644306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005022702503401794, AUC: 0.863920170787018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00498246973839359, AUC: 0.8644335178096051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049406596098874175, AUC: 0.8654602118547796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004896492938324038, AUC: 0.8685402939903033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004849563967860757, AUC: 0.8690536410128905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004800744431853047, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004757537358049033, AUC: 0.8711070291032396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004742762070018065, AUC: 0.8716203761258268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004751793346049623, AUC: 0.8711070291032396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004743488185400795, AUC: 0.8716203761258268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047260675864683665, AUC: 0.8721337231484141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004714268581714196, AUC: 0.8710984554577683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004735440694520685, AUC: 0.8705851084351811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004799405980554426, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004841690231307446, AUC: 0.8690536410128905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00486027799531293, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00485264934121205, AUC: 0.8675135999451288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048384538101606984, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004824524340422257, AUC: 0.8675135999451288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004811141308296788, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004798248934696427, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004785777865976527, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004773668620897376, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047618846715607255, AUC: 0.8685402939903033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004750414171080658, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047392467534319955, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004728400929373984, AUC: 0.8664869058999541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004717907056551789, AUC: 0.8670002529225413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004707789198952432, AUC: 0.8685402939903033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00469806660776553, AUC: 0.8685317203448322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004688774576838713, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004680157077978857, AUC: 0.8700717614125939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004673350548398667, AUC: 0.8710984554577683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004672638007572719, AUC: 0.8710984554577683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004687468827881428, AUC: 0.8716203761258268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00471609065744941, AUC: 0.8690536410128905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047401687126475585, AUC: 0.8690622146583618\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004755663452187927, AUC: 0.8690622146583618\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004765556095549779, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004772323999345672, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004777292533937695, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004781151780430574, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004784285528566033, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004786915167024664, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004789182735032423, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047911810331956696, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004792970776804732, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004794594293795758, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004796080460953169, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004797457661441147, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004798740950677212, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004799944026623207, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004801077872329617, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004802150262315327, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00480316884769416, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004804139675314135, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004805066447327103, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048059538531254045, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004806806211886199, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004807627472571458, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004808418745826737, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00480918114229759, AUC: 0.8675221735905999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004809916883275128, AUC: 0.8675221735905999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009568001666177627, AUC: 0.656307202290878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004112532049972819, AUC: 0.8279237202762428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002206146717071533, AUC: 0.9185225036759505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031858664121687044, AUC: 0.8961924440462463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003325100641072907, AUC: 0.8967400856507182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033509565929942, AUC: 0.8982972740094223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037557479017269538, AUC: 0.8906056423160847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003821644970595713, AUC: 0.8901008689389686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003835459550221761, AUC: 0.8885608278712067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003766705654175879, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003965420382363456, AUC: 0.8880560544940906\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004053636984301897, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004093486206378502, AUC: 0.8844711989814509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004122298820171791, AUC: 0.8829311579136891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041305641209857065, AUC: 0.8829311579136891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00411563753834916, AUC: 0.8834445049362765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004066511093953134, AUC: 0.8849845460040382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008183568160726, AUC: 0.8865245870717999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003952688435343235, AUC: 0.8860112400492127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038986078947474004, AUC: 0.8870379340943872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038427202104288107, AUC: 0.8885779751621492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037821601636661506, AUC: 0.8906313632524981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003716841741131453, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036507846158977376, AUC: 0.8931980983654345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003591673591368934, AUC: 0.8937114453880217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035565142552551523, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003545657941766901, AUC: 0.89217140432026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035254288904415154, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003497023019731415, AUC: 0.8926847513428473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034672172420019934, AUC: 0.8931980983654345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003441406086118078, AUC: 0.8952514864557836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034248596886423555, AUC: 0.8952514864557836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003419564624257216, AUC: 0.8957648334783708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034207717725702447, AUC: 0.8952514864557836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003422838066922458, AUC: 0.894224792410609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003423310584903504, AUC: 0.894224792410609\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003422474145395662, AUC: 0.8952429128103123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003421142728185555, AUC: 0.8947295657877251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003419763059596344, AUC: 0.8947295657877251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034184053571081063, AUC: 0.8957562598328996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034166609031566677, AUC: 0.896269606855487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034137091774871383, AUC: 0.896269606855487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034091663903577972, AUC: 0.8952429128103123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003403551953673116, AUC: 0.8952343391648412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033983167407428748, AUC: 0.8947124184967827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033994692206135942, AUC: 0.8947124184967827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003429407288569101, AUC: 0.8941990714741954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003493001372177408, AUC: 0.8936942980970796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003534762755684231, AUC: 0.8936942980970796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035543723136001494, AUC: 0.8926676040519048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003564237314228192, AUC: 0.8926676040519048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003570936111189564, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00357703651700701, AUC: 0.8921542570293176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035834179161498263, AUC: 0.8926676040519048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035902867652861476, AUC: 0.8911189893386721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035976534304411516, AUC: 0.8906056423160847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036055133456275577, AUC: 0.8911189893386721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036139973202107115, AUC: 0.8911189893386721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036238285078518634, AUC: 0.8906056423160847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003637875706019115, AUC: 0.8900922952934973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036624670028686523, AUC: 0.8890656012483228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036954510779607865, AUC: 0.8890656012483228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037241975466410318, AUC: 0.8885522542257356\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037505662465934673, AUC: 0.887525560180561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037856398161894046, AUC: 0.887020786803445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003833088568772342, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038733388572992993, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00389977913218749, AUC: 0.8839407046679213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003918186107777661, AUC: 0.883427357645334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003932035364226032, AUC: 0.883427357645334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003943009652953217, AUC: 0.8829140106227468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003952032167225397, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003959639965870859, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003966188332062083, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00397190951412509, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003976972823804457, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003981501049136523, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003985587237537771, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039893018532984005, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003992699688265783, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039958276363633435, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003998719633983036, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004001405545149777, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004003913382812563, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004006260547085085, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004008466906182268, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004010547145306447, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040125138517739115, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00401437739160984, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004016146526573608, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004017834090791627, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004019443909820809, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0040209838815851, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004022461286983135, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00402387871752121, AUC: 0.8813739695549849\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004025239751946112, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004026553769042526, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004027817930494036, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004029040381034709, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004030224082386025, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00403136804730749, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05783585534579512, AUC: 0.30556258118170554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0363514250603275, AUC: 0.4764267617769737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006731455864126391, AUC: 0.773038457086761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039625162910477225, AUC: 0.8754356483605046\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004042336289186655, AUC: 0.8884493704800812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0042171083375287105, AUC: 0.8936685771606657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037665991556076776, AUC: 0.9029173972127078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036807135518786825, AUC: 0.9075375204159931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003962164216406844, AUC: 0.902925970858179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038526561689673005, AUC: 0.9044660119259409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037339764105360452, AUC: 0.9075460940614645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036279941691128117, AUC: 0.9101128291744008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003474551328220723, AUC: 0.9126795642873372\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032802285861771546, AUC: 0.9162729934454481\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003228771760596992, AUC: 0.9188568758493268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033117035407704103, AUC: 0.9183521024722108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003240088004750001, AUC: 0.9193787965173852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00317407468831317, AUC: 0.9204054905625598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031182313064117115, AUC: 0.9219455316303216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030719447826993637, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00303608160581648, AUC: 0.9239989197206706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003008693209839657, AUC: 0.9245122667432579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029828187471591166, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029650062754534292, AUC: 0.9260523078110197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029832085220463283, AUC: 0.9245122667432579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002985823475302623, AUC: 0.9255389607884325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002976134080077304, AUC: 0.9255389607884325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029619074509504174, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029466695790458662, AUC: 0.9255389607884325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029317452177004292, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029177928563230526, AUC: 0.9245122667432579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029071510825344742, AUC: 0.9239989197206706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002920883474389465, AUC: 0.9234855726980834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00295762572722899, AUC: 0.9234855726980834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002971031527588333, AUC: 0.9219455316303216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002970307571794182, AUC: 0.9219455316303216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029672271346453554, AUC: 0.9229807993209673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029639367237841367, AUC: 0.9229807993209673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029609402637797606, AUC: 0.9229807993209673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029584556879710955, AUC: 0.9240074933661419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002956892886270401, AUC: 0.9240074933661419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029582444185055562, AUC: 0.9239989197206706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029714505494751547, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003012502785795224, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030612907301071513, AUC: 0.9219455316303216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003093034275817081, AUC: 0.9214321846077342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031131838542827663, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031289893277683615, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003143198371673963, AUC: 0.9198921435399725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003156593744305597, AUC: 0.9193787965173852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031688795820279643, AUC: 0.918865449494798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031794336765202428, AUC: 0.9173254084270361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003188832576230446, AUC: 0.9178387554496236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003199330521419675, AUC: 0.9173254084270361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003215709088011558, AUC: 0.9162987143818616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003241573431477043, AUC: 0.9152720203366871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003267658670002876, AUC: 0.9137319792689252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003286930221454944, AUC: 0.913218632246338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033011869614168726, AUC: 0.913218632246338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033124127496596944, AUC: 0.9127052852237507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033216791123336885, AUC: 0.9127052852237507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033295674106842738, AUC: 0.9121919382011634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033364316938333137, AUC: 0.9121919382011634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033425165506129925, AUC: 0.9127052852237507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033480201695523155, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033531200071299297, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003358009562482498, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033629811822010617, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033687118664538144, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003376981733255011, AUC: 0.9116785911785762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003391617573566318, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003415427222755385, AUC: 0.911165244155989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003440846814378695, AUC: 0.9106518971334017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034585306363076156, AUC: 0.909625203088227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034695080101613427, AUC: 0.909625203088227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034767868109124543, AUC: 0.909625203088227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003482020049361709, AUC: 0.909625203088227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003486054407637065, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00348934228869452, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034921303792523053, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034945687398653838, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003496752269026162, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003498738473493367, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035005689407727734, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035022720540285606, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003503870272981948, AUC: 0.9091118560656398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035053806275314424, AUC: 0.9085985090430526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035068102751706206, AUC: 0.9085985090430526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035081720500258927, AUC: 0.9085985090430526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003509472245755403, AUC: 0.9085985090430526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035107186368780355, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003511913568089961, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003513063950074632, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035141737317940214, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035152429132481295, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003516275443398928, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003517276258448883, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003518242890296762, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035191812623855245, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035200916215252925, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035209754485768067, AUC: 0.9080851620204653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03605250640932324, AUC: 0.45852284662176934\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015834899175734746, AUC: 0.634966327007412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004192320271308378, AUC: 0.8578618185559409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004223114708689182, AUC: 0.8730232388660496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036308222429105707, AUC: 0.8879703180393788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034877325930703995, AUC: 0.8900580007116125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003358499110362051, AUC: 0.8910932684022583\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002901446621857321, AUC: 0.9003335148088292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026946389897269493, AUC: 0.905980332057289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00265724818158594, AUC: 0.9095737612154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025827752630656303, AUC: 0.9126538433509236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026605745033200976, AUC: 0.9121490699738074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027371913996789275, AUC: 0.9111309495741041\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0026936536620122305, AUC: 0.9131843376644532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002623818305708607, AUC: 0.9167777668225641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025568506362275306, AUC: 0.9183178078903259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025034236488381775, AUC: 0.9203711959806751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024904191617393097, AUC: 0.9214064636713207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024843849627374367, AUC: 0.9229550783845537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002470844280645714, AUC: 0.9234684254071411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002462858492296428, AUC: 0.9244951194523156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024558609933833402, AUC: 0.9250084664749028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024563300560226597, AUC: 0.9250084664749028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024793294275769536, AUC: 0.9250084664749028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025083776833354564, AUC: 0.9234684254071411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002527396069303556, AUC: 0.9229550783845537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025377066239066744, AUC: 0.9229550783845537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002539021196325867, AUC: 0.9234684254071411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002534721208655316, AUC: 0.9224417313619665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002528577240851108, AUC: 0.9239817724297283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025225414992859647, AUC: 0.925017040120374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025171473406363225, AUC: 0.9245036930977868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025120512669130884, AUC: 0.9245036930977868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002507575920649937, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025067425045661056, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025181429726736887, AUC: 0.9250256137658452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025497433068095775, AUC: 0.9245122667432579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002605463036839266, AUC: 0.9229722256754961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002676100772853717, AUC: 0.9219455316303216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002745313797431456, AUC: 0.920918837585147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028019258077593818, AUC: 0.9173254084270361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028322397058301338, AUC: 0.9173254084270361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028565082367409335, AUC: 0.9162987143818616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028782332659261322, AUC: 0.9157853673592744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002889121911540535, AUC: 0.9157853673592744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002893793286744112, AUC: 0.9157853673592744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002897154778920839, AUC: 0.9152720203366871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029004766580727776, AUC: 0.9152720203366871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029038398162178373, AUC: 0.9152720203366871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002907072164997551, AUC: 0.9152720203366871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029099095558774643, AUC: 0.9162987143818616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029119480840908074, AUC: 0.9162987143818616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002912674569688722, AUC: 0.9157767937138032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029117378018657615, AUC: 0.917316834781565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002909277228341586, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029057747458819277, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002901649808291323, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028971469426994243, AUC: 0.9188568758493268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028923842477502288, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028874431090818923, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002882379552592402, AUC: 0.9183435288267394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028772332530090775, AUC: 0.9188568758493268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028720314828505427, AUC: 0.9193702228719141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028668023167683224, AUC: 0.9203969169170886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002861621340362675, AUC: 0.9203969169170886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028566074544104977, AUC: 0.9203969169170886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028519089300933585, AUC: 0.9198749962490302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002847639793688219, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00284383601777055, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028404536701384046, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002837398345919623, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028345418272551545, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028317870560640133, AUC: 0.9203883432716173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002829077204315312, AUC: 0.9209016902942047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002826440470065636, AUC: 0.921415037316792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002824079854641395, AUC: 0.9219283843393792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028226863029827487, AUC: 0.9219283843393792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002824423969655797, AUC: 0.9219283843393792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002834982198217641, AUC: 0.9224417313619665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028629348638388435, AUC: 0.921415037316792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002905248484996535, AUC: 0.9198749962490302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029457615646022693, AUC: 0.9183349551812683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002976508861249525, AUC: 0.9167949141135066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029957641232334557, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030078768853568634, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030163598109969937, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003022773912481146, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030278799820143737, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030320966712683133, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003035673073359898, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030387700467869854, AUC: 0.9152548730457447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030414957560861086, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003043924737914502, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003046115177758732, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030481069971562418, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030499325282331824, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003051618117970216, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030531809196709106, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003054639320689452, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030560051062092277, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030572891975781933, AUC: 0.9157682200683319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061322962522013094, AUC: 0.45641694495290924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023487004187289724, AUC: 0.5693522182164246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026132712453048423, AUC: 0.8672124506479533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016548761299678258, AUC: 0.9191987499624903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020674020360468832, AUC: 0.906476531788934\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022220973766121557, AUC: 0.9090775614837552\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022739922901611645, AUC: 0.9101128291744008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002317780478400473, AUC: 0.9101128291744008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002489740927520499, AUC: 0.9060060529937027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002612566602402839, AUC: 0.9024126238355918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026589276627724213, AUC: 0.902925970858179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026490229257145285, AUC: 0.9044660119259409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002722676743138157, AUC: 0.904474585571412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027220037536344666, AUC: 0.9039612385488247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027027826131500814, AUC: 0.904474585571412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026861076893026537, AUC: 0.9055012796165867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026806465217045377, AUC: 0.9049879325939995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026856361585621013, AUC: 0.9039612385488247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002695851999780406, AUC: 0.9039612385488247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002736092354199901, AUC: 0.9039612385488247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027704667107165478, AUC: 0.902421197481063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027867833279674836, AUC: 0.9019078504584757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002878223516926262, AUC: 0.8993411153455394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002998649827195004, AUC: 0.896774380232603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003092632900854075, AUC: 0.8931809510744921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003134345539361547, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003157316527751662, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003182179068926699, AUC: 0.8911275629841431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032110664661873446, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032461310272137818, AUC: 0.8911275629841431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032880928205407185, AUC: 0.8895875219163812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033564578672373516, AUC: 0.889074174893794\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.003451438424009714, AUC: 0.885480745735683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003506724385247714, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035452031941147323, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003580499633252004, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036063444787177486, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036261485230108226, AUC: 0.8818873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036427766146373552, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036585007641873253, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036741513643205534, AUC: 0.8813739695549849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003690080366272857, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003706708087684205, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037266990906456737, AUC: 0.8798339284872232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037579573459506775, AUC: 0.8793205814646359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037845934646717014, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003794562495766713, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037997050314956572, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003802799290011388, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038048483076549714, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038062963426483344, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003807375396507374, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003808210972179784, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038088815552847727, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003809432435479964, AUC: 0.8788072344420487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038098992768281735, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038103003432785254, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038106510604637256, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003810960066738089, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038112371111014864, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038114888574272456, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003811715552525491, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038119237368644887, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038121153849252263, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038122943222646142, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038124596850472206, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038126154222350188, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003812759312536899, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003812896292155327, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003813023522773885, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038131437193039287, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038132578689859522, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003813365107984523, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038134663001350736, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038135626794882195, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038136533822085298, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003813741370017484, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003813824298218911, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003813903277458365, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038139773204953526, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814048401810861, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038141154107593353, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038141799516065765, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814241037112092, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038143005183518056, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038143575314902862, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038144123233376575, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038144634130331794, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038145125282477146, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038145594221711404, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814605699069258, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038146496312712044, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038146913421820408, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038147286105106584, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038147676065101387, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814804134408386, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814838441015524, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00381487336464797, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814905079748813, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00381493704165978, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003814967275899883, AUC: 0.8782938874194613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021009211214432805, AUC: 0.57150634664106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010830806896059655, AUC: 0.6951125933991503\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005081790574589131, AUC: 0.8224237267064769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004581857418668443, AUC: 0.8520274528127987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004323569513996196, AUC: 0.861832488114784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004026878324354657, AUC: 0.8741699639478208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003568495035665129, AUC: 0.8864988661353865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030818197791374, AUC: 0.902925970858179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00303600145422894, AUC: 0.9024126238355918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030467610798513914, AUC: 0.902925970858179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031888492359137682, AUC: 0.8998458887226555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032216354926920825, AUC: 0.9003678093907139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033059989566881958, AUC: 0.8988277683229521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003302542010696285, AUC: 0.8952343391648412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003310544890646609, AUC: 0.8957476861874285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034664196750885706, AUC: 0.8916409100067304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003557371303408289, AUC: 0.8901008689389686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036402376788990344, AUC: 0.8880474808486195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037146477225404348, AUC: 0.887020786803445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037603990385004205, AUC: 0.8865074397808577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003792239765696397, AUC: 0.8859940927582703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038238541680093137, AUC: 0.8844540516905087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038580821661228473, AUC: 0.8839407046679213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038969039176561817, AUC: 0.8824006636001597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003940045216562338, AUC: 0.8803472755098104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00399118427410876, AUC: 0.8793205814646359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004056281801583111, AUC: 0.8767538463516995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004109117555322114, AUC: 0.875727152306525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041455136569637195, AUC: 0.8747004582613505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00416368381824059, AUC: 0.8726470701710014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041713726940115535, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004176345424375672, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00418092017341598, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041857727072500545, AUC: 0.8747004582613505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004191084431318516, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00419676279182513, AUC: 0.8747004582613505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00420252469755848, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004208101125484174, AUC: 0.8741871112387631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004213569327170805, AUC: 0.8736737642161759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004219742418569561, AUC: 0.8736737642161759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004222993031298398, AUC: 0.8731604171935888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004212526430994828, AUC: 0.8736651905707047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004200659800266874, AUC: 0.8736651905707047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00421873592688677, AUC: 0.8736651905707047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0042906076518151575, AUC: 0.8710984554577683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004336460776951002, AUC: 0.8700717614125939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004366118098391263, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043887630506085065, AUC: 0.8685317203448322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004404789048939264, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004413039664550845, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00441691433667643, AUC: 0.8695584143900066\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004423094708973823, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004445704860963683, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004500711186331992, AUC: 0.8690450673674194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004549742979045733, AUC: 0.8685402939903033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00457661381419401, AUC: 0.8670002529225413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004593878922748763, AUC: 0.8664869058999541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004606302110304743, AUC: 0.8664869058999541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004615875257961992, AUC: 0.8659735588773669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004623595602023675, AUC: 0.8654602118547796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004630033150469541, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004635532203421583, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004640324021965327, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046445606411367225, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004648351891440634, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046517821819392294, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004654909513011482, AUC: 0.8644335178096051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00465778016155551, AUC: 0.8644335178096051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00466043596188721, AUC: 0.863920170787018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004662903569499898, AUC: 0.863920170787018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004665205073899611, AUC: 0.863920170787018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004667365402908799, AUC: 0.8634068237644306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004669396897033628, AUC: 0.8634068237644306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004671315105311866, AUC: 0.8634068237644306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046731357001863405, AUC: 0.863928744432489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004674864728505073, AUC: 0.863928744432489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004676511692457811, AUC: 0.863928744432489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004678083009107759, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004679587687024419, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004681027577283713, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004682412799100698, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004683745203551299, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004685028863002548, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00468626772641642, AUC: 0.8629020503873144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004687464755514394, AUC: 0.8629020503873144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004688625873739428, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004689749723635846, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004690837292444138, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004691896971708499, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004692926293327695, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004693924887086541, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004694898059402687, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004695848525187491, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046967741865549025, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004697676524365664, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004698558500341254, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00469941851021587, AUC: 0.8629020503873144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00470026161359704, AUC: 0.8629020503873144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004701085095573409, AUC: 0.8629020503873144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004701892534891765, AUC: 0.8629020503873144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004702684671982475, AUC: 0.8629020503873144\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.03036915244029422, AUC: 0.4360813296009396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05187304321036329, AUC: 0.5033790880213312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050742147378546355, AUC: 0.506510612029682\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04732129983526826, AUC: 0.5126879235916716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04314999353317987, AUC: 0.5244863314657076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03908389350148708, AUC: 0.5419487038791458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035198644081257884, AUC: 0.5532423383760657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03160225728036948, AUC: 0.5706961371440329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028421125550200974, AUC: 0.5912214444020525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025730320632334328, AUC: 0.6086752431700198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0232769717340884, AUC: 0.6281824300283358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021329399961862505, AUC: 0.6492210843089427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01981926063079518, AUC: 0.666683456722381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018459425703092145, AUC: 0.6779856648647722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01736062900867028, AUC: 0.6882697526074599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016526876275830635, AUC: 0.6985366930592053\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015849254146125747, AUC: 0.7067502454206015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015122789773881805, AUC: 0.7149723714274691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014375131816350648, AUC: 0.7262660059243891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013740892982877806, AUC: 0.7355148259764311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013209092197457703, AUC: 0.7421969109155367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01274293451328949, AUC: 0.748357075186584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012340095472631988, AUC: 0.7550305864802184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011955704007829939, AUC: 0.7596507096835039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011588921951704637, AUC: 0.7647841799093766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011241798815519913, AUC: 0.7709443441804238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010915124885290553, AUC: 0.7760778144062964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01063691064190914, AUC: 0.7822379786773437\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010399665398133714, AUC: 0.7873714489032163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010175966574785379, AUC: 0.7904515310387401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009955127046715398, AUC: 0.7945754545103806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009758028431215149, AUC: 0.7971421896233168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009610851852543359, AUC: 0.8033109275398352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009498332845004696, AUC: 0.8043461952304811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009401696068899972, AUC: 0.8063995833208302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0093089929525403, AUC: 0.8089663184337665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00921054212202937, AUC: 0.8094796654563536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009105357077304374, AUC: 0.8115416271921739\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008996517515083772, AUC: 0.8130816682599357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008887389678639161, AUC: 0.8146217093276975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00878015610989083, AUC: 0.8177017914632212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008675832185686004, AUC: 0.8197551795535701\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008575350601480614, AUC: 0.8202685265761575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008476227707003955, AUC: 0.8212952206213321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008374373118082682, AUC: 0.8233486087116811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008268348672128365, AUC: 0.8259153438246175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008159501952414187, AUC: 0.8264286908472047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008051125652795007, AUC: 0.8274553848923794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007947434549746306, AUC: 0.828995425960141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007851319530242224, AUC: 0.8284735052920825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007763373679009037, AUC: 0.8295001993372572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007683614272755372, AUC: 0.8310402404050189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076124495354251585, AUC: 0.8310402404050189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007550093204585168, AUC: 0.8315535874276062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007496617595601526, AUC: 0.8315535874276062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007452383791684611, AUC: 0.8320669344501936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074170514416744, AUC: 0.8325802814727808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00738856017466164, AUC: 0.8325802814727808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007364054891140071, AUC: 0.8330936284953679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007341299985012899, AUC: 0.8336155491634265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007318882961944517, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007296002676274713, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007272690966509391, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007249971601039973, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007229192409949767, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00721101583160969, AUC: 0.8346422432086011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007195086953062448, AUC: 0.8346422432086011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007180568594369829, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007166694163288883, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007152953996915008, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007139064016796294, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007124879839010614, AUC: 0.8346422432086011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007110336305685419, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007095426999757502, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007080182525682153, AUC: 0.8351555902311883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007064659896597852, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007048946483288246, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007033136567220431, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007017324429861507, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007001577203565009, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00698592351830524, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069703295610953064, AUC: 0.8366956312989501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006954687722721455, AUC: 0.8366956312989501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006938814870072201, AUC: 0.8366956312989501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006922440005632168, AUC: 0.8372089783215375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00690520081214036, AUC: 0.8372089783215375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00688663353337511, AUC: 0.8382356723667118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006866235663925392, AUC: 0.8382356723667118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068435629455692775, AUC: 0.8392623664118865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006818372763955569, AUC: 0.840289060457061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006790726327994843, AUC: 0.8413157545022355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00676094523127775, AUC: 0.8418291015248228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0067294695362541245, AUC: 0.8418291015248228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006696761024664648, AUC: 0.8433691425925847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006663266916452728, AUC: 0.8454225306829336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00662942826130869, AUC: 0.845935877705521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006595812475705986, AUC: 0.845935877705521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006563272041810472, AUC: 0.8464492247281082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006533205879400976, AUC: 0.8459273040600498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006507761730170398, AUC: 0.846440651082637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006489572070893787, AUC: 0.846440651082637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03650257750327543, AUC: 0.5077762964423658\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03820049688682793, AUC: 0.5141336545592503\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033624335105374735, AUC: 0.5264968513287007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029233747881144963, AUC: 0.5454992648099009\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025500582858889245, AUC: 0.5609168227784612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022422726356711695, AUC: 0.5814764246183657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019830451989025805, AUC: 0.5973987559640421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01745247199175027, AUC: 0.6235966014069353\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015455578671725888, AUC: 0.6395017854616694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01394775688771629, AUC: 0.6595223193425729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012658642439121539, AUC: 0.6713378745075513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01148720261473093, AUC: 0.6928984494562166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010551220635202854, AUC: 0.7088122071564219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009763013255275307, AUC: 0.7221592297436908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009194965935148314, AUC: 0.731912823172849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008729039512065627, AUC: 0.7452684194055891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008265929192489719, AUC: 0.752455277721811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007830128166246118, AUC: 0.7581106686157421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007457542863691815, AUC: 0.7668547152906681\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00712080747197627, AUC: 0.7735368002297737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006799235106995387, AUC: 0.7822636996137573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006492262794857933, AUC: 0.7889372109073917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006227498469145402, AUC: 0.7945926018013229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005996524423792743, AUC: 0.7992212986500794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057811907359531945, AUC: 0.8100015861244122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005575353067607367, AUC: 0.8141083623051103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005413975774871637, AUC: 0.8171884444406339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00532407938323406, AUC: 0.8187284855083958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00527668295439726, AUC: 0.8187284855083958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005233992700991424, AUC: 0.8202685265761575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005183335663615793, AUC: 0.8218171412893905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051238410961553914, AUC: 0.8238705293797397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005056669746620068, AUC: 0.8284906525830251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004982628437302868, AUC: 0.8310573876959615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004902521275585482, AUC: 0.833632696454369\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004818038170382103, AUC: 0.8356946581901892\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004732194400969006, AUC: 0.8367213522353638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004650030323684092, AUC: 0.8382613933031255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004579920946441082, AUC: 0.8403147813934746\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004531283926519548, AUC: 0.8423681694838236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004505354054966328, AUC: 0.8428900901518821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004491275511913418, AUC: 0.8444387048651152\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00447686661351048, AUC: 0.8449520518877024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044570135774079315, AUC: 0.8454653989102896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00443161039865782, AUC: 0.8459787459328769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044023641394779055, AUC: 0.8464920929554642\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004371457712003656, AUC: 0.8470054399780516\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004340944823270999, AUC: 0.8475187870006388\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004312260674146885, AUC: 0.8490588280684007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004285908263662587, AUC: 0.850085522113575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004261579202569049, AUC: 0.851625563181337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004238614878052264, AUC: 0.851625563181337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004216404928677324, AUC: 0.8526522572265114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004194596169157798, AUC: 0.8531656042490987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004173213403911078, AUC: 0.853678951271686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004152822198334688, AUC: 0.8552189923394478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041347803783219296, AUC: 0.8552189923394478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004121249383527546, AUC: 0.8562456863846224\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004114381521631719, AUC: 0.8557323393620352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004114647212729444, AUC: 0.8547056453168604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00412021179376922, AUC: 0.8541922982942732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004128031725715653, AUC: 0.8541922982942732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004135132699772931, AUC: 0.8541922982942732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041391017767706765, AUC: 0.8541922982942732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004138295201287753, AUC: 0.8552189923394478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004132022645409309, AUC: 0.8552189923394478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004120421705779082, AUC: 0.8572723804297968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041041701229956335, AUC: 0.8582990744749714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004084138149553698, AUC: 0.8593257685201459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004061188263429124, AUC: 0.8598391155427332\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004036083601523137, AUC: 0.8608658095879078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004009472040409381, AUC: 0.8608658095879078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039818844686630595, AUC: 0.8618925036330822\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00395374095711402, AUC: 0.8618925036330822\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0039253985166056065, AUC: 0.8624058506556695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038971578852730507, AUC: 0.8634325447008441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038692847542140794, AUC: 0.8639458917234314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038420407421593836, AUC: 0.8639458917234314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038156983274850787, AUC: 0.8649725857686059\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037905672568958985, AUC: 0.867025973858955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037670024433491393, AUC: 0.867025973858955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003745434940725133, AUC: 0.867025973858955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037263441776883774, AUC: 0.867025973858955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037101462761067456, AUC: 0.8685660149267167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036970053647122276, AUC: 0.8685660149267167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036865963945724458, AUC: 0.8685660149267167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036781474670267993, AUC: 0.869079361949304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036707411888470065, AUC: 0.8701060559944787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003663598997499138, AUC: 0.8711327500396531\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003656216413091182, AUC: 0.8716460970622404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036483421829176244, AUC: 0.8726727911074149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036399026341566634, AUC: 0.8731861381300021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036309330606559297, AUC: 0.8736994851525894\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036215202161737604, AUC: 0.8736994851525894\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036117699822530488, AUC: 0.8742128321751768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00360177713398114, AUC: 0.8742128321751768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003591603990914165, AUC: 0.8752395262203513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003581269187216433, AUC: 0.8762662202655258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035707580376856075, AUC: 0.8762662202655258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035600311761070235, AUC: 0.8762662202655258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003549027763785289, AUC: 0.8767795672881131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020770825214267517, AUC: 0.4957924834850154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03874833835578113, AUC: 0.5125593189096038\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03817719011326508, AUC: 0.5187966459898916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03560523315492871, AUC: 0.5311512691138709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032340871127742664, AUC: 0.5450287860146694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028906444091480958, AUC: 0.5588891556245259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02564968579057334, AUC: 0.5743067135930862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022881784300873245, AUC: 0.5927957800516991\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020489690713507296, AUC: 0.613843007977777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01848976459068788, AUC: 0.6307920333686281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01690200298222449, AUC: 0.6503163675178868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015653080081347352, AUC: 0.6636633901051558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01475321975060378, AUC: 0.6754789452701342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013944832187755262, AUC: 0.6862592327444667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013125608179633414, AUC: 0.6955080527965087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01233941822565367, AUC: 0.7068016872934286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011635673218879147, AUC: 0.7170686277451741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011027977333305785, AUC: 0.7247688330839831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010499019800506023, AUC: 0.7324690384227922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010009377639486183, AUC: 0.7442760199422993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009580125473054053, AUC: 0.7514628782585211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009181505157834008, AUC: 0.7571096955069812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00881799210179173, AUC: 0.7637832068006155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008527115758654988, AUC: 0.7704652917397212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008303192091284332, AUC: 0.7745720679204194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008098941905651526, AUC: 0.7807322321914667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007889507966999188, AUC: 0.7868923964625137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007672680831103592, AUC: 0.7904858256206247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007446015596883391, AUC: 0.7956192958464974\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007212248401365418, AUC: 0.8017794601175446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069822164302533705, AUC: 0.8053728892756554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006778228356971503, AUC: 0.8079396243885918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006620604799400946, AUC: 0.8125683212373486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0064915616072976565, AUC: 0.8166750974180466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006370600212681614, AUC: 0.8202771002216287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006247676677585389, AUC: 0.8238705293797397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006119294442992279, AUC: 0.8269506115152633\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059859419461362855, AUC: 0.8279773055604378\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.005852278221714817, AUC: 0.832084081741136\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057280771974204244, AUC: 0.8336241228088977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005621212362996293, AUC: 0.8351641638766596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055288125762781495, AUC: 0.8372175519670086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005443537210578998, AUC: 0.8418376751702941\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005360766720821151, AUC: 0.8438910632606431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005279269277679254, AUC: 0.8464577983735796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005199999912925388, AUC: 0.8500512275316904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005126002782620258, AUC: 0.8515912685994522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005062349094367175, AUC: 0.8515912685994522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005015467388042505, AUC: 0.8536532303352724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004992670894409559, AUC: 0.8551932714030342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049921823337704995, AUC: 0.8541665773578597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004999336125194162, AUC: 0.854679924380447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005000370136205701, AUC: 0.8536532303352724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00499054277412146, AUC: 0.8536532303352724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049705195624389015, AUC: 0.8541665773578597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004942448489661049, AUC: 0.854679924380447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004908513455163865, AUC: 0.854679924380447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004870589722264134, AUC: 0.8562199654482088\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004830143589904343, AUC: 0.8572466594933833\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004788298414360663, AUC: 0.8577600065159705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004745966529253847, AUC: 0.8582733535385579\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004703955744117437, AUC: 0.8587867005611451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004663008834017483, AUC: 0.8608400886514942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004623756522224063, AUC: 0.8618667826966687\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004586716492970784, AUC: 0.863920170787018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004552405936871009, AUC: 0.8644335178096051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045215146882193425, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00449488091419449, AUC: 0.8654602118547796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044729266601072825, AUC: 0.8649468648321923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004455002321713213, AUC: 0.8654602118547796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004439586931627483, AUC: 0.8675135999451288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044252128334519285, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004410994102248988, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004396591744314316, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004382069930279971, AUC: 0.868026946967716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004367895624899223, AUC: 0.8685402939903033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004355043234538835, AUC: 0.8690536410128905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004345062233152844, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004339541831125137, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004338908146133581, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004341843952550157, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043462576579850155, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043505179709282474, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004353796596606079, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004355860546262121, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00435679793111039, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004356831250477034, AUC: 0.8711070291032396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004356212127282753, AUC: 0.8711070291032396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004355160099132214, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004353842503289011, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00435237509370097, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004350830926164583, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004349248256248964, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004347638684029905, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004345995915849263, AUC: 0.8695669880354778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004344293666428908, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004342495901490838, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004340552148364839, AUC: 0.870080335058065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004338391325735404, AUC: 0.8705936820806524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004335937786299743, AUC: 0.8711070291032396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004333137478640854, AUC: 0.8716289497712981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030194565869759823, AUC: 0.49042216630300123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04578652786665575, AUC: 0.5058429393886134\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04638932901386395, AUC: 0.5131841233233164\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04303964373981484, AUC: 0.5239987053795337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03916733901693214, AUC: 0.5389114899709783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035278978801908945, AUC: 0.5573834091386486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031651178008527736, AUC: 0.5763772489743777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02835964218676707, AUC: 0.60104362699498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0255372539070082, AUC: 0.6226127755891165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02327801129832771, AUC: 0.644173350537782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021202185139152573, AUC: 0.6626538433509236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01933120052266565, AUC: 0.6739389042023722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017717946883807765, AUC: 0.6939594380832759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0163220737291419, AUC: 0.7103865428060684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015171710502040065, AUC: 0.7242469124159246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014237923651748563, AUC: 0.7334871588224955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013519086699554886, AUC: 0.7427274052290663\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012898746731365197, AUC: 0.7494009165227008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012322707205825711, AUC: 0.7565877748389227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011767987632356569, AUC: 0.7627479391099697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01121429725710156, AUC: 0.7694214504036043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010738396002885965, AUC: 0.7812284319231114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010325401219275181, AUC: 0.7889372109073917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009932186292565388, AUC: 0.7935573341106771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009539934912576932, AUC: 0.7986908043365498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0091862466271126, AUC: 0.8043290479395385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008913194664269994, AUC: 0.806895783052475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008693354964009477, AUC: 0.8094625181654114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008519500185490641, AUC: 0.8110025592331731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008368560492868996, AUC: 0.8125426003009351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00820898047145109, AUC: 0.8135692943461094\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008049333811299894, AUC: 0.8171712971496916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007911834410752322, AUC: 0.8197380322626279\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0077978308403220484, AUC: 0.8202513792852151\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007694018306692688, AUC: 0.823844808443326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007590676686778572, AUC: 0.8269248905788498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007483832831214921, AUC: 0.8284649316466114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007372562436089999, AUC: 0.8310402404050189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007257598774280114, AUC: 0.8320669344501936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007140361003994201, AUC: 0.8356603636083043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00702247511032452, AUC: 0.8372004046760662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006905488099123874, AUC: 0.8413071808567644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006790716208779787, AUC: 0.8428472219245262\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006679316731960383, AUC: 0.844387262992288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006573197757728845, AUC: 0.8459273040600498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006475168972528746, AUC: 0.8474673451278116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006386410869179799, AUC: 0.8490073861955734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006304808531735501, AUC: 0.8515741213085097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006227643099877652, AUC: 0.8520874683310969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006153314997197185, AUC: 0.8526008153536843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006081004073654396, AUC: 0.8525922417082131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006010132299940532, AUC: 0.8536275093988589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059402324644921975, AUC: 0.854140856421446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005870941015997782, AUC: 0.855680897489208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005801993620815238, AUC: 0.8572209385569697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005733153588036326, AUC: 0.8577342855795571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005664161026601219, AUC: 0.8603010206924934\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.005594946336055147, AUC: 0.8628677558054296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005525983638644959, AUC: 0.8654344909183659\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005458247834357662, AUC: 0.8659478379409532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005392838215482408, AUC: 0.8669745319861278\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005330796320739494, AUC: 0.8685145730538897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005273120990697888, AUC: 0.8690279200764769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005220734307978217, AUC: 0.871081308166826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005174326600495332, AUC: 0.8726213492345878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005134116048398225, AUC: 0.8746747373249368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005099644818908186, AUC: 0.8751880843475242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050698180623182845, AUC: 0.8757014313701114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00504325833133042, AUC: 0.8762147783926987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005018720715682699, AUC: 0.8762147783926987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004995281898703881, AUC: 0.8762147783926987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049723618766042265, AUC: 0.8762147783926987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004949702239184646, AUC: 0.8762147783926987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004927363208115224, AUC: 0.8772414724378732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004905795458681095, AUC: 0.8787815135056349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004885904043604375, AUC: 0.8787815135056349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004868894877147477, AUC: 0.8798167811962806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004855571326261722, AUC: 0.8798167811962806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004845549107585141, AUC: 0.8803301282188679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004837455710022099, AUC: 0.8798167811962806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004829920596957947, AUC: 0.8803301282188679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004822152248327283, AUC: 0.8803301282188679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048138809006653465, AUC: 0.8803301282188679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00480511346465559, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004795960758043372, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004786557292345888, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047770249917640445, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004767466282499009, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004757965820423071, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004748598389003588, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004739426431201753, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004730508441016788, AUC: 0.8808434752414553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004721901184777048, AUC: 0.8813568222640425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004713657233038798, AUC: 0.8818701692866299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004705830143598789, AUC: 0.8818701692866299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046984764359752585, AUC: 0.8818701692866299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00469164522538274, AUC: 0.8818701692866299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004685388588757248, AUC: 0.882383516309217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004679735156073087, AUC: 0.882383516309217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004674698501887035, AUC: 0.8818701692866299\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0046702662856929296, AUC: 0.8829054369772756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040761949606316926, AUC: 0.38217239028948913\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05496658893845836, AUC: 0.48530905848512257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050170582520542184, AUC: 0.4967312976641103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04369879262541145, AUC: 0.5090944944335607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03749550055272831, AUC: 0.5229891586253017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03179138491612784, AUC: 0.5342570721858081\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026770247188907727, AUC: 0.5563224205115894\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022926260472331234, AUC: 0.5799706781324885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019891518736971585, AUC: 0.6030798677943868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01770238205019238, AUC: 0.6210470135849412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016067725037442478, AUC: 0.6359255035945008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014749312252731798, AUC: 0.6508039936040606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013782414343539726, AUC: 0.6600356663651601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012977266410369557, AUC: 0.6692844864172023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012208702648154943, AUC: 0.6816391095411812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011437411634077937, AUC: 0.6919060499929267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010718906888310214, AUC: 0.7006329493769103\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010146522620696706, AUC: 0.7062797666253703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009714434605947933, AUC: 0.713971398318708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009349410084710606, AUC: 0.724760259438512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009001611182408303, AUC: 0.7314423443776176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008676309516464455, AUC: 0.7365758146034903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008388456103717811, AUC: 0.7401692437616011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008122513259666553, AUC: 0.7453027139874738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00788408036557784, AUC: 0.7494094901681719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007665561593097189, AUC: 0.7514628782585211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007441481448108365, AUC: 0.7571182691524522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00721259097381655, AUC: 0.7607116983105631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006993800710200276, AUC: 0.7653318215138485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0067839773051733806, AUC: 0.7678985566267849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065758865072120054, AUC: 0.7730320268526575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0063762257558218445, AUC: 0.7817589262366411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006203556899945435, AUC: 0.7889372109073917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006064900453539862, AUC: 0.7925306400655027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005953462721151348, AUC: 0.7956107222010261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00585960724832602, AUC: 0.7976641102913754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005773128436465688, AUC: 0.8028061541627193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005689607397122907, AUC: 0.8069129303434174\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056115645552767485, AUC: 0.8084529714111791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055398222822580275, AUC: 0.8089663184337665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005474854947123715, AUC: 0.8110197065241156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005420385803988755, AUC: 0.81204640056929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00537776169569596, AUC: 0.8130730946144646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00534014302010862, AUC: 0.8125597475918772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005299023096112238, AUC: 0.8140997886596391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005250792202248583, AUC: 0.815639829727401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005195949758802142, AUC: 0.8176932178177501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051364923362652954, AUC: 0.8197466059080991\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005074131069222839, AUC: 0.821286646975861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005009483600008315, AUC: 0.8228266880436227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004942395548889603, AUC: 0.8243667291113844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004872855192385846, AUC: 0.8279601582694954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004801564828702875, AUC: 0.8315535874276062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047298041683299695, AUC: 0.8325802814727808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00465919426015692, AUC: 0.8336069755179553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045916628146517105, AUC: 0.83463366956313\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00452942556969621, AUC: 0.8356603636083043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044747423187792915, AUC: 0.8372004046760662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044292558300816, AUC: 0.8397671397890025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004392861949731104, AUC: 0.8413071808567644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00436337221236456, AUC: 0.8423338749019388\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004337660150745147, AUC: 0.844387262992288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004313136479869392, AUC: 0.846440651082637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004288314045339391, AUC: 0.8479806921503988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00426261716254256, AUC: 0.8484940391729862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004236011524871763, AUC: 0.8484940391729862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004208705933691305, AUC: 0.8500340802407479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004180994339858029, AUC: 0.8505474272633352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004153146753646819, AUC: 0.8526008153536843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004125366423194206, AUC: 0.8526008153536843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004097791438764173, AUC: 0.854140856421446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004070498805115189, AUC: 0.854140856421446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004043535045955492, AUC: 0.8546542034440333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004016931629575804, AUC: 0.855680897489208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003990706943330311, AUC: 0.8567075915343824\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003964893442750224, AUC: 0.8572209385569697\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0039395399962399566, AUC: 0.8587609796247314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00391471941278588, AUC: 0.8597876736699062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003890536710095455, AUC: 0.8608143677150805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038671549062551176, AUC: 0.8608143677150805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003844814887945203, AUC: 0.8613277147376678\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038238489849967247, AUC: 0.8613277147376678\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038046728256573093, AUC: 0.8623544087828425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037877248681109886, AUC: 0.8628677558054296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037733370719735915, AUC: 0.8633811028280168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037616021144464148, AUC: 0.8638944498506042\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037522851556971454, AUC: 0.8638944498506042\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037448771498464896, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037387798291555843, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003733427381416779, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003728394429382577, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003723393562664403, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037182641078719937, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003712914868664791, AUC: 0.8649211438957787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037073235087266374, AUC: 0.8659564115864244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037015003940827113, AUC: 0.8664697586090117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003695475018542746, AUC: 0.8664697586090117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003689292178144119, AUC: 0.8664697586090117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036830113541265453, AUC: 0.8674964526541863\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036767063427168884, AUC: 0.8685231466993607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003670455999749541, AUC: 0.8685231466993607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016233897357253554, AUC: 0.5768445126525573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02284631373719399, AUC: 0.5742209771383744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022823728636431645, AUC: 0.5815021455547792\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02070042608193976, AUC: 0.6015569740175675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01835684549240839, AUC: 0.6215775078984708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01608757844376021, AUC: 0.6492982471181834\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014212001184499041, AUC: 0.6718683688210809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01292157913587108, AUC: 0.6893221675890481\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011832355712511525, AUC: 0.7042178048895499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010866897693578747, AUC: 0.719122015835523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010054246732660456, AUC: 0.7329823854453795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009333244762065247, AUC: 0.7432578995425959\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008728869459890678, AUC: 0.7561001487527489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008200372968401228, AUC: 0.7627736600463835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007674658520621542, AUC: 0.7725358271210128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00728539280269457, AUC: 0.7797226854372346\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007033657583390704, AUC: 0.7889629318438054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006810454601580065, AUC: 0.7935830550470908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006580198526876067, AUC: 0.8012832603858998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006360293421932876, AUC: 0.8059033835891852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0061643785077839415, AUC: 0.8094968127472962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005990961817233953, AUC: 0.813090241905407\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00583159035037023, AUC: 0.8172055917315765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00568410649309494, AUC: 0.8202856738670999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005555074160637076, AUC: 0.8243924500477982\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005455283397966784, AUC: 0.8269591851607345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005386033413573081, AUC: 0.8305526143188453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053341603427199845, AUC: 0.8321012290320784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005285784571313957, AUC: 0.8326145760546656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005233831533980913, AUC: 0.8331279230772528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005175581136352033, AUC: 0.8346679641450147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005110132274667175, AUC: 0.8351898848130731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005037548625938147, AUC: 0.836729925880835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004958904061011399, AUC: 0.8398014343708873\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004876564254918701, AUC: 0.8413414754386492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004794650319693745, AUC: 0.8433948635289983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004719291908153589, AUC: 0.8464749456645219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00465641863351036, AUC: 0.8485283337548709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004607097826142242, AUC: 0.8510950688678073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004567148152345456, AUC: 0.8526351099355691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004531586268920583, AUC: 0.8526351099355691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00449750746752658, AUC: 0.8526351099355691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004464297437766571, AUC: 0.8541751510033309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004433226141129962, AUC: 0.8562285390936799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004406653452610624, AUC: 0.8572552331388545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004386653317674593, AUC: 0.858281927184029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004374723133339892, AUC: 0.8587952742066163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004371292472626112, AUC: 0.8593086212292036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004374401663154302, AUC: 0.8598219682517909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004380718644854938, AUC: 0.8598219682517909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004387695226610077, AUC: 0.8598219682517909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004394089459879304, AUC: 0.8598219682517909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043994498055420555, AUC: 0.8603353152743781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004403680871485676, AUC: 0.8608486622969654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004406921982024767, AUC: 0.8608486622969654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004409613446419283, AUC: 0.8608486622969654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044124115327870625, AUC: 0.8613620093195526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004415668439174044, AUC: 0.86187535634214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004418965081990875, AUC: 0.8623972770101984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004421520677412518, AUC: 0.8623972770101984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004422834200888687, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004422830251926715, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004421698504106352, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004419759316967634, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004417358224683173, AUC: 0.8608572359424366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004414801642021037, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004412330579066622, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004410115828425248, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004408266603576471, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004406829428228533, AUC: 0.8603438889198494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00440581232371044, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004405192213275665, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004404924671102014, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004404964160721741, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004405252188135625, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004405738404078513, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044063754210067335, AUC: 0.8598305418972622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004407121651414512, AUC: 0.8598305418972622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00440794426955545, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004408820692303265, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004409732285493649, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004410659674531925, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004411600267911797, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004412542588962531, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004413486144063883, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044144213076210415, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004415347586013763, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044162623877357495, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004417166946837621, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00441806842081295, AUC: 0.8598305418972622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004418975818231239, AUC: 0.8603524625653205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004419904934940377, AUC: 0.8603524625653205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004420879834927387, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004421922607698302, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004423059415126192, AUC: 0.8618925036330822\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.004424305312628578, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004425662644901631, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044271141352367205, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004428620911039427, AUC: 0.861379156610495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004430132252829415, AUC: 0.8608658095879078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004431580534632902, AUC: 0.8608658095879078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03947994871909574, AUC: 0.514569838772597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04209966244904891, AUC: 0.5146727225182511\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038607178761105115, AUC: 0.5224072224389449\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035163861624202375, AUC: 0.5285759603554633\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03201537102645969, AUC: 0.540400089165913\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029257503849132213, AUC: 0.548605067881838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026699177720285103, AUC: 0.5583586613109961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024311590885770493, AUC: 0.5727495252343822\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022160941769617686, AUC: 0.5850784274219477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020177232059139148, AUC: 0.5968768352959837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018343205777754695, AUC: 0.6132953663733051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016769480261003007, AUC: 0.6235708804705217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015382482398370778, AUC: 0.6379617443939076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014284124532348128, AUC: 0.651830687649235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013334345866927942, AUC: 0.6692844864172023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012483890012184286, AUC: 0.6795514268689474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011831618243863123, AUC: 0.6882783262529311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01137677384212644, AUC: 0.6908450613658675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010945123174916143, AUC: 0.6980319196820891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010497864235508763, AUC: 0.7047054309757238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010036089405509997, AUC: 0.7124227836054752\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009578102123663293, AUC: 0.7206534832578138\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009120561074519503, AUC: 0.7278489152195068\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008665463692406443, AUC: 0.7360710412263742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008237189140872679, AUC: 0.7422226318519504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007835691266425155, AUC: 0.7499314108362304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007483271338184428, AUC: 0.7571182691524522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007212727459814731, AUC: 0.7632784334234994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006992659460190167, AUC: 0.7684119036493722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006802212871132924, AUC: 0.771500559430367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066108244546451925, AUC: 0.7756073356110651\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006403505431939356, AUC: 0.7833075409498741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006186803428776269, AUC: 0.7910077462886832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005970929967197078, AUC: 0.7961497901600272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057703863759958965, AUC: 0.8002565663407253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005593081932383788, AUC: 0.8043633425214234\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005438853494869256, AUC: 0.8084701187021216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005315372662514633, AUC: 0.8105235067924706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005225030531794388, AUC: 0.8136035889279942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005162093950354535, AUC: 0.8146302829731689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005117228312521988, AUC: 0.8151436299957561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005081345822746956, AUC: 0.8161703240409306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005050112001644159, AUC: 0.8177103651086925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005025113097876002, AUC: 0.8182237121312796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005010206013239195, AUC: 0.8182237121312796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005001408960014643, AUC: 0.818737059153867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049911127821012065, AUC: 0.8192504061764543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004975969746986531, AUC: 0.8202771002216287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004955421570171727, AUC: 0.8213037942668033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004928800260058101, AUC: 0.8228524089800364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004895140048633204, AUC: 0.8243924500477982\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004854913577283145, AUC: 0.8264544117836183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004810071756627496, AUC: 0.8290211468965547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004762231686594076, AUC: 0.8305611879643164\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004712185257463475, AUC: 0.8326145760546656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004660250977699801, AUC: 0.835181311167602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004606620371958731, AUC: 0.8367213522353638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004551598250742531, AUC: 0.8387747403257129\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004495728706968003, AUC: 0.8413414754386492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004439772286030076, AUC: 0.8433948635289983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004384692904865273, AUC: 0.8444215575741727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004331723256634382, AUC: 0.8454482516193473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004282428487734271, AUC: 0.8469882926871091\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004238343633726764, AUC: 0.8490416807774581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004199958489301535, AUC: 0.8505817218452201\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041662357115103835, AUC: 0.8510950688678073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004135570294121531, AUC: 0.8531484569581563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0041068083998085795, AUC: 0.8546884980259182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004079406305869914, AUC: 0.8562285390936799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004053160023738632, AUC: 0.8562285390936799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004027979467719732, AUC: 0.8562285390936799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004003807994889917, AUC: 0.8562285390936799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003980618085920441, AUC: 0.8572552331388545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003958383208723049, AUC: 0.8587952742066163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003937014758463479, AUC: 0.8593086212292036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003916320593460747, AUC: 0.8598219682517909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038960362566677433, AUC: 0.8603353152743781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038759227124800593, AUC: 0.8613620093195526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038559176413415627, AUC: 0.86187535634214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003836141856807606, AUC: 0.86187535634214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003816826866773838, AUC: 0.86187535634214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037982682263629037, AUC: 0.8623887033647272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037808183804308652, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037649769960723307, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037514828993913795, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037412814965652875, AUC: 0.8644420914550763\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037351836822541356, AUC: 0.8644420914550763\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037332294396978973, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003734357361961349, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037368152205741675, AUC: 0.8654687855002507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003738925323723266, AUC: 0.8659821325228381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037395741875374047, AUC: 0.8659821325228381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003738305213288491, AUC: 0.8664954795454254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003735181584368088, AUC: 0.8659821325228381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003730542664695724, AUC: 0.8659821325228381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003724799516531745, AUC: 0.8670088265680126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037183192699345494, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037113900757230834, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037042266587046114, AUC: 0.8685488676357744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036969763645227404, AUC: 0.869575561680949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003689739027872342, AUC: 0.8700889087035362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019523625541671214, AUC: 0.5447865805301085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030140118569320775, AUC: 0.5598215395695173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03041563369719385, AUC: 0.5655883878545738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029098777297120657, AUC: 0.5738105138614413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026977300150300653, AUC: 0.5907509656068212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024611675467797193, AUC: 0.609231458419963\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022707254003046955, AUC: 0.6246318690975808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021383745576530756, AUC: 0.6349073831947976\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02023577936934635, AUC: 0.6446609766239556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019166279530179672, AUC: 0.6533878760079392\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018139468957178342, AUC: 0.6621147753919226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017263531438065364, AUC: 0.6723902894891393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016514696689866343, AUC: 0.6785504537601866\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.015801674584177465, AUC: 0.6898526619025777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015078895580694543, AUC: 0.6996062553317358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014429067232593986, AUC: 0.7093598487608938\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013954192708491292, AUC: 0.7124399308964174\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013517346194565419, AUC: 0.7206534832578138\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013075903088903329, AUC: 0.7263003005062737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01267287696617237, AUC: 0.731955691400205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012279921683712282, AUC: 0.7365758146034903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011884378350299337, AUC: 0.7391425497164266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011535131659813796, AUC: 0.7468427550552357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011233633843021116, AUC: 0.7499314108362304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010944077687233872, AUC: 0.7535248399943415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010674574607154104, AUC: 0.7576316161750396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010455976608623876, AUC: 0.7607116983105631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010282557449972654, AUC: 0.7632784334234994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010124219377095161, AUC: 0.7673937832496688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009960634120996448, AUC: 0.7694471713400178\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00978560107094901, AUC: 0.7704738653851925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009600585538654841, AUC: 0.7730406004981288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00940962657178164, AUC: 0.7776607237014143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009216866384628644, AUC: 0.781254152859525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009026147070385161, AUC: 0.786396196730869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008841751771930828, AUC: 0.7874228907760437\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00866858164469401, AUC: 0.7894762788663926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008508376700043925, AUC: 0.7910163199341544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008358031573009293, AUC: 0.7951230961148527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00821438191099937, AUC: 0.8002565663407253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008076433069217279, AUC: 0.8038499954988362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00794438866601474, AUC: 0.8048766895440107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007818247960961384, AUC: 0.8064167306117724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007696827252705892, AUC: 0.8089834657247088\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007577964978188461, AUC: 0.8120635478602325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007459582008930467, AUC: 0.8120635478602325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073405373417319226, AUC: 0.8120635478602325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007220938092186337, AUC: 0.8161703240409306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007102028430125235, AUC: 0.8166836710635179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006985776419471757, AUC: 0.8182237121312796\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006873680197674295, AUC: 0.8192504061764543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006765441864914035, AUC: 0.8213037942668033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066595437857428445, AUC: 0.8223304883119779\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00655466379833024, AUC: 0.8264372644926761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006450176732633918, AUC: 0.8290039996056123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006345974239009755, AUC: 0.8310573876959615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006242366064162482, AUC: 0.8325974287637232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006140347840129465, AUC: 0.8336241228088977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006042091495995689, AUC: 0.8351641638766596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005950909964046123, AUC: 0.8351641638766596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005868944815720584, AUC: 0.8372175519670086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005794367928435837, AUC: 0.8382442460121832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057229963642223035, AUC: 0.8403062077480035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005651446356289629, AUC: 0.8418548224612366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005578049715014471, AUC: 0.8423681694838236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005502413888895733, AUC: 0.842881516506411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005424869603498628, AUC: 0.8454482516193473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005346044496966692, AUC: 0.8485283337548709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005266590641645664, AUC: 0.8516084158903945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051871246926285955, AUC: 0.8531484569581563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005108284037058892, AUC: 0.8546884980259182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00503101654921506, AUC: 0.8552018450485055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004957007695429073, AUC: 0.8572552331388545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004888905995133994, AUC: 0.8587952742066163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048293371378264815, AUC: 0.8608486622969654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004778974668333002, AUC: 0.86187535634214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004735972200121198, AUC: 0.8634153974099017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004697502646633804, AUC: 0.8654687855002507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00466132546557156, AUC: 0.8654687855002507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004626278921684123, AUC: 0.8654687855002507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004592099791975002, AUC: 0.8664954795454254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045591188020094086, AUC: 0.8664954795454254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004527963096310633, AUC: 0.8680355206131871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004499381867007933, AUC: 0.8690707883038329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004474105055040948, AUC: 0.8690707883038329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044525795101379015, AUC: 0.8700974823490074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044344969664548, AUC: 0.8700974823490074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004418728761297822, AUC: 0.8700974823490074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044038714089008595, AUC: 0.8711327500396531\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004388813399873659, AUC: 0.8716460970622404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004372901057604677, AUC: 0.8716460970622404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004355839690806703, AUC: 0.8726727911074149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004337544396797322, AUC: 0.8742128321751768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004318048248133057, AUC: 0.8747261791977641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004297447994382238, AUC: 0.8747261791977641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004275875678960828, AUC: 0.8757528732429385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004253474328335274, AUC: 0.8757528732429385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004230395360516218, AUC: 0.8762662202655258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004206779457273937, AUC: 0.8767795672881131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004182762364176243, AUC: 0.8772929143107003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004158454775563432, AUC: 0.8778062613332875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010656021643376005, AUC: 0.6700839788573902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020161901201520647, AUC: 0.6322549116271493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020933010069726664, AUC: 0.6287472189237502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020120055038736474, AUC: 0.6446866975603692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01900158362852614, AUC: 0.6565022527253475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017868003489808267, AUC: 0.6672825401996801\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01688521841297979, AUC: 0.6775494806514255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01594039964379731, AUC: 0.6878164211031709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015100537866785906, AUC: 0.6965518941326256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014323203460029934, AUC: 0.7073321816069584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013588885096042546, AUC: 0.7170943486815877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012909358085806079, AUC: 0.725307901042984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012346015953869553, AUC: 0.7355748414947294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011882468039945046, AUC: 0.7432750468335385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011447573794094425, AUC: 0.7504619051497602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011015351021018334, AUC: 0.7591888045337438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010611669370599909, AUC: 0.7653489688047911\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010281525536847164, AUC: 0.7740758681887745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010026015850327771, AUC: 0.7781826443694727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0098031791347401, AUC: 0.7817760735275836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009570370549741, AUC: 0.7869095437534563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009312528260746357, AUC: 0.7879362377986309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009036925762089636, AUC: 0.7920515876248002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008757437978472029, AUC: 0.7997517929636092\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008484774247953363, AUC: 0.8069386512798309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008223132810730865, AUC: 0.8136121625734656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007978017532553979, AUC: 0.8177189387541636\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007778684545007551, AUC: 0.8207990208896871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00764463012016091, AUC: 0.8243924500477982\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007549618095097828, AUC: 0.8249057970703854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074644557684351446, AUC: 0.8254191440929726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007377810606551714, AUC: 0.8295259202736708\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007295662818734937, AUC: 0.8310659613414326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0072295939700203656, AUC: 0.8310659613414326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007183538213773297, AUC: 0.8310659613414326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007152199745178223, AUC: 0.8315793083640199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007128067638563073, AUC: 0.8320926553866073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00710611215042525, AUC: 0.8326060024091944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007084324246361142, AUC: 0.8336412700998401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00706277056510404, AUC: 0.8357032318356603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007042376397806171, AUC: 0.8372432729034223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007023791348712044, AUC: 0.836729925880835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007006343353855931, AUC: 0.8372432729034223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006987428813247207, AUC: 0.8382699669485967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006964246678796614, AUC: 0.838783313971184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006937851323350863, AUC: 0.8398100080163585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006911242723958586, AUC: 0.8398100080163585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006885781051209254, AUC: 0.840836702061533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00686134808305381, AUC: 0.8418633961067077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068372670661341825, AUC: 0.8418633961067077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00681282225109282, AUC: 0.8418633961067077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00678747164289897, AUC: 0.8418633961067077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006760908209759256, AUC: 0.8418633961067077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0067330472958013875, AUC: 0.8428900901518821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006703965905783833, AUC: 0.8434034371744694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066738232322361155, AUC: 0.8434034371744694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006642829557383282, AUC: 0.8434034371744694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006611207503956544, AUC: 0.8439167841970567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065791471157508365, AUC: 0.8454568252648185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00654680659805519, AUC: 0.8459701722874058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006514287636640402, AUC: 0.8464835193099931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006481653168087914, AUC: 0.8469968663325803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00644894268201745, AUC: 0.8469968663325803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006416176663669246, AUC: 0.8475102133551675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0063833667131190965, AUC: 0.8480235603777548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006350514558037862, AUC: 0.8480235603777548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006317611313261107, AUC: 0.8485369074003422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006284646365953528, AUC: 0.8490502544229294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006251607128798838, AUC: 0.8505902954906912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006218484963442721, AUC: 0.8511036425132785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006185280363505425, AUC: 0.8511036425132785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006152011099315825, AUC: 0.8511036425132785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006118710243430444, AUC: 0.8511036425132785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00608544147286109, AUC: 0.8521303365584529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006052285988138329, AUC: 0.854183724648802\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006019352879336655, AUC: 0.8557237657165639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005986787270808565, AUC: 0.8562371127391512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005954758474298639, AUC: 0.8562371127391512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00592347282306995, AUC: 0.857777153806913\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005893185025169736, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058641954485180465, AUC: 0.8588038478520875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005836852095388725, AUC: 0.8593171948746748\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005811515802182025, AUC: 0.8603438889198494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005788440783324943, AUC: 0.8603438889198494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005767599642893789, AUC: 0.8613705829650238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005748587365476241, AUC: 0.8634239710553728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005730743610587426, AUC: 0.8634239710553728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005713400139818527, AUC: 0.8634239710553728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005696062592492587, AUC: 0.8634239710553728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056784466433475725, AUC: 0.8639373180779601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005660453074713918, AUC: 0.8639373180779601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005642102125021735, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056234925183203405, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005604768268316676, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005586092393097176, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005567646791722711, AUC: 0.8649554384776635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005549618793076857, AUC: 0.8654687855002507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005532193257941962, AUC: 0.8659821325228381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005515550234302971, AUC: 0.8664954795454254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005499850395550145, AUC: 0.8675221735905999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005485213691403407, AUC: 0.8670088265680126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03942638104993611, AUC: 0.38078881825157646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0608240783091164, AUC: 0.4915120909835258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05985646218246555, AUC: 0.49621795064152296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0551943236009428, AUC: 0.5013771418038093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05001864818312367, AUC: 0.5065191856751532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0448951898894695, AUC: 0.5162813527497825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040239750721933434, AUC: 0.5275749872467024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03585468908274396, AUC: 0.5373285806758604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031953742538673294, AUC: 0.5547909530892988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028601390728052112, AUC: 0.5676074813630383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025683218401164495, AUC: 0.5835212390632435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02319183902464051, AUC: 0.6066218550796707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021123017336764444, AUC: 0.620490798334998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01940124523565636, AUC: 0.6369350503487331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017857622162402293, AUC: 0.6559460374754045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016442870995025952, AUC: 0.6713550217984936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015243492264678513, AUC: 0.6903574352796937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014164402371361143, AUC: 0.7031911108443756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013249146518746766, AUC: 0.7211668302804011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01258567351979005, AUC: 0.7298937296643846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012002317554955651, AUC: 0.7381072820257809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011385361847176562, AUC: 0.7499228371907593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010773832506768204, AUC: 0.7560830014618064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010208135312635213, AUC: 0.7622431657328539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009751501043884404, AUC: 0.7689252506719594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009367096744955944, AUC: 0.7720053328074831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009031093392066087, AUC: 0.7776607237014143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008714934066709278, AUC: 0.7894677052209212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008399981149235127, AUC: 0.7935744814016195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008085247892770708, AUC: 0.7992212986500794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007779208769709427, AUC: 0.8053814629211267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007493332306050366, AUC: 0.8094882391018249\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007232268898136621, AUC: 0.8125683212373486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006996993199145078, AUC: 0.8171884444406339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006788808366526728, AUC: 0.8212952206213321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006605844319977375, AUC: 0.824888649779443\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0064410398218695914, AUC: 0.8295087729827283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006276092667510544, AUC: 0.8341288961860137\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006104627010985191, AUC: 0.8356689372537756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005929752906657154, AUC: 0.8387490193892992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005772968256695671, AUC: 0.8428557955699972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005653859665675193, AUC: 0.8438824896151719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005556656707147634, AUC: 0.844387262992288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005482002938509481, AUC: 0.846440651082637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005438258435661995, AUC: 0.8469625717506954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005412236997553033, AUC: 0.8469625717506954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00539120470268139, AUC: 0.8474759187732827\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005370052951710071, AUC: 0.8479978394413412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005345464986797198, AUC: 0.8490245334865159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005315632923789646, AUC: 0.8490245334865159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052806099502689845, AUC: 0.8500512275316904\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.005241680712926956, AUC: 0.8510779215768649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005201079830619859, AUC: 0.8521046156220394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005162360628692754, AUC: 0.8510779215768649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051302721041329895, AUC: 0.8510779215768649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005108592919928193, AUC: 0.8515912685994522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005097428340595948, AUC: 0.8521046156220394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005093648813772893, AUC: 0.853131309667214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005092804229530982, AUC: 0.8526179626446266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005090125352452754, AUC: 0.8526179626446266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00508209550849646, AUC: 0.8526179626446266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050691833900862356, AUC: 0.8526179626446266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005054296420474477, AUC: 0.853131309667214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005039144006575116, AUC: 0.853131309667214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005024001341675626, AUC: 0.853131309667214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005008568181261019, AUC: 0.8541580037123887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004992484676171534, AUC: 0.8541580037123887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004975534373929042, AUC: 0.855184697757563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004957616452598177, AUC: 0.855184697757563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004938663286205157, AUC: 0.855184697757563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004918536044055631, AUC: 0.8556980447801503\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004896973847849275, AUC: 0.8562113918027376\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004873595622755726, AUC: 0.8562113918027376\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004847966119122554, AUC: 0.8567247388253248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004819745479409986, AUC: 0.858778126915674\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004788855588213997, AUC: 0.8592914739382612\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047555592983158975, AUC: 0.8598048209608484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004720446485910357, AUC: 0.8603181679834357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004684317679632278, AUC: 0.8613448620286104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004648092864216238, AUC: 0.8628849030963721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004612690543536074, AUC: 0.8644249441641338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0045789292633656884, AUC: 0.8644249441641338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004547390138140376, AUC: 0.8654516382093085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00451833342913515, AUC: 0.8659649852318957\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004491704961527948, AUC: 0.8664783322544829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044672422527526475, AUC: 0.8675050262996575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00444460458143404, AUC: 0.8675050262996575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004423488741335662, AUC: 0.8675050262996575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004403671369295929, AUC: 0.8685317203448322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0043850576902275005, AUC: 0.8695584143900066\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004367711874762431, AUC: 0.8700717614125939\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004351877154277225, AUC: 0.8705851084351811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004338001612550724, AUC: 0.8716118024803556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004326687096068578, AUC: 0.8716118024803556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004318511634139541, AUC: 0.8726384965255303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004313779050025387, AUC: 0.8726384965255303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004312286836019954, AUC: 0.8726384965255303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004313353302562706, AUC: 0.872125149502943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00431602514555242, AUC: 0.8716118024803556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0043193211713439435, AUC: 0.8716118024803556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004322377914720934, AUC: 0.8710984554577683\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.017256723427624437, AUC: 0.5512018107539235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022331058115198994, AUC: 0.5572280118144836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025446987546995807, AUC: 0.5508974463396964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027459101153703456, AUC: 0.5536013597801718\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02873911077684991, AUC: 0.550059372494888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029575100103026837, AUC: 0.5516680027264192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030180142286154548, AUC: 0.5511889502857168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030613142017498766, AUC: 0.5496746301543686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03089675844085883, AUC: 0.5486565097546652\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031056019089977193, AUC: 0.5491784304227236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031125197005814894, AUC: 0.549700351090782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031125109141411002, AUC: 0.5497089247362533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03106737038116771, AUC: 0.5502308454043118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030964455495956767, AUC: 0.5502308454043118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030826310933746905, AUC: 0.5502308454043118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030659415953894827, AUC: 0.550744192426899\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030468624817905465, AUC: 0.5512575394494863\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030257809482993052, AUC: 0.5522842334946607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030030184404203363, AUC: 0.5533195011853065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02978845856944967, AUC: 0.5538328482078937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0295347387499444, AUC: 0.5548595422530683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029270542334325564, AUC: 0.5548595422530683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028997153722474786, AUC: 0.5553728892756556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028716074507182183, AUC: 0.5558862362982427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028429198215713658, AUC: 0.5558862362982427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02813878661603908, AUC: 0.5558862362982427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02784725844736672, AUC: 0.5574262773660047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027556786626022053, AUC: 0.5589663184337665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027268888540643094, AUC: 0.5594796654563537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02698420096134794, AUC: 0.5594796654563537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0267026784750739, AUC: 0.5610197065241156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026423884721522992, AUC: 0.5615330535467028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02614701707417427, AUC: 0.5625597475918772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025871132718356747, AUC: 0.563586441637052\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025595410269980103, AUC: 0.565639829727401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025319250474064987, AUC: 0.5661531767499882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025042221906515876, AUC: 0.5676932178177501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024764017535539393, AUC: 0.5692332588855118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02448447446645417, AUC: 0.5702599529306864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024203528528628143, AUC: 0.5723133410210355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02392123698200992, AUC: 0.5743667291113845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023637874279456603, AUC: 0.5759067701791464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023353961683948588, AUC: 0.5769334642243208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023070338349905073, AUC: 0.5795001993372572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02278812183356433, AUC: 0.5820669344501935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022508470168024857, AUC: 0.5836069755179553\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022232245214237188, AUC: 0.5846422432086011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021959735246425336, AUC: 0.5856689372537757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02169064211796036, AUC: 0.5887490193892991\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021424336956648107, AUC: 0.5897671397890025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021160179043408507, AUC: 0.5918205278793516\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02089773497966506, AUC: 0.5949006100148752\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020636761904256437, AUC: 0.596440651082637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020377171952778755, AUC: 0.5990073861955734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02011894340594116, AUC: 0.6005474272633352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019862058493414773, AUC: 0.6026008153536843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019606496483149244, AUC: 0.6036275093988589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01935225638790407, AUC: 0.6051675504666206\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019099439893450056, AUC: 0.6067075915343824\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018848333793150464, AUC: 0.6077342855795569\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018599468235150133, AUC: 0.6123544087828424\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018353786034120044, AUC: 0.615434490918366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018112750280471074, AUC: 0.617487879008715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017878353719138703, AUC: 0.619027920076477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017652539239413498, AUC: 0.621081308166826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017436077382500373, AUC: 0.6226213492345877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0172280120059817, AUC: 0.6246747373249368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017026429837781697, AUC: 0.6246747373249368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016829510406430957, AUC: 0.6251880843475242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016636153926020084, AUC: 0.6277548194604605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016446079033008522, AUC: 0.6303215545733968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016259698393922415, AUC: 0.6328882896863331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016077840797155785, AUC: 0.6354635984447408\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01590152951747981, AUC: 0.6380303335576771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015731731063337306, AUC: 0.6390570276028517\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015569219431274919, AUC: 0.6400837216480261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015414558335614253, AUC: 0.6441904978287243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015268141685312086, AUC: 0.6462438859190732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015130200988264064, AUC: 0.6477839269868352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015000589639256953, AUC: 0.6503506620997715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014878600280477394, AUC: 0.6508640091223586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014762973686676341, AUC: 0.6508640091223586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014652123856001512, AUC: 0.6518907031675333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014544504276220348, AUC: 0.6529173972127079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01443882659848926, AUC: 0.6544574382804696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014334118390922468, AUC: 0.654970785303057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014229735972718422, AUC: 0.6565108263708188\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014125262728389005, AUC: 0.6575375204159933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014020459745734869, AUC: 0.6595909085063423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01391524755189631, AUC: 0.6606176025515168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013809603933962236, AUC: 0.6621576436192786\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013703552092084233, AUC: 0.662670990641866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01359715471603362, AUC: 0.6636976846870406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01349046462317678, AUC: 0.6642110317096277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013383549439487497, AUC: 0.6657510727773895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013276459514230921, AUC: 0.6672911138451513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013169239766849495, AUC: 0.6672911138451513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013061926725241462, AUC: 0.6683178078903259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012954550500241866, AUC: 0.6693445019355003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012847143177166736, AUC: 0.670371195980675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012739710679459029, AUC: 0.670371195980675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07423014275529123, AUC: 0.49590179746477303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020155033956650126, AUC: 0.5007651978583034\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015534060835591508, AUC: 0.5791197438194733\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019726538016435768, AUC: 0.5564660290732317\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02270165931117214, AUC: 0.5440267412002245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02478919907879879, AUC: 0.5385942650885442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026302726619238687, AUC: 0.5350437041577895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027456932186339954, AUC: 0.5289006871776846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0283164365938238, AUC: 0.5294826233640412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02895483072253241, AUC: 0.5264025412285176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02942729341811028, AUC: 0.5259234887878151\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029754396797954174, AUC: 0.5254272890561702\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029957701207194515, AUC: 0.5259492097242287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030072029579747046, AUC: 0.5269930510603456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03011812581285433, AUC: 0.5264882776832295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03011138493476694, AUC: 0.5270101983512879\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030066323329696498, AUC: 0.5264968513287007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029993165847430812, AUC: 0.5275321190193464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02989824662297409, AUC: 0.5280540396874047\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02978558569961453, AUC: 0.5280540396874047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029658114194376375, AUC: 0.5285673867099921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029518101773153428, AUC: 0.5311512691138709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029367115186608356, AUC: 0.5326913101816326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029206047887387482, AUC: 0.5326913101816326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02903536585300359, AUC: 0.53320465720422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028855429426236676, AUC: 0.5337180042268073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02866665818429635, AUC: 0.5357885396080987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028469613867023222, AUC: 0.5368152336532731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028264958912788216, AUC: 0.5378419276984477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02805332811722844, AUC: 0.5383552747210351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027835285194665504, AUC: 0.5383552747210351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027611274403321322, AUC: 0.5399038894342679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027381728154531916, AUC: 0.5414525041475009\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0271471361195819, AUC: 0.5424791981926756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026908140004791827, AUC: 0.5450459333056118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02666561154351718, AUC: 0.5465859743733738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026420763067083575, AUC: 0.5481260154411355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026175304476025188, AUC: 0.5496660565088973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025931408686667497, AUC: 0.5517194445992465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02569122887052611, AUC: 0.5537728326895954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025455911213813607, AUC: 0.5553128737573574\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025224997636941155, AUC: 0.5578796088702936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024996852282411563, AUC: 0.5594196499380554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024769714900425503, AUC: 0.56044634398323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024542292205936914, AUC: 0.5619863850509917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024313967173637565, AUC: 0.5630130790961664\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024084739803527454, AUC: 0.5655798142091026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023855171835447195, AUC: 0.5666065082542773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023626405506647397, AUC: 0.5681551229675101\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023399924639589297, AUC: 0.5702085110578593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023176916884586184, AUC: 0.5732885931933829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022957661630697627, AUC: 0.5743067135930862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022741693887651338, AUC: 0.5794401838189589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022528428221834866, AUC: 0.5804668778641334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02231760893796048, AUC: 0.5820069189318953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022109383134861663, AUC: 0.5840603070222444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021904244432785002, AUC: 0.5866270421351807\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021702858231822896, AUC: 0.5897071242707044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021505911651358595, AUC: 0.591247165338466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021313726531792872, AUC: 0.5943272474739897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02112605211404046, AUC: 0.5953539415191642\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02094222793421143, AUC: 0.5979206766321006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020761429646493978, AUC: 0.5999740647224496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020582956310137953, AUC: 0.6010007587676242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02040631726661824, AUC: 0.6035674938805605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02023122917791331, AUC: 0.6071609230386714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020057554817594605, AUC: 0.608187617083846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01988527246637127, AUC: 0.6112676992193696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019714367315635917, AUC: 0.6143477813548932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019544795926806843, AUC: 0.6169145164678296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019376483269606566, AUC: 0.619489825226237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019209329632745274, AUC: 0.6215432133165862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01904323925389513, AUC: 0.6220565603391733\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01887814203898112, AUC: 0.6230832543843479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018714002940965736, AUC: 0.625136642474697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0185508254151907, AUC: 0.6266766835424589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01838864598955427, AUC: 0.6302701127005698\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018227571779649943, AUC: 0.6312968067457442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01806775975671614, AUC: 0.6318101537683315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017909462654319117, AUC: 0.6323235007909187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017752981580809284, AUC: 0.6333501948360933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017598676878966654, AUC: 0.6348902359038551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017446891614862604, AUC: 0.6364217033261457\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017297972309910238, AUC: 0.6395017854616694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017152349400964582, AUC: 0.640528479506844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017010630040928936, AUC: 0.6425818675971929\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0168735304727811, AUC: 0.644635255687542\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01674157590846344, AUC: 0.6451486027101293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016614807318456423, AUC: 0.6461752967553039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01649272318458952, AUC: 0.6477153378230657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016374539637911148, AUC: 0.650282072936002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016259466886026766, AUC: 0.651830687649235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01614682768195806, AUC: 0.6523440346718222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016036024251586407, AUC: 0.6523440346718222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015926543229855365, AUC: 0.6533707287169969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015817921107353385, AUC: 0.6538840757395842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015709776315629854, AUC: 0.6543974227621714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015601798861169913, AUC: 0.6554241168073459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01549377451278655, AUC: 0.6569641578751078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015385582333519346, AUC: 0.6585041989428695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015277214919064603, AUC: 0.6595223193425729\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024308178982626084, AUC: 0.4264874203186825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029052197316171712, AUC: 0.4506972517179443\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03411852400248589, AUC: 0.4617015256802116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03755923877344862, AUC: 0.47596485662721366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04007592606001512, AUC: 0.4797126114038058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04198684652893193, AUC: 0.47878880110428557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04343350333456667, AUC: 0.48195461969452097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04454085742958337, AUC: 0.48252798223540655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0453818658864276, AUC: 0.48622429513917165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046015540018338345, AUC: 0.4872767101207598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04648583966999567, AUC: 0.487832925370703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04682479684644111, AUC: 0.49045110235646644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047049249921526225, AUC: 0.49201686436064185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04718272483620337, AUC: 0.49619222970510946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04723661632024477, AUC: 0.49723607104122636\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04722455026693719, AUC: 0.4977579917092848\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04715002150762649, AUC: 0.49827991237734326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047027141657922086, AUC: 0.4988018330454017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04686851580444083, AUC: 0.4993237537134602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046680418847757345, AUC: 0.49984567438151867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04646398413995778, AUC: 0.5003675950495771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04621716216977832, AUC: 0.5003675950495771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045939970707547836, AUC: 0.5019247834082814\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04563702608981241, AUC: 0.5019247834082814\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04531409972449514, AUC: 0.5019247834082814\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044975634193815305, AUC: 0.5029686247443983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044625011783702526, AUC: 0.5034819717669854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04426489606900738, AUC: 0.5034819717669854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043897182551476774, AUC: 0.5039867451441016\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04352362851918854, AUC: 0.5050220128347473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04314582935277966, AUC: 0.5065706275479803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0427647880885912, AUC: 0.5070925482160387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04238088975041549, AUC: 0.5076058952386259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041994152108581415, AUC: 0.5076058952386259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04160436191914244, AUC: 0.5081192422612133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041211234856836546, AUC: 0.5086325892838006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04081463665695664, AUC: 0.5081106686157421\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04041473120142461, AUC: 0.5096507096835039\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.040011966697424343, AUC: 0.5101640567060912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03960679925006369, AUC: 0.5106774037286783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03919958426592019, AUC: 0.5106774037286783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03879063963643266, AUC: 0.5122174447964403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03838030102336876, AUC: 0.5132441388416148\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037969020582874366, AUC: 0.5137574858642021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037557301807601015, AUC: 0.5158194476000223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03714579232731221, AUC: 0.5158194476000223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036735208878606006, AUC: 0.5158194476000223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036326443926888226, AUC: 0.5178728356903713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03592047286576613, AUC: 0.5183861827129587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03551811905381102, AUC: 0.5194128767581331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035119581913602524, AUC: 0.520952917825895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034724517885449016, AUC: 0.5224929588936568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034332358318826424, AUC: 0.5240329999614186\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03394265698103184, AUC: 0.525059694006593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03355522432189057, AUC: 0.525059694006593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03317020052955264, AUC: 0.526599735074355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03278810193079599, AUC: 0.5276264291195294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03240993649816414, AUC: 0.528653123164704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03203719101583982, AUC: 0.5296883908553497\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0316716346187868, AUC: 0.5317417789456989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03131458132410148, AUC: 0.5317417789456989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030965664865560908, AUC: 0.5332818200134606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030622779459193134, AUC: 0.5332818200134606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030283541906447636, AUC: 0.5337951670360479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02994622256198038, AUC: 0.5348132874357512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029609831223576705, AUC: 0.5368666755261002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02927383379412981, AUC: 0.5373800225486876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028938074289641767, AUC: 0.5373800225486876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02860271165583198, AUC: 0.5394334106390366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02826823161502309, AUC: 0.542000145751973\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027935596726695943, AUC: 0.5425134927745602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027606403358728004, AUC: 0.5440535338423221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027282904393924688, AUC: 0.5450802278874965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02696698941058994, AUC: 0.5466202689552585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026658761081735045, AUC: 0.5481603100230202\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026356572690217392, AUC: 0.549700351090782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026058548479099945, AUC: 0.5522756598491896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025763615317966625, AUC: 0.5527890068717768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025471603401452613, AUC: 0.5538157009169513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02518283753168015, AUC: 0.5553557419847132\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02489779948200992, AUC: 0.5574091300750622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02461699866853639, AUC: 0.5599758651879987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024340848745026202, AUC: 0.5635692943461096\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024069223344696234, AUC: 0.5656226824364585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02380148076122592, AUC: 0.5687027645719821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02353682527877776, AUC: 0.570242805639744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023274840281863638, AUC: 0.570242805639744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023015655098988157, AUC: 0.5728095407526804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022759912423712374, AUC: 0.5758896228882039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022508544211061843, AUC: 0.5758896228882039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022262249427305737, AUC: 0.5784563580011404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02202089874393945, AUC: 0.5815364401366638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02178355724421594, AUC: 0.5825631341818384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02154910243569447, AUC: 0.5866699103625367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021316660610538586, AUC: 0.5887232984528857\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02108568385027457, AUC: 0.5902633395206475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020855915472374198, AUC: 0.5912900335658221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02062728834448394, AUC: 0.5938481950332872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020399835045540063, AUC: 0.5969282771688107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020173706623338023, AUC: 0.59898166525916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01994926539513882, AUC: 0.5994950122817471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022879327059285734, AUC: 0.637103308141105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010362423231389459, AUC: 0.734482773402837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010482909022897913, AUC: 0.7397555653676166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012645565451548954, AUC: 0.7218152122191595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014883048786139635, AUC: 0.7103511765184997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016937350634462344, AUC: 0.6848210037166753\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01871672723110665, AUC: 0.6710377969160597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0201813903160964, AUC: 0.6541487870435071\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021421626981494343, AUC: 0.6418799003742397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022479681248003404, AUC: 0.6337006425947281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023336516157193708, AUC: 0.6301415080185019\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024045582883846686, AUC: 0.6250166114381004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024654664855072464, AUC: 0.6198917148576989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025184281864521665, AUC: 0.6173249797447625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025636129991361566, AUC: 0.6147839655682398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026017850477009333, AUC: 0.6137658451685364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026339790589073923, AUC: 0.6137829924594788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0266050512499444, AUC: 0.6127648720597755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026816528035987237, AUC: 0.6112334046374848\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026981132617895153, AUC: 0.6076399754793739\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02710810655392475, AUC: 0.6071266284567868\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027205409964172488, AUC: 0.6066132814341993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027277686827918264, AUC: 0.6061170817025546\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02732735292264887, AUC: 0.6056037346799672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027356087544443197, AUC: 0.6056037346799672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027365723011656577, AUC: 0.6056037346799672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027358558607397613, AUC: 0.6056037346799672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027336987402621755, AUC: 0.6071523493932002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027303026329656567, AUC: 0.6066390023706131\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027258232266759774, AUC: 0.6071523493932002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02720402190403909, AUC: 0.6071523493932002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02714179613575432, AUC: 0.6071523493932002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027072853183153993, AUC: 0.6076742700612587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02699827506181863, AUC: 0.6076742700612587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026918824908649452, AUC: 0.6076742700612587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026834983509766635, AUC: 0.608187617083846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026746967070838186, AUC: 0.608187617083846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026654833839053198, AUC: 0.6092143111290205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02655855024823491, AUC: 0.6112676992193696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02645807384704211, AUC: 0.6117810462419568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02635337797998148, AUC: 0.6128077402871314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02624451299631818, AUC: 0.6133210873097187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02613158156906349, AUC: 0.6143477813548932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026014769299430137, AUC: 0.6143477813548932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025894338793389298, AUC: 0.6148611283774804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025770606955139285, AUC: 0.6174278634904169\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025643921293333698, AUC: 0.6174278634904169\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025514653997638456, AUC: 0.617941210513004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02538316639807407, AUC: 0.6184545575355913\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025249789220205744, AUC: 0.6189679045581785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025114786057245164, AUC: 0.619481251580766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024978371140379343, AUC: 0.6199945986033533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024840663925707957, AUC: 0.6205079456259405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02470171574973665, AUC: 0.6215346396711149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024561522663503452, AUC: 0.6220479866937023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02442008071804639, AUC: 0.6235880277614639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024277390900605954, AUC: 0.6241013747840513\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02413346999427053, AUC: 0.6251280688292259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023988372297267243, AUC: 0.6261547628744004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02384216000574716, AUC: 0.6261547628744004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023694927894797633, AUC: 0.6261547628744004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023546804305682765, AUC: 0.6261547628744004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0233979284393121, AUC: 0.6261461892289292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023248507616189202, AUC: 0.6261461892289292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02309872743752679, AUC: 0.6276948039421621\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02294880608347385, AUC: 0.6297481920325112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022798979504508262, AUC: 0.6312968067457442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022649493523512816, AUC: 0.6323235007909187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022500572244079465, AUC: 0.6328368478135061\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02235249604250827, AUC: 0.6338635418586805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022205579848516555, AUC: 0.6338635418586805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022060216583820604, AUC: 0.6343768888812679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02191693738380574, AUC: 0.6348902359038551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021776369146185137, AUC: 0.6359169299490297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02163907262355891, AUC: 0.6359169299490297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021505370643568333, AUC: 0.6384836650619661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021375173367328526, AUC: 0.6395103591071406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021248037523858048, AUC: 0.640537053152315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02112336089645607, AUC: 0.6410504001749023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021000527447054846, AUC: 0.6441304823104259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020879022823357435, AUC: 0.6441304823104259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020758414614027824, AUC: 0.6456705233781879\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020638372093500806, AUC: 0.6472105644459495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020518640553729133, AUC: 0.6472105644459495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020399046240386014, AUC: 0.6487506055137114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020279499314586568, AUC: 0.6497772995588859\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020159953376027613, AUC: 0.6528573816944095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020040436067442963, AUC: 0.6533707287169969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0199210510490844, AUC: 0.6533707287169969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019801965164595262, AUC: 0.6543974227621714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019683404492048497, AUC: 0.6569641578751078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019565664216351558, AUC: 0.6590175459654567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019449025701045, AUC: 0.6595308929880441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019333777220352837, AUC: 0.6610709340558057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019220141890626517, AUC: 0.6615842810783931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019108237193484732, AUC: 0.6615842810783931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018998112984572386, AUC: 0.6620976281009804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018889685842067804, AUC: 0.6626109751235677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018782823969365155, AUC: 0.6636376691687422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018677345714213686, AUC: 0.6646643632139168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018573049185932545, AUC: 0.665177710236504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03215044428349528, AUC: 0.4713061520193078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018338976933102182, AUC: 0.5634781993629782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022578079507958076, AUC: 0.5979871223845022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02535485431521082, AUC: 0.6077332138738731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02717272835488645, AUC: 0.6048074573568308\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028492386543479273, AUC: 0.6023264586986065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02952197471760815, AUC: 0.5982368298088505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030368536402226483, AUC: 0.5983225662635624\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031047090486956926, AUC: 0.5926928963060448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031541878639047435, AUC: 0.591195723465639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031888818642120675, AUC: 0.5906909500885229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032146436087093, AUC: 0.590699523733994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03234580930468952, AUC: 0.5907166710249364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032500202858176536, AUC: 0.5902118976478203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03261532793380706, AUC: 0.5886718565800586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03268879343510661, AUC: 0.5886804302255297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0327181125032729, AUC: 0.588689003871001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03270708107800217, AUC: 0.5886975775164722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03266402455837337, AUC: 0.5886975775164722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032595548570526316, AUC: 0.5892194981845306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03250605423257958, AUC: 0.5887061511619432\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03239948458306291, AUC: 0.5892194981845306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03227885366720196, AUC: 0.5892194981845306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03214585262796153, AUC: 0.589741418852589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032001429216215085, AUC: 0.5892280718300017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03184618861038492, AUC: 0.5887147248074145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0316806441755275, AUC: 0.5882013777848273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031505522520645805, AUC: 0.5876880307622399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03132230648096057, AUC: 0.5887147248074145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03113320451345503, AUC: 0.5892280718300017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030940632395615984, AUC: 0.5892280718300017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0307466623452386, AUC: 0.5892280718300017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03055280484027744, AUC: 0.5902547658751762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03036005107018765, AUC: 0.5907681128977637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030169040766808805, AUC: 0.5907681128977637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029980139209123378, AUC: 0.5912814599203509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02979341352948491, AUC: 0.5923081539655253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029608739335591255, AUC: 0.5928215009881127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029425873766281096, AUC: 0.5933348480106999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029244405142268778, AUC: 0.5938481950332872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029063836881586237, AUC: 0.5943615420558744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028883666478822442, AUC: 0.5948748890784616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028703384517882922, AUC: 0.5953882361010491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02852254279158377, AUC: 0.5964149301462236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028340733569601307, AUC: 0.5964149301462236\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028157703131128788, AUC: 0.5984683182365726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02797328561976336, AUC: 0.59898166525916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027787508678238832, AUC: 0.6005217063269217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02760048386473093, AUC: 0.6025750944172706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027412438244553087, AUC: 0.6041151354850325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027223649232283882, AUC: 0.6046284825076198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02703432908462935, AUC: 0.6046284825076198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02684454295946204, AUC: 0.6046284825076198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026654282958858008, AUC: 0.605141829530207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026463426664996098, AUC: 0.6061685235753816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026271888187953403, AUC: 0.6061685235753816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026079636923274637, AUC: 0.6066818705979689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025886692615769664, AUC: 0.6077171382886145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025693181632221607, AUC: 0.6092571793563765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025499252058704448, AUC: 0.6107972204241382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025305144781898513, AUC: 0.6113105674467254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025111111548129568, AUC: 0.6123372614918999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024917446555064577, AUC: 0.6128506085144874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02472452890305292, AUC: 0.6138773025596619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02453277125862074, AUC: 0.6159392642954821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024342681063381534, AUC: 0.6174793053632438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024154779580315696, AUC: 0.6185059994084185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023969577212758192, AUC: 0.6200460404761803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023787442201412982, AUC: 0.621586081543942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023608526581316014, AUC: 0.6220994285665292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023432667457785914, AUC: 0.6241528166568785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02325951139872612, AUC: 0.6246661636794657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02308853812839674, AUC: 0.625179510702053\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022919213549690957, AUC: 0.6262062047472274\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022751037131678736, AUC: 0.6267195517698146\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022583581399226536, AUC: 0.627232898792402\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.022416533397098013, AUC: 0.6282595928375765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022249682843068126, AUC: 0.6292862868827511\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02208292015344213, AUC: 0.6303129809279256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02191618115758797, AUC: 0.6318530219956874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021749468817227127, AUC: 0.6323663690182747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021582881856408918, AUC: 0.6333930630634493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02141659106773866, AUC: 0.6344197571086239\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02125090545749072, AUC: 0.6349331041312111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02108623374322927, AUC: 0.6349331041312111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02092295551892393, AUC: 0.6364731451989728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020761229236673864, AUC: 0.6364731451989728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02060088953369646, AUC: 0.6374998392441473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020441557803262587, AUC: 0.6380131862667346\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02028292109013591, AUC: 0.6390398803119093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020124840687027135, AUC: 0.6395532273344965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019967432594694214, AUC: 0.6410932684022582\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019811016185436684, AUC: 0.6421199624474327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019656140364968752, AUC: 0.6426333094700201\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019503502618698848, AUC: 0.6431466564926074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019353805368237862, AUC: 0.644173350537782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019207536310389423, AUC: 0.6452000445829564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01906480256074704, AUC: 0.6467400856507182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018925317819567695, AUC: 0.6472534326733055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01878857513885814, AUC: 0.6498201677862419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018654064115283406, AUC: 0.6513602088540036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041835634851554414, AUC: 0.4975950924453323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043004201806109886, AUC: 0.496080772313984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04350739038755681, AUC: 0.4971417609410433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04386697694134761, AUC: 0.49768082890004417\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0441244117468287, AUC: 0.4992465909042195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04430005762641227, AUC: 0.4997770852177491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04441371072646747, AUC: 0.5002990058858076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04447377048911021, AUC: 0.5002990058858076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04448231406833814, AUC: 0.5002990058858076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044442599357778736, AUC: 0.5002990058858076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0443601924193325, AUC: 0.5002990058858076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044240290086955514, AUC: 0.500820926553866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044087640987419935, AUC: 0.5013428472219245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04390694438547328, AUC: 0.5018647678899829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04370257967994327, AUC: 0.5029086092260998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04347828653781804, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043236586371317165, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04297890870467476, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04270581429049095, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042417565734736914, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04211444933715568, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04179700215657552, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04146625289759034, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041123607390662405, AUC: 0.5034219562486871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0407706886591625, AUC: 0.5044572239393329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040409125649904364, AUC: 0.5059972650070947\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04004040909603269, AUC: 0.5080506530974438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03966574145646816, AUC: 0.508564000120031\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039286084303451124, AUC: 0.508564000120031\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038902235327300076, AUC: 0.5095906941652056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038514869800512344, AUC: 0.5095906941652056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038124617582522564, AUC: 0.5101040411877928\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03773210458380342, AUC: 0.5106173882103802\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03733788958247404, AUC: 0.5116440822555547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03694246422430003, AUC: 0.5126707763007292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03654616614553005, AUC: 0.5142108173684911\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036149307314159954, AUC: 0.5147241643910783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03575238036319583, AUC: 0.5152375114136656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03535596085384519, AUC: 0.5157508584362528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034960601640784225, AUC: 0.5178128201720731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03456696121342187, AUC: 0.5188395142172477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03417569806116708, AUC: 0.5193528612398348\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033787623695705246, AUC: 0.5198662082624221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03340350717738055, AUC: 0.5214062493301839\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033024105719651246, AUC: 0.5229462903979458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03265024366832915, AUC: 0.5244863314657076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032282905302185944, AUC: 0.5244777578202364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03192263459073337, AUC: 0.525504451865411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03156891718167449, AUC: 0.5285845340009345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031220295908041377, AUC: 0.529611228046109\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030875215866057275, AUC: 0.5301245750686964\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030532685866267045, AUC: 0.5311512691138709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030192498588167114, AUC: 0.5311512691138709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029855181218180843, AUC: 0.5326913101816326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029521749626775708, AUC: 0.5337180042268073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029193139717939232, AUC: 0.535258045294569\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028869667408629233, AUC: 0.536798086362331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02855083710411814, AUC: 0.5388514744526799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028236016970490323, AUC: 0.5398781684978544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02792515468399964, AUC: 0.5409048625430289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027619212804126936, AUC: 0.5419315565882035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02731970773226973, AUC: 0.5429496769879069\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027027550691403217, AUC: 0.5455164121008432\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026742013098043436, AUC: 0.547056453168605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026461226105936812, AUC: 0.5485964942363668\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02618342946528401, AUC: 0.5501365353041286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02590774749376759, AUC: 0.5506498823267159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025634251272703055, AUC: 0.5516765763718904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025363766135142702, AUC: 0.5521899233944777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025097447152463547, AUC: 0.5547566585074141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024836192713514373, AUC: 0.5557833525525886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024580116350951895, AUC: 0.5578367406429375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024328595116024927, AUC: 0.5598901287332867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02408066447477163, AUC: 0.5624654374916944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023835458617279495, AUC: 0.564005478559456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02359246121677059, AUC: 0.5660588666498051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023351457054817407, AUC: 0.5675989077175669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023112465876229803, AUC: 0.5691389487853289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022875578507133152, AUC: 0.569652295807916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022640784087882032, AUC: 0.569652295807916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02240801943508488, AUC: 0.5701656428305034\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02217720063329977, AUC: 0.5717056838982653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021948258575692187, AUC: 0.5732457249660269\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02172118536433818, AUC: 0.5747857660337888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02149592077756767, AUC: 0.5773525011467252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021272414466115504, AUC: 0.5783791951918997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021050736524056698, AUC: 0.5794058892370743\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020831243345209284, AUC: 0.5799192362596614\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02061470497715794, AUC: 0.5814592773274232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020401864811994026, AUC: 0.5824859713725977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020192867974070043, AUC: 0.5824859713725977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019987241575189753, AUC: 0.5835126654177722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019784449543765365, AUC: 0.5855660535081215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019584221375901753, AUC: 0.5876194415984706\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019386646910483793, AUC: 0.5896728296888196\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.01919198579176119, AUC: 0.5917262177791686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01900052333223647, AUC: 0.5948062999146922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018812514239956873, AUC: 0.5958329939598669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018628111537198844, AUC: 0.5978863820502159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018447460348314872, AUC: 0.6004616908086233\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018270821304795164, AUC: 0.601488384853798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03718534513043074, AUC: 0.29993934145829143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04547026142570543, AUC: 0.39897780711869785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05110951733638534, AUC: 0.43308269709739233\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05453847209859339, AUC: 0.4539680974652017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05684446251910666, AUC: 0.47016478546595625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05840575176736583, AUC: 0.47643640712812885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.059454787591969746, AUC: 0.480089851804538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06017874881594324, AUC: 0.48375187012641835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06068879674433675, AUC: 0.48428236443994804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061029491464050165, AUC: 0.4858481264441234\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061252868446997726, AUC: 0.4853347794215361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061374541888819474, AUC: 0.4858567000895946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061409740961363105, AUC: 0.4869005414257115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06137490124435899, AUC: 0.48846630342988684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061285240062768906, AUC: 0.4889882240979453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061151378149818435, AUC: 0.4889882240979453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06098135756656497, AUC: 0.48951014476600374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06078143741773522, AUC: 0.4900320654340622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06055671976219793, AUC: 0.4900320654340622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06031081592567712, AUC: 0.49055398610212064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.060046180188038825, AUC: 0.49055398610212064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05976456786287991, AUC: 0.4910759067701791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.059467374908257715, AUC: 0.4910759067701791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05915578403828307, AUC: 0.4910759067701791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.058830977967066794, AUC: 0.49159782743823754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05849439411676695, AUC: 0.492119748106296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05814784308644802, AUC: 0.4926330951288833\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.057793165092389284, AUC: 0.49315501579694176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05743177583745795, AUC: 0.4941988571330587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05706465663870423, AUC: 0.4941988571330587\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05669251830928321, AUC: 0.4947207778011172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0563158228777457, AUC: 0.4947207778011172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05593492377618825, AUC: 0.4947207778011172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05554998883549471, AUC: 0.4947207778011172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055161051621841845, AUC: 0.4952426984691756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05476807659457189, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05437107560057077, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05397025596034206, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05356600664664006, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05315886076933109, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05274940672374907, AUC: 0.49575604549176283\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05233818749216526, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05192562166454876, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05151207254540106, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05109773758282079, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05068276683736292, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05026725705859577, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049851269455429933, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049434875109180904, AUC: 0.4962779661598213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049018143126683206, AUC: 0.4967913131824086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04860113076788545, AUC: 0.4967913131824086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04818392096098906, AUC: 0.4967913131824086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047766679562396885, AUC: 0.4967913131824086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04734963166294137, AUC: 0.49678273953693747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046933197827072615, AUC: 0.497809433582112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046518140204451344, AUC: 0.49728751291405354\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046105752080123616, AUC: 0.49728751291405354\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04569789538965956, AUC: 0.49780085993664075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045296220799163754, AUC: 0.4977922862911696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04490120218407293, AUC: 0.4993409010044026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04451211293538412, AUC: 0.5003675950495771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04412783549685903, AUC: 0.5003675950495771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043747655106380616, AUC: 0.5003675950495771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043371358520002345, AUC: 0.5013942890947517\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04299863969317134, AUC: 0.501907636117339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04262862787977262, AUC: 0.5029343301625134\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04226024896214961, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04189276448441342, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04152594145780765, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041160028666936584, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04079549406379399, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04043277400867786, AUC: 0.503961024207688\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040072030409029055, AUC: 0.5049877182528626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03971316256631729, AUC: 0.5049877182528626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039356014496544627, AUC: 0.5049877182528626\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03900045390948499, AUC: 0.5065277593206243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03864629717840665, AUC: 0.5065277593206243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0382932402332377, AUC: 0.5085811474109735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03794101257008302, AUC: 0.5090944944335607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03758938909811016, AUC: 0.5090944944335607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03723828096567474, AUC: 0.509607841456148\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03688775727961128, AUC: 0.5101211884787352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03653796810047474, AUC: 0.5106345355013224\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036189152340464464, AUC: 0.5126879235916716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0358415647076277, AUC: 0.5132012706142589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03549543819072084, AUC: 0.5147413116820206\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03515099590609533, AUC: 0.5152546587046078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03480848861283644, AUC: 0.5157680057271953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03446821445757311, AUC: 0.5162813527497825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03413064534126108, AUC: 0.5178213938175442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03379633510581702, AUC: 0.5188480878627187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033465698392248056, AUC: 0.5203881289304807\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03313852788005063, AUC: 0.5229548640434168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03281402192994428, AUC: 0.5234682110660043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0324911834290309, AUC: 0.5239815580885916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03216925615109272, AUC: 0.5255215991563532\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031847840263730005, AUC: 0.528601681291877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03152678669362828, AUC: 0.5301417223596386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031206129006964328, AUC: 0.5316817634274006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030886005417407176, AUC: 0.532708457472575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030566673594725553, AUC: 0.5342484985403368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025333154769170852, AUC: 0.4950840860279586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019353606932898733, AUC: 0.5086368761065361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02505393946392936, AUC: 0.5207203576924891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028287274496895925, AUC: 0.521131892675106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030200249413279028, AUC: 0.5232881645111094\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031372391165660284, AUC: 0.5254530099925838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032102502897906254, AUC: 0.5234081955477059\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03259811440856807, AUC: 0.5213805283937704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03292414465799588, AUC: 0.5208929023075968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033122677733932716, AUC: 0.5209014759530679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033228785354898586, AUC: 0.520910049598539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03325375661593293, AUC: 0.520910049598539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03320711048987095, AUC: 0.5214319702665975\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.033103867840816266, AUC: 0.5224672379572433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032957024702621046, AUC: 0.5224672379572433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032775647891974596, AUC: 0.5235110792933602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03256581782307437, AUC: 0.5245463469840058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032331752974547705, AUC: 0.5245463469840058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032076818849235834, AUC: 0.5260863880517677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031804016658238, AUC: 0.528148349787588\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03151620939898442, AUC: 0.5302017378779369\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031216059659085166, AUC: 0.5312284319231114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030906072067671434, AUC: 0.5327684729908734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03058863772121769, AUC: 0.5343085140586351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03026599469392196, AUC: 0.5353352081038097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02993999899791141, AUC: 0.5358485551263968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0296115825882116, AUC: 0.5368752491715715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02928091428294685, AUC: 0.5373885961941588\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028947917077358713, AUC: 0.5384152902393333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028612710427546848, AUC: 0.5394419842845078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02827567442110113, AUC: 0.5404686783296823\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027937255290724477, AUC: 0.5430354134426187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02759787754982895, AUC: 0.5440621074877933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027257828485398067, AUC: 0.5450888015329679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026917354907555115, AUC: 0.5466288426007296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026576800375991725, AUC: 0.5481688836684914\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026236546952778755, AUC: 0.5502222717588404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025897042845100103, AUC: 0.5517623128266023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025558828073505537, AUC: 0.5522756598491896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02522256408912548, AUC: 0.5538157009169513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024888973552000943, AUC: 0.5563824360298877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02455858266131478, AUC: 0.5574005564295911\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024231861343541748, AUC: 0.5599672915425273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02390937133852246, AUC: 0.5625340266554637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023591798778399672, AUC: 0.5635607207006383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023279581997952353, AUC: 0.5651007617684001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022972787142293546, AUC: 0.5671541498587491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022671327334259854, AUC: 0.5676674968813364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022374875797248034, AUC: 0.5686941909265111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022082759233241742, AUC: 0.5728009671072091\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021794295459060194, AUC: 0.5743410081749709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021509366993084703, AUC: 0.5763943962653201\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021228494111055173, AUC: 0.5799878254234309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020952586061465814, AUC: 0.5835812545815419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020682598493114022, AUC: 0.5866613367170653\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020419305402546443, AUC: 0.5902547658751762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02016303356636632, AUC: 0.5912814599203509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01991364871986658, AUC: 0.5938481950332872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01967061577869992, AUC: 0.5979549712139853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01943338978611411, AUC: 0.6000083593043344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019201874979781316, AUC: 0.6046284825076198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018976893731032347, AUC: 0.6061685235753816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018759964415745706, AUC: 0.6092486057109052\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018551817591886344, AUC: 0.6118153408238415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01835122217055927, AUC: 0.6123286878464288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01815574361670832, AUC: 0.6138687289141908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017963338342512618, AUC: 0.6143820759367778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017772878919328963, AUC: 0.6159221170045398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01758385988002485, AUC: 0.6174621580723015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01739600874622416, AUC: 0.620037466830709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01720913596775221, AUC: 0.6226042019436454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017023150224863372, AUC: 0.625684284079169\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016838141356442533, AUC: 0.6277376721695181\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016654413432561587, AUC: 0.6303044072824544\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016472511409972766, AUC: 0.6318444483502162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01629312931874277, AUC: 0.6323577953728036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0161169187375971, AUC: 0.6359512245309143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015944362427136913, AUC: 0.6374912655986762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01577580592153482, AUC: 0.6385179596438507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015611668798000423, AUC: 0.6395446536890252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015452597205436501, AUC: 0.6410846947567872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01529949594975505, AUC: 0.6431380828471361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015153266381526339, AUC: 0.644678123914898\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01501463955233556, AUC: 0.6477582060504216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014884016775443194, AUC: 0.648271553073009\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014761443957532167, AUC: 0.6508382881859451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014646569147366667, AUC: 0.654431717344056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014538689429715554, AUC: 0.6549450643666435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014436917768995708, AUC: 0.6569984524569924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014340260014030505, AUC: 0.6580251465021669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014247766933085755, AUC: 0.6590518405473414\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014158550009717606, AUC: 0.6595651875699289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014071822906873241, AUC: 0.6595651875699289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013986874811397576, AUC: 0.6616185756602778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013903162741019366, AUC: 0.6626452697054523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013820303646427258, AUC: 0.6652120048183888\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013738066513345849, AUC: 0.6662386988635634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013656356073067548, AUC: 0.6667520458861506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01357517775541507, AUC: 0.6677787399313251\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01349455327967926, AUC: 0.6682920869539123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01341452213547985, AUC: 0.6698321280216742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03096084515747323, AUC: 0.5108595936949412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014800748963286911, AUC: 0.5645391879900374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018981876333801394, AUC: 0.5687177684515567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02246806044015825, AUC: 0.5593414154231309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02490788019468572, AUC: 0.5446515456139374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026644151896917056, AUC: 0.5385685441521307\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02785563222122982, AUC: 0.5371142395390809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02875520575861013, AUC: 0.5387228697706121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029436523129480967, AUC: 0.5372085496392639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02997117309096437, AUC: 0.5351980297762707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030370038982257094, AUC: 0.5367809390713885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030633528533682813, AUC: 0.5357628186716851\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030792850391711753, AUC: 0.5362847393397435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030872703339002147, AUC: 0.5373285806758604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030888436990741865, AUC: 0.5383724220119773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03085040355074233, AUC: 0.5383724220119773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030768622522768768, AUC: 0.5388943426800358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030653897279537982, AUC: 0.538902916325507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03051493725668076, AUC: 0.5383895693029197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030357850511128364, AUC: 0.5383895693029197\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030186794312597555, AUC: 0.538902916325507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030004492457609, AUC: 0.5409563044158562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02981248306685106, AUC: 0.5414696514384433\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029611432527656634, AUC: 0.5430182661516764\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02940137341896199, AUC: 0.5440449601968509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029182103356466038, AUC: 0.5445583072194381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028953516705435996, AUC: 0.5450716542420254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02871574476885746, AUC: 0.5455850012646127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028469076808194937, AUC: 0.5460983482872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028214000520252046, AUC: 0.5466116953097873\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027951325442233194, AUC: 0.5476383893549617\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027682209607236875, AUC: 0.5486650834001363\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.027408114131192984, AUC: 0.5507184714904855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027130639330940957, AUC: 0.5543290479395387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02685119893486702, AUC: 0.5553557419847132\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026571099062143645, AUC: 0.5584358241202367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02629174850495459, AUC: 0.5594625181654113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026014997351984058, AUC: 0.5610025592331731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02574302641748148, AUC: 0.5620292532783476\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025478020464658243, AUC: 0.5625426003009351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025221504780076304, AUC: 0.5640826413686967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024974054924943187, AUC: 0.5651093354138712\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02473554848143773, AUC: 0.5661360294590458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02450556587235034, AUC: 0.5697294586171566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024283499944777714, AUC: 0.5712694996849185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024068397024403446, AUC: 0.5748629288430295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02385897271134592, AUC: 0.5769077432879073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023653774774839667, AUC: 0.5774210903104945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023451451682649536, AUC: 0.5799878254234309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023250933266080933, AUC: 0.5805011724460183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023051506737497778, AUC: 0.5825545605363672\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022852823601005982, AUC: 0.5846079486267163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022654798953923132, AUC: 0.5846079486267163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022457661836043648, AUC: 0.5871746837396526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022261806156324303, AUC: 0.5882013777848273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022067625823721876, AUC: 0.589741418852589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02187537752076459, AUC: 0.589741418852589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02168507506881935, AUC: 0.5907681128977637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021496640475887195, AUC: 0.5907681128977637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021310072754727634, AUC: 0.5912814599203509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021125616740982973, AUC: 0.5912814599203509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020943865766189607, AUC: 0.5917948069429381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020765744874689643, AUC: 0.5938481950332872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020592253153862174, AUC: 0.5969282771688107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02042385460673899, AUC: 0.59898166525916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020260046727909063, AUC: 0.6000083593043344\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02009970307596969, AUC: 0.60104362699498\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01994160144719031, AUC: 0.602583668062742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019784756575558744, AUC: 0.604637056153091\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019628507997185053, AUC: 0.6056637501982656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019472473649998382, AUC: 0.6072037912660274\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01931648866483637, AUC: 0.6082304853112019\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01916059154407825, AUC: 0.6087438323337891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01900494913136737, AUC: 0.6097791000244349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018849893139509435, AUC: 0.6102924470470222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018695869801207358, AUC: 0.6123458351373712\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018543445792504224, AUC: 0.6133725291825457\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018393252947315666, AUC: 0.6138858762051331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01824598727018937, AUC: 0.6149125702503077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018102140406890933, AUC: 0.6185059994084185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01796180022182425, AUC: 0.6195326934535931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01782462611701918, AUC: 0.6210727345213547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017690032658863264, AUC: 0.621586081543942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017557363332428546, AUC: 0.6226127755891165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017426026780659614, AUC: 0.6246661636794657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017295543204676782, AUC: 0.6267195517698146\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01716548512934651, AUC: 0.6287729398601639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017035511956698654, AUC: 0.6287729398601639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01690533936147117, AUC: 0.6313396749731001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016774791614856285, AUC: 0.6313396749731001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016643762588500977, AUC: 0.6339064100860365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01651227153359486, AUC: 0.6349331041312111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016380398910238136, AUC: 0.6364731451989728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01624835796237732, AUC: 0.6380131862667346\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016116423636489772, AUC: 0.638526533289322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015985037229075936, AUC: 0.6400665743570838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01585471506691374, AUC: 0.6416066154248455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015726087503058078, AUC: 0.6431466564926074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015599729605096221, AUC: 0.6436600035151947\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015476099452617005, AUC: 0.644173350537782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015355385608554626, AUC: 0.6467400856507182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02340605836477339, AUC: 0.5778358404101631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01006021435463157, AUC: 0.6890006558838784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011253038054914455, AUC: 0.677324422457807\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013256272914246742, AUC: 0.6473970412349479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014980732283977248, AUC: 0.6312014249398773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016354152628106855, AUC: 0.6236726925104921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01741897196009539, AUC: 0.6108904588186375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018270352365560908, AUC: 0.6022235749529521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018943509206515167, AUC: 0.5899289673472712\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019491372394759215, AUC: 0.5894842094884534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019953803739685944, AUC: 0.5874651159799891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02033282807154685, AUC: 0.5869860635392866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020625531056406087, AUC: 0.5839231286947054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020848647407863453, AUC: 0.5834269289630605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02101211468872323, AUC: 0.5808773411410665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02113900273482992, AUC: 0.579850647095892\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021240096161330956, AUC: 0.5783106060281301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021314452153555354, AUC: 0.5772839119829556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021361064713440573, AUC: 0.5762572179377811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021379065069352617, AUC: 0.5757438709151937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021371680510463675, AUC: 0.5762572179377811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02134392029503611, AUC: 0.5772924856284268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02129943425117319, AUC: 0.5783277533190725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02124121075584775, AUC: 0.5783277533190725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021172230288108683, AUC: 0.5793630210097183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02109466378980048, AUC: 0.5809116357229512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021010037534725592, AUC: 0.5824602504361842\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020920647844271136, AUC: 0.5829821711042427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020828938138657722, AUC: 0.585044132840063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02073602597412362, AUC: 0.5855574798626502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02064187877173256, AUC: 0.5865841739078247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020545746228709725, AUC: 0.5886375619981737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020446490056766485, AUC: 0.5906909500885229\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020342722195769443, AUC: 0.5917176441336974\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020233047674901736, AUC: 0.5937796058695176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02011646740678428, AUC: 0.5948062999146922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01999269015547158, AUC: 0.5968596880050414\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019862230273260586, AUC: 0.5973730350276285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0197260128044934, AUC: 0.5994264231179777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019584974640398045, AUC: 0.6014798112083268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019439838441015524, AUC: 0.6025150788989724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019291173844110398, AUC: 0.6045684669893217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019139562334333147, AUC: 0.6066304287251418\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01898575322721809, AUC: 0.6081618961474323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018830610358196755, AUC: 0.6127991666416602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018675044950244343, AUC: 0.6143392077094221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018519832974388487, AUC: 0.6163925957997711\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018365526298064868, AUC: 0.6189593309127074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018212421093421447, AUC: 0.6199860249578819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018060566722482876, AUC: 0.6215346396711149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017909920733907948, AUC: 0.6246147218066386\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.017760390327090307, AUC: 0.6266681098969876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0176119113313979, AUC: 0.6287214979873368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01746445758495765, AUC: 0.6312882331002732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01731807153911077, AUC: 0.6312882331002732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01717286573927348, AUC: 0.6338549682132095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017029018875975046, AUC: 0.634881662258384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016886743205921498, AUC: 0.6364217033261457\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016746248517717634, AUC: 0.6374483973713203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01660769770604483, AUC: 0.6395017854616694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016471147537231445, AUC: 0.6420685205746056\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01633657333026515, AUC: 0.6430952146197804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016203865501451198, AUC: 0.6451486027101293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01607285325818427, AUC: 0.6472019908004784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01594336482061856, AUC: 0.6487420318682403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015815291592299816, AUC: 0.650282072936002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015688625181683843, AUC: 0.6538755020941128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015563512687604126, AUC: 0.6564422372070492\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015440210792588891, AUC: 0.6574689312522238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01531909514164579, AUC: 0.6605490133877474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01520061344833848, AUC: 0.661575707432922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015085232183799981, AUC: 0.6631157485006837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014973451878960336, AUC: 0.6646557895684456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014865718766522457, AUC: 0.6677358717039692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014762384797722163, AUC: 0.6677358717039692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01466355017746951, AUC: 0.6687625657491437\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014569063364348796, AUC: 0.6718426478846673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01447845739360675, AUC: 0.6744093829976036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014391037247936177, AUC: 0.6749227300201909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014305978581525278, AUC: 0.6769761181105399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014222449150638304, AUC: 0.6795428532234764\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01413972086541154, AUC: 0.6805695472686508\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014057178675017741, AUC: 0.6815962413138255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013974399053285335, AUC: 0.6815962413138255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013891110509078696, AUC: 0.6815876676683543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013807209382146041, AUC: 0.683127708736116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013722699621449347, AUC: 0.6846677498038779\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013637699202227543, AUC: 0.6856944438490524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013552410508781733, AUC: 0.6867211378942271\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013467080844855456, AUC: 0.6882611789619887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013381986637786803, AUC: 0.6892878730071632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013297394936129173, AUC: 0.6928813021652742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013213538728638959, AUC: 0.694421343233036\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013130594731364438, AUC: 0.6959613843007978\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013048635506481858, AUC: 0.6975014253685596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01296765216882678, AUC: 0.6985281194137342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012887600292577014, AUC: 0.6995548134589087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012808382634543978, AUC: 0.7010948545266704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01272992021548822, AUC: 0.7016082015492577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.012652173545790015, AUC: 0.7016082015492577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012575163851119963, AUC: 0.7026348955944324\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.008507248777780474, AUC: 0.7367944425630055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008611208163433193, AUC: 0.739002156271836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008750129190290936, AUC: 0.7401831759354919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008920981276849782, AUC: 0.740328927908502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00911147994284304, AUC: 0.7399356119225113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009309929843768322, AUC: 0.7399956274408098\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00950950939462792, AUC: 0.7390546698503471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009709260972143453, AUC: 0.7386184856370004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009908177344201761, AUC: 0.7381565804872403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010104036232452708, AUC: 0.7376775280465377\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010296943518439189, AUC: 0.7372327701877199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01048857997910083, AUC: 0.7367880123289021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010678855281932508, AUC: 0.7379004428287885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010866609419354741, AUC: 0.7379261637652023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011050894640494083, AUC: 0.7379690319925581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011231845456867732, AUC: 0.738559541824386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011409590703360043, AUC: 0.738063342092741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011583388468740395, AUC: 0.7355137542707472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011752184380162083, AUC: 0.7344956338710438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011915278977735689, AUC: 0.732450819426166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01207269447437231, AUC: 0.7340337287212837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012224686071739434, AUC: 0.7319974879218769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012371545499402791, AUC: 0.7315012881902321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012513638036344856, AUC: 0.7284212060547083\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012651138917753168, AUC: 0.727403085655005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012784137982512607, AUC: 0.7263763916098305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012912791708241339, AUC: 0.7248449241875399\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013037327160252795, AUC: 0.7238268037878366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013157956595253007, AUC: 0.723843951078779\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013274868576176171, AUC: 0.7228172570336044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013388240312690813, AUC: 0.7228344043245467\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013498270733756309, AUC: 0.7207810162341977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013605217015521127, AUC: 0.7202676692116105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013709314121222643, AUC: 0.7192495488119071\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01381073136260544, AUC: 0.7172047343670291\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013909569931820066, AUC: 0.7167085346353843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0140059122634477, AUC: 0.7167171082808554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01409981956639892, AUC: 0.7182828702850308\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014191370326292934, AUC: 0.7172647498853276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014280645990470428, AUC: 0.7167514028627402\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014367750219183186, AUC: 0.7162380558401529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014452752612885974, AUC: 0.7167685501536826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014535740542362442, AUC: 0.7162552031310954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014616769786700451, AUC: 0.7152370827313921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014695890201544909, AUC: 0.7147237357088048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014773145225477515, AUC: 0.7142189623316887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01484855608416887, AUC: 0.7142275359771598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014922156343795744, AUC: 0.7142361096226311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01499396871088948, AUC: 0.7132179892229276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015064017866462408, AUC: 0.712191295177753\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015132339844792526, AUC: 0.7111646011325785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015198989437727208, AUC: 0.7091112130422296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01526399873058248, AUC: 0.7101550543783464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015327441272775086, AUC: 0.7086150133105845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015389371362532147, AUC: 0.7086235869560558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015449842804460545, AUC: 0.7081188135789396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015508916807470855, AUC: 0.7091712285605278\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015566652605992666, AUC: 0.707631187492766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01562309511946842, AUC: 0.7060911464250043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0156782971652645, AUC: 0.7045511053572424\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015732315509709265, AUC: 0.7040377583346551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01578518569346047, AUC: 0.7030196379349517\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015836953623201044, AUC: 0.7025062909123645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01588768396318329, AUC: 0.7009662498446027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01593740583700176, AUC: 0.7009662498446027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015986167125820374, AUC: 0.7004529028220154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016034012749081568, AUC: 0.7004614764674867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016080973804860874, AUC: 0.6999481294448994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01612708089761359, AUC: 0.699434782422312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016172377959541653, AUC: 0.699434782422312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016216902999404054, AUC: 0.700478623758429\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016260679217352383, AUC: 0.6999652767358416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01630373129439897, AUC: 0.6984252356680799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01634608094983466, AUC: 0.6968851946003181\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016387747434849078, AUC: 0.6963718475777309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016428755430454547, AUC: 0.6963718475777309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016469117277157233, AUC: 0.6963718475777309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01650884975804552, AUC: 0.6958585005551435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01654796274552434, AUC: 0.6953451535325562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016586463643897393, AUC: 0.6958670742006147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01662437121073405, AUC: 0.6948403801554403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01666168791413554, AUC: 0.6948489538009114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016698421158405564, AUC: 0.6948575274463825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016734576866987084, AUC: 0.693830833401208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016770160963323053, AUC: 0.693830833401208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0168051769027552, AUC: 0.6933174863786208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016839626659764514, AUC: 0.6933174863786208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016873509247110497, AUC: 0.6928041393560335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016906819728590688, AUC: 0.6928041393560335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016939560572306316, AUC: 0.6928041393560335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016971727335675164, AUC: 0.6928041393560335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01700333433368438, AUC: 0.6928041393560335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01703436823858731, AUC: 0.6922907923334461\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01706483102486494, AUC: 0.6912640982882717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01709473355216269, AUC: 0.6907507512656844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0171240708842781, AUC: 0.6902374042430971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017152849931894622, AUC: 0.6902374042430971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017181071682252747, AUC: 0.6902374042430971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017208750450339625, AUC: 0.6902374042430971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017235888704256488, AUC: 0.6892107101979226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017262517542078876, AUC: 0.6892107101979226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039413043430873325, AUC: 0.5404879690319926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03476484764683568, AUC: 0.5494977987165253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03054978190988734, AUC: 0.5559751878700063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026786130901202406, AUC: 0.562426856087074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023486901514278437, AUC: 0.5688870979496127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020664659346112554, AUC: 0.5831675761875571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018348778256718417, AUC: 0.5918183844679838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016475621217526264, AUC: 0.6035235539475208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015055974324544271, AUC: 0.6075799599610757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014044433400250864, AUC: 0.6115420558744477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013350519827927615, AUC: 0.6227595992678107\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012897805397554954, AUC: 0.6281931470851749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012600338483695905, AUC: 0.6346190943658289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012446403009797722, AUC: 0.6436632186322464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012410458570681744, AUC: 0.6485148302632538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012450210302759649, AUC: 0.64611099441427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012538066315107958, AUC: 0.6472662931415124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012657533274427457, AUC: 0.6515445422316342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012800828270290209, AUC: 0.6563104174079297\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.012963395187820213, AUC: 0.6574485688442298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013142908088415553, AUC: 0.6560371324585357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013333958868654619, AUC: 0.6571667102493645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013530754894943712, AUC: 0.6587924877718382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013728723269318448, AUC: 0.6588696505810789\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013927275102824651, AUC: 0.6579115456996738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014127007182340444, AUC: 0.6595373232221474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014326695823274537, AUC: 0.6601192594085041\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0145250437916189, AUC: 0.6586478075045118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014721892141654131, AUC: 0.6581687550638093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014915256026368704, AUC: 0.655097246573757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015104269635850105, AUC: 0.6525648060427054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0152882290676267, AUC: 0.6521029008929451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01546680458337377, AUC: 0.6500752337390097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01564074154966366, AUC: 0.6496047549437782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015811022270787085, AUC: 0.6486209291259597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01597790737823423, AUC: 0.6481504503307284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01614083068958227, AUC: 0.6461056358858505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016299004386917653, AUC: 0.6430255537503269\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016452187583560034, AUC: 0.6451132364225607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01660055995727918, AUC: 0.6435903426457412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016744318956173725, AUC: 0.6436160635821547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01688383380818811, AUC: 0.6446599049182717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017019699325719482, AUC: 0.6436417845185685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017152366184052966, AUC: 0.6421188907417489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017281969141515887, AUC: 0.6390388086062253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017408444027476183, AUC: 0.6380121145610509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017531789854693364, AUC: 0.6380292618519932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017652050555369374, AUC: 0.6380464091429355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017769314487528356, AUC: 0.6375330621203483\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01788367840073864, AUC: 0.634974900652883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0179953116067448, AUC: 0.6344787009212383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018104339485089476, AUC: 0.6324338864763602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018210853355518287, AUC: 0.6314243397221282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018314885796967502, AUC: 0.6329986753717747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018416401762399615, AUC: 0.6340510903533628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018515315361891722, AUC: 0.6345815846668924\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01861150220314168, AUC: 0.6330672645355442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01870492082204878, AUC: 0.6320491441358408\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018795537652436252, AUC: 0.6325710648038992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018883338872937187, AUC: 0.6330929854719577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01896830473874173, AUC: 0.6331101327629002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019050481650153054, AUC: 0.6320834387177257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019129966356739494, AUC: 0.6315786653406096\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01920691484249897, AUC: 0.6321005860086679\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01928149197659384, AUC: 0.6321091596541392\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01935384584509808, AUC: 0.6305691185863773\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019424126508566657, AUC: 0.6295424245412028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01949243367828938, AUC: 0.6285157304960284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01955883744834126, AUC: 0.6264709160511504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019623364474215615, AUC: 0.6259575690285631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01968607399034204, AUC: 0.6275233310327384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019747023256669133, AUC: 0.6275233310327384\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019806265584183528, AUC: 0.6270099840101511\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019863856258352845, AUC: 0.626496636987564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019919837730518287, AUC: 0.6254699429423894\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019974257388223525, AUC: 0.6249565959198021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020027145835923854, AUC: 0.6244432488972149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020078524792910116, AUC: 0.6234165548520403\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02012844460844747, AUC: 0.6218765137842784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020176928976307743, AUC: 0.6218765137842784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020224045028844482, AUC: 0.6203364727165166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02026984212808234, AUC: 0.6203450463619878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020314385431893865, AUC: 0.6198316993394005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020357747996075554, AUC: 0.618805005294226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02040000188918341, AUC: 0.6182916582716387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020441204371166033, AUC: 0.6182916582716387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020481423561617456, AUC: 0.6182916582716387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02052070092463839, AUC: 0.6172649642264643\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02055908779673448, AUC: 0.6177868848945227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02059663452717088, AUC: 0.6177868848945227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020633364809719425, AUC: 0.6167601908493482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020669294440228005, AUC: 0.6167601908493482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020704445137987474, AUC: 0.6167601908493482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020738822826440784, AUC: 0.6167601908493482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020772436390752377, AUC: 0.616246843826761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020805258188188448, AUC: 0.6167687644948194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020837283282546522, AUC: 0.6167687644948194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02086849982694069, AUC: 0.6157420704496449\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020898883140358617, AUC: 0.6152287234270576\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0209284203886739, AUC: 0.6152287234270576\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020957131316696388, AUC: 0.615750644095116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03448131217719605, AUC: 0.5273027740029922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029177505777489326, AUC: 0.5362868827511114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02430507411127505, AUC: 0.5541264955652818\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020027701652321508, AUC: 0.5798206393367429\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016427158568956837, AUC: 0.598789829941742\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013540866705695048, AUC: 0.6271107243444376\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011322073808121138, AUC: 0.6632690024134812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759091442416174, AUC: 0.692693753670592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00866913400574994, AUC: 0.7080437941810668\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007916425079045582, AUC: 0.7254729437183043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074300062582359555, AUC: 0.7381104971428327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007114322289176609, AUC: 0.7414649359334342\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069342128485132696, AUC: 0.7463251212099129\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068505721062606904, AUC: 0.747566156391867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006837263610792456, AUC: 0.746154720006173\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006873386493627576, AUC: 0.7483710073604746\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006941102799915132, AUC: 0.7484567438151865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070315389652923525, AUC: 0.7527264192598372\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007140763798115416, AUC: 0.7548826910958404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007262744765350784, AUC: 0.7493130366566213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073943313357746135, AUC: 0.7473110904390993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007531178170356197, AUC: 0.7458482121805781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007670444731386552, AUC: 0.7428024246269394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007810474676128253, AUC: 0.7423662404135927\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007950406390440883, AUC: 0.7418957616183613\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008089524618587139, AUC: 0.7414424301140723\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008226894197009858, AUC: 0.7394319102510791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008361683128783421, AUC: 0.738422363496847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008493653982569219, AUC: 0.7369166170109699\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008623240650564001, AUC: 0.7369680588837971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008750597635904947, AUC: 0.7390814624924444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0088754011237103, AUC: 0.7375671423610961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008997174770442103, AUC: 0.7355309015616895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00911565695736966, AUC: 0.7345127811619862\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009230909880644046, AUC: 0.7355823434345166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009343165048160908, AUC: 0.7351032909938142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009452652980575403, AUC: 0.7351290119302276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009559473389177342, AUC: 0.7341023178850532\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.009663663789105464, AUC: 0.7351461592211701\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00976527650410591, AUC: 0.7346413858440539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009864376692051226, AUC: 0.7346756804259387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009961020132029279, AUC: 0.7326394396265319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010055263096748179, AUC: 0.7326565869174744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010147189008029599, AUC: 0.7306117724725966\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010236915841112472, AUC: 0.7280536110051312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010324568481919188, AUC: 0.7285926789641322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010410260956726706, AUC: 0.7280879055870161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010494062372369549, AUC: 0.7286269735460168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010576006788644732, AUC: 0.7270869324782551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010656095686412993, AUC: 0.7265735854556677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010734316231547922, AUC: 0.7240068503427314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010810664968707794, AUC: 0.7235106506110865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01088510092741214, AUC: 0.7219706095433247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010957596464927152, AUC: 0.7219706095433247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011028119989557049, AUC: 0.7219791831887958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011096672488542323, AUC: 0.7219791831887958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011163263834287908, AUC: 0.7214658361662086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011227917226945392, AUC: 0.7194124480758596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011290702760589789, AUC: 0.7183943276761562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011351703363422528, AUC: 0.7178809806535689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011411004431746268, AUC: 0.7173676336309818\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011468731838723888, AUC: 0.7168542866083943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011524996155290623, AUC: 0.7168542866083943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011579918812027136, AUC: 0.7153142455406327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011633605443666194, AUC: 0.7158361662086912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011686139965649718, AUC: 0.7153228191861039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011737598889115929, AUC: 0.7158447398541623\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01178802910798825, AUC: 0.7163666605222208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011837471099126907, AUC: 0.716375234167692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01188593424131658, AUC: 0.7163838078131631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011933435317645655, AUC: 0.7169143021266927\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011979966923810434, AUC: 0.7164009551041055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01202553399601338, AUC: 0.7158876080815182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01207014196407721, AUC: 0.7133208729685819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012113804649368823, AUC: 0.7133294466140531\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012156536366875375, AUC: 0.712824673236937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012198365746571163, AUC: 0.712824673236937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012239332771696166, AUC: 0.7133465939049954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012279467059465175, AUC: 0.7133465939049954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012318794278131016, AUC: 0.7128332468824081\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012357371194022042, AUC: 0.7128332468824081\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012395227424353053, AUC: 0.7118151264827047\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012432402458743773, AUC: 0.7113017794601175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012468920978206531, AUC: 0.7113017794601175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012504815068057359, AUC: 0.7113017794601175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012540121749814746, AUC: 0.7107884324375303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012574859781048065, AUC: 0.7107884324375303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012609048412946935, AUC: 0.7097617383923557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01264271528824516, AUC: 0.7097617383923557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012675880151752606, AUC: 0.7092483913697685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012708559292937412, AUC: 0.7087350443471812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012740765052305739, AUC: 0.7087436179926524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012772498910718329, AUC: 0.7087436179926524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012803790979010224, AUC: 0.7087436179926524\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012834630397535999, AUC: 0.7077169239474778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01286503493662453, AUC: 0.7066902299023033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012894996698351873, AUC: 0.7066902299023033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012924534440287398, AUC: 0.7066902299023033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012953651124152584, AUC: 0.7066902299023033\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012982344281846199, AUC: 0.7066988035477745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013010622304912433, AUC: 0.7067073771932456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025727286842298802, AUC: 0.4762681493357568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02626268414483554, AUC: 0.4832417382208828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0268512167051959, AUC: 0.4824636798943727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02746507395868716, AUC: 0.4836532732034997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028082248340235486, AUC: 0.49262880830614775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028696181611244723, AUC: 0.48964303627080713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029300301711751808, AUC: 0.4944174850925739\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029891728861238153, AUC: 0.49867858689175343\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03046913917020241, AUC: 0.495153746897412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0310315029468102, AUC: 0.4973357396698289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031576346166385626, AUC: 0.4969081291019535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03209889848286567, AUC: 0.4959500242205485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03259833357595756, AUC: 0.4960014660933756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03307874849370795, AUC: 0.4986539376610237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03354367360812043, AUC: 0.5002968624744398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0339932264008137, AUC: 0.5013749983924415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03442796959886887, AUC: 0.50349697564656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03484897830718299, AUC: 0.502496002537799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03525780644229234, AUC: 0.5004769090293348\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03565548172155029, AUC: 0.500485482674806\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036041945897767755, AUC: 0.5005369245476331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03641614262361704, AUC: 0.49953595143887203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036777101441693355, AUC: 0.499031178061756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037124949706020316, AUC: 0.4990483253526984\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0374604574641826, AUC: 0.5006312346478161\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03778398209723873, AUC: 0.5011788762522881\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038095553222403516, AUC: 0.5011960235432305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03839549860352068, AUC: 0.5017265178567601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038684390840076265, AUC: 0.5017436651477025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03896286571494788, AUC: 0.5017522387931738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039231549138608185, AUC: 0.5007512656844126\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03949115192421228, AUC: 0.5012731863524712\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03974222100299338, AUC: 0.5002464923072966\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03998499331266984, AUC: 0.49974171893018055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040219391848483194, AUC: 0.5002636395982389\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0404452645753975, AUC: 0.5013160545798271\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04066249499903456, AUC: 0.5008027075572398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040871286490935965, AUC: 0.5008027075572398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04107219190577789, AUC: 0.49926266648947804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04126602472972672, AUC: 0.5003065078255949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04145357080621502, AUC: 0.4992798137804204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04163545999467743, AUC: 0.4987664667578331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0418121484002218, AUC: 0.49877504040330434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0419839144246672, AUC: 0.4992969610713628\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042150866664467886, AUC: 0.49982745538489237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04231296168104215, AUC: 0.4998360290303635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04247006520968293, AUC: 0.5008884440119517\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04262204298568315, AUC: 0.5008970176574228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042768885136637874, AUC: 0.5014189383254812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04291072197829221, AUC: 0.500905591302894\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04304774306082084, AUC: 0.5024713533070694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043180228760523826, AUC: 0.503001847620599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04330838837238572, AUC: 0.5035323419341288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043432452910681936, AUC: 0.5040542626021872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043552641542801945, AUC: 0.5030361422024838\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043669143818920446, AUC: 0.503044715847955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04378221247260368, AUC: 0.5030618631388972\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.04389203113058339, AUC: 0.503592357452427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04399878539407229, AUC: 0.5041142781204855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04410261150225843, AUC: 0.5041142781204855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04420364569432987, AUC: 0.5046361987885439\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04430201236258876, AUC: 0.5051666931020735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04439781418004638, AUC: 0.5046533460794863\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04449117356452389, AUC: 0.5046533460794863\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04458223465313329, AUC: 0.5051752667475448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044671068527190085, AUC: 0.5051752667475448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044757728497680914, AUC: 0.5051752667475448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0448422974928072, AUC: 0.5051838403930159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04492480118082177, AUC: 0.5051838403930159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0450052415362056, AUC: 0.5057143347065456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0450836185589587, AUC: 0.5057143347065456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04515993817252402, AUC: 0.506236255374604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04523422604515439, AUC: 0.506236255374604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045306490074773755, AUC: 0.5057229083520167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04537677764892578, AUC: 0.5057314819974879\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04544513812963513, AUC: 0.5062534026655463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045511601134116605, AUC: 0.5067753233336048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04557621799887584, AUC: 0.5072972440016632\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04563902623905158, AUC: 0.506783896979076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045700057446339606, AUC: 0.506783896979076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04575937875309346, AUC: 0.5067924706245472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04581700595516102, AUC: 0.5073143912926057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045872982491123995, AUC: 0.5073143912926057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04592733797819718, AUC: 0.5073143912926057\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04598009018670945, AUC: 0.5068010442700184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046031282555242505, AUC: 0.5073229649380769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04608093680308719, AUC: 0.5073229649380769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04612907464953436, AUC: 0.5068096179154896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04617576125245657, AUC: 0.5062962708929024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04622103017803058, AUC: 0.5062962708929024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046264932762762036, AUC: 0.5062962708929024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04630751244523264, AUC: 0.5062962708929024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04634878502129028, AUC: 0.5073401122290192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046388799852959614, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04642760432778432, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04646522411401721, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04650167500750619, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04653700439579492, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04657123202369327, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046604401329782934, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04663653600783575, AUC: 0.5078620328970778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03215731547732778, AUC: 0.4979648309062772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02705377673510439, AUC: 0.4899999142635453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022619100337689955, AUC: 0.48633039400187766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019081698194547223, AUC: 0.4936126341239664\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01649377755743623, AUC: 0.5061483755085243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014807789468863982, AUC: 0.5072361567776811\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013860120536377711, AUC: 0.519224256557767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013499482077841433, AUC: 0.5291503946020328\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013552116804735014, AUC: 0.5383831390688164\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013825610557698315, AUC: 0.5330792676392039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014225316590650728, AUC: 0.5297173269088149\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014698486150421712, AUC: 0.5289735631641896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015217207973788244, AUC: 0.5297784141327971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015756703805232395, AUC: 0.5310108756692802\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016295228685651506, AUC: 0.5285813188838829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016821188462693745, AUC: 0.526630814539188\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017329448004933863, AUC: 0.5267336982848423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017814996573248757, AUC: 0.5206335495320933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018276149441736826, AUC: 0.5217374063865086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01871539248195988, AUC: 0.5187259134147545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01913594903412813, AUC: 0.514653431815941\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019538604941674146, AUC: 0.5142086739571232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01992365538950539, AUC: 0.5117105280079564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02029071140486755, AUC: 0.5097085817904343\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02063954690968768, AUC: 0.5092552502861454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020971738527033393, AUC: 0.5098286128270311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021289149179715302, AUC: 0.5098629074089157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02159250547673638, AUC: 0.5088876552365683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02188170079612337, AUC: 0.5088962288820394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022156823989520655, AUC: 0.5073647614597488\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022418829718485134, AUC: 0.5079124030642209\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022668855284064947, AUC: 0.5094867387138675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022907782292020493, AUC: 0.5074333506235184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02313607869434554, AUC: 0.5084857656051064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023353908372961956, AUC: 0.5079809922279904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02356146778872788, AUC: 0.5090334072095785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0237591202461448, AUC: 0.5090505545005208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023947261628650483, AUC: 0.5080410077462887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0241263292837834, AUC: 0.5090934227278767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02429683164039754, AUC: 0.5080838759736446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024459450881673683, AUC: 0.5096582116232912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024614929412462697, AUC: 0.5107020529594081\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02476394744146438, AUC: 0.5081353178464717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024907005499608767, AUC: 0.5076305444693557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0250445034192956, AUC: 0.5081610387828852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02517675316852072, AUC: 0.5092134537644734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025303956144344733, AUC: 0.5097353744325318\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025426313743828248, AUC: 0.509743948078003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025543948384792414, AUC: 0.5087172540328285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025656981497817897, AUC: 0.5087172540328285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025765522666599438, AUC: 0.5092477483463581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02586969924516066, AUC: 0.5087344013237709\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025969662281297008, AUC: 0.5092648956373005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02606561119758811, AUC: 0.5092648956373005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026157762199701978, AUC: 0.5097953899508302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02624632754434463, AUC: 0.5103173106188886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026331520475462604, AUC: 0.5108392312869471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02641356016044538, AUC: 0.5113611519550055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026492640098429613, AUC: 0.511883072623064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026568930094780143, AUC: 0.511883072623064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026642597980380798, AUC: 0.5124049932911224\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02671377308373619, AUC: 0.5124135669365936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026782594605755855, AUC: 0.5113954465368902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02684919483666588, AUC: 0.5113954465368902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026913655717427192, AUC: 0.510882099514303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02697606215072221, AUC: 0.510882099514303\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027036488179587922, AUC: 0.5103687524917156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027094996000175398, AUC: 0.5103687524917156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02715163694899028, AUC: 0.5098554054691284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027206446566690322, AUC: 0.5108992468052453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027259455457730817, AUC: 0.5108992468052453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02731069225208606, AUC: 0.5108992468052453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027360188541451842, AUC: 0.5114211674733039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02740796012167605, AUC: 0.5103944734281294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027454033648251993, AUC: 0.5103944734281294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02749843182771102, AUC: 0.5103944734281294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02754121586896371, AUC: 0.509881126405542\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027582393669934008, AUC: 0.5093677793829549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027622008669203606, AUC: 0.5093677793829549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027660096407430265, AUC: 0.5098897000510133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027696707233879136, AUC: 0.5104116207190718\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027731873727486495, AUC: 0.5098982736964844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027765668944048832, AUC: 0.5104201943645428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027798125462502425, AUC: 0.5104201943645428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0278292975810744, AUC: 0.5104201943645428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027859198133891167, AUC: 0.5104201943645428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027887893266065767, AUC: 0.5104201943645428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027915395811724614, AUC: 0.5114640357006598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02794176006909483, AUC: 0.5114640357006598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02796702454055565, AUC: 0.5114640357006598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027991213907119405, AUC: 0.5109506886780725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02801435877324138, AUC: 0.5109506886780725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028036476909250454, AUC: 0.5109592623235436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028057611753728326, AUC: 0.5114811829916021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02807780082181374, AUC: 0.5114811829916021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02809704115178521, AUC: 0.5114811829916021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028115360386376548, AUC: 0.5120031036596605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02813276247454973, AUC: 0.5120031036596605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02814927802076004, AUC: 0.5120031036596605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0281649188718934, AUC: 0.5120031036596605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028179697862076216, AUC: 0.5120031036596605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02773823254350303, AUC: 0.4845374303927158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02824369770152722, AUC: 0.4835450309294261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028692367901219592, AUC: 0.4856670081835445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02911717551095145, AUC: 0.48778898543766314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0295190169450906, AUC: 0.4898938154008393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029898888329294653, AUC: 0.49044145700531133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030256686990552315, AUC: 0.49098052496431216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030592887791540804, AUC: 0.4920329399459003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03090952938387853, AUC: 0.4915453138597266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03120825749746761, AUC: 0.4910405404826105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031490110709306865, AUC: 0.49157960844161136\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031755497736960465, AUC: 0.49158818208708255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03200504843986306, AUC: 0.492110102755141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03224053491469989, AUC: 0.49316251773672903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03246429889592078, AUC: 0.4947282797409044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032678230949070144, AUC: 0.4957721210770213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032883531558587684, AUC: 0.4957892683679637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033080857239401365, AUC: 0.49684168334955187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0332705387170764, AUC: 0.4984074453537272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03345277146523043, AUC: 0.4984074453537272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03362766408031772, AUC: 0.4994512866898441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03379529356709672, AUC: 0.49894651331272794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03395574186652837, AUC: 0.5005208489623746\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034109121524028896, AUC: 0.5010599169213754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03425565368146877, AUC: 0.5010599169213754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03439555355727549, AUC: 0.5026256789255508\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034529075859496314, AUC: 0.5031475995936092\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03465644962792564, AUC: 0.5036695202616677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03477803816706498, AUC: 0.50368666755261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03489424624551651, AUC: 0.5031733205300227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035005474682920465, AUC: 0.5042171618661396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035112094681702295, AUC: 0.5042171618661396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03521440438849092, AUC: 0.5047476561796693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035312684179586405, AUC: 0.5042343091570821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03540714927341627, AUC: 0.5047562298251405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03549799909256013, AUC: 0.5047562298251405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03558543898304057, AUC: 0.5063219918293158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03566963282677944, AUC: 0.5063219918293158\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03575077017395146, AUC: 0.506330565474787\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0358290247788834, AUC: 0.5068524861428454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03590450326354854, AUC: 0.5068524861428454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03597731027543915, AUC: 0.5068524861428454\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03604752084483271, AUC: 0.5063391391202582\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03611516458894402, AUC: 0.5068610597883166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03618023360984913, AUC: 0.5068610597883166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03624275555028185, AUC: 0.5053210187205549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03630273435920415, AUC: 0.5053210187205549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03636019767934985, AUC: 0.5048076716979677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03641515538312387, AUC: 0.5042943246753804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03646769039872764, AUC: 0.5042943246753804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036517883679881596, AUC: 0.5053381660114972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0365658003844583, AUC: 0.5053381660114972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03661152541514016, AUC: 0.5058600866795557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036655181189748316, AUC: 0.5058600866795557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036696860508889144, AUC: 0.5058600866795557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03673665814764998, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0367746787535231, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03681100722919093, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03684573045181685, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03687893727304526, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03691068692730574, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03694106629176169, AUC: 0.5063820073476142\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03697013854980469, AUC: 0.5063905809930854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03699797083378825, AUC: 0.5063905809930854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037024586837484226, AUC: 0.5063905809930854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037050075412537, AUC: 0.5063905809930854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037074468150642345, AUC: 0.5063905809930854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03709779664349605, AUC: 0.5063991546385566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037120122100008694, AUC: 0.5063991546385566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03714148006083803, AUC: 0.5063991546385566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03716188829631292, AUC: 0.5063991546385566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0371813882705341, AUC: 0.5074429959746735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037200001702792404, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037217748337897705, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0372346558185838, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037250757711027475, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03726603821938082, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037280519062934704, AUC: 0.5074515696201446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03729421011409404, AUC: 0.507973490288203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0373071311176687, AUC: 0.507973490288203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03731929194606362, AUC: 0.507973490288203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03733068272687387, AUC: 0.507973490288203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037341311358023384, AUC: 0.507973490288203\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03735119560984104, AUC: 0.5084954109562615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037360337456807835, AUC: 0.5084954109562615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037368727026518826, AUC: 0.50901733162432\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03737637221689797, AUC: 0.5085039846017327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037383284874831176, AUC: 0.5085039846017327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03738946894928042, AUC: 0.5085039846017327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037394936287131614, AUC: 0.5085039846017327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03739968886286576, AUC: 0.5085039846017327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037403744446811715, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03740710303896949, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037409768588301064, AUC: 0.5085125582472039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741175491617333, AUC: 0.5085125582472039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741308571635813, AUC: 0.5085125582472039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741375901437447, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741379455503223, AUC: 0.5090259052697912\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.03741319036385041, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741197408356282, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03741013781624551, AUC: 0.5090259052697912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02297484652596231, AUC: 0.5814678509728944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023053746786176787, AUC: 0.5814678509728944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02309856947904788, AUC: 0.5814678509728944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023142237100541963, AUC: 0.5819897716409529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023184766433747412, AUC: 0.5819897716409529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023226204866207904, AUC: 0.5819897716409529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023266564244809357, AUC: 0.5819897716409529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02330587517400706, AUC: 0.5819897716409529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02334415246240841, AUC: 0.5814764246183657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02338143165067116, AUC: 0.5814764246183657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023417708789833337, AUC: 0.5809630775957784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023453006586426288, AUC: 0.5809630775957784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023487339849057404, AUC: 0.5809630775957784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023520719437372117, AUC: 0.5804497305731912\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023553176943066204, AUC: 0.5809716512412496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023584714340620653, AUC: 0.5804583042186622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023615341502440396, AUC: 0.5804583042186622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02364506040300642, AUC: 0.5804583042186622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02367387696576168, AUC: 0.5804583042186622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02370180994827555, AUC: 0.5799449571960751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023728839605738163, AUC: 0.5799449571960751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02375497975951643, AUC: 0.5799449571960751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023780242256496265, AUC: 0.5794316101734877\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02380462512219668, AUC: 0.5789182631509006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023828139216263103, AUC: 0.5789182631509006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023850776640771586, AUC: 0.577891569105726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023872536408481637, AUC: 0.577891569105726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023893436289722136, AUC: 0.5784134897737845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023913488131378995, AUC: 0.5784134897737845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023932689958971232, AUC: 0.5784134897737845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02395108027487808, AUC: 0.5784134897737845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02396865907909954, AUC: 0.5779001427511972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023985458950571886, AUC: 0.5779001427511972\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02400149371066202, AUC: 0.5773867957286097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024016775206255864, AUC: 0.5773867957286097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024031344901454126, AUC: 0.5768734487060225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02404522352830717, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024058434780586828, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024070991492419508, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02408292920446297, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024094261738084117, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024105002914649853, AUC: 0.5763601016834352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024115200121703848, AUC: 0.5753334076382608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024124859282689065, AUC: 0.5753334076382608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024133999155174873, AUC: 0.5753334076382608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02414264145845212, AUC: 0.5753334076382608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024150798039406722, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02415847975768411, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02416570043465119, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02417247487891535, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024178811975641035, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02418472653343564, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024190237309868537, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024195339368737263, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024200048505889703, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02420436768304734, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024208303810893627, AUC: 0.5758553283063192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02421186873631448, AUC: 0.575341981283732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024215069369993347, AUC: 0.575341981283732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024217907686411223, AUC: 0.575341981283732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024220385660049092, AUC: 0.5753505549292032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024222514150552373, AUC: 0.5753505549292032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02422429513240206, AUC: 0.5753505549292032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024225742426965055, AUC: 0.5753505549292032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024226859983203328, AUC: 0.5753505549292032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024227645826635894, AUC: 0.5758724755972616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024228105880705713, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02422824113265328, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024228062442124013, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024227571783598904, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02422676718259697, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024225665422206586, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024224262553465787, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024222570423260485, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024220587057109697, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024218321340177863, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024215783144869912, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024212959637059436, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024209869574315798, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024206509007677034, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024202878924383633, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024198992158562006, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024194851671933634, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024190466349662956, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024185830268307007, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024180955274751715, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02417584729244003, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024170498423448015, AUC: 0.574845781552087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02416490768053517, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024159090859549388, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024153044011528693, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024146783919561477, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02414031255812872, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024133624003787466, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02412672714170215, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024119619010151295, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024112313430501808, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02410480941551319, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024097100054501993, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024089196207113642, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0240811028095506, AUC: 0.5753591285746744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07236820323620277, AUC: 0.48746533032112593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07241359655407892, AUC: 0.48746533032112593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07241153519592917, AUC: 0.4879872509891844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07240845895455245, AUC: 0.4879872509891844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07240438757475859, AUC: 0.4879872509891844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07239936054616734, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07239339761358858, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07238651457287017, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07237871932193606, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07237003950352007, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07236047906658417, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07235005380697626, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07233879136743013, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07232668779898381, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07231376284644717, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0723000323056681, AUC: 0.48850917165724284\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.07228550407457056, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0722701821021165, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07225408613311578, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07223725170822617, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07221968277640965, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07220139513351409, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07218242037123528, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07216277428542112, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07214244897814764, AUC: 0.48850917165724284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07212149183695854, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07209991470873973, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0720777333893391, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07205498341941438, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07203165690104167, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07200778542591671, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07198337689196348, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07195844709502984, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0719330276268116, AUC: 0.4890310923253013\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0719071224362707, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07188073152340717, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07185389042887876, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07182658335683756, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07179885374586528, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07177069369803799, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07174211506024157, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07171312178143803, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07168373360643722, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07165396238212507, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07162380810850155, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07159329053037655, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07156240569878809, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07153116151166011, AUC: 0.4900749336614182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07149957771380248, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07146764245832929, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07143538338797432, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07140279655377564, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07136988985365715, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07133668303242875, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07130315634528056, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07126934138390835, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07123522235246425, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07120081504679615, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07116610367105615, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07113111981694002, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07109585953548582, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07106033072461747, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07102452943537299, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07098845566775241, AUC: 0.4905968543294767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07095211337071768, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07091550254426882, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07087863898425369, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07084151874171034, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0708041378676768, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07076651215800094, AUC: 0.49111877499753515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07072863371475883, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0706904985889885, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07065211862757587, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07061349777948289, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07057462814678564, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07053551762740805, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07049617411927407, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0704565976223837, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07041679603466089, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07037676540714366, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.070336509688794, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07029603677753583, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07025535062233114, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07021443542733202, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07017331488631033, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07013198899926606, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07009045776619921, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07004872118710978, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07000678715992172, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06996465173567304, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06992233465917362, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06987981223665163, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06983709631499296, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0697941789962737, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06975108792322764, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06970782704481673, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06966438056519313, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0696207642802047, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06957697424088946, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06953302229413334, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06948889264408846, AUC: 0.49163212202012235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014004219146001907, AUC: 0.670686277451741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0142676692078079, AUC: 0.6676490635435735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014512591727278494, AUC: 0.6661347434122252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014750363663857027, AUC: 0.6640985026128184\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014980361081551815, AUC: 0.6605136471001788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015202568184514964, AUC: 0.656424018210423\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015417875957291565, AUC: 0.6554401923926044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015627461190549485, AUC: 0.6533953779477265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01583192264564783, AUC: 0.6523772575480232\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016031192696612816, AUC: 0.6487924020353835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016225050201573974, AUC: 0.6493314699943843\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01641345517729133, AUC: 0.646773308526919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016596497956270016, AUC: 0.645763761772687\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016774259492230464, AUC: 0.6452589883955708\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016946839002842242, AUC: 0.6421789062600473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01711445170653286, AUC: 0.6411607858603438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017277424379905558, AUC: 0.6416998538193448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017436045297184347, AUC: 0.6411865067967575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017590477353050596, AUC: 0.6401769600425253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017740918982843433, AUC: 0.637610224929589\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01788758046878791, AUC: 0.6365921045298856\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018030662220704135, AUC: 0.635060637107595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01817034687808335, AUC: 0.6361044784437119\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018306807208011856, AUC: 0.6376788140933585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018440157730386864, AUC: 0.6376959613843008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018570479398928814, AUC: 0.6361644939620102\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018697924248673656, AUC: 0.6346244528942484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01882267195739114, AUC: 0.6336063324945451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018944890355965117, AUC: 0.6320662914267833\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019064666321558982, AUC: 0.6305262503590214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01918199590521076, AUC: 0.6300214769819054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019296876145198972, AUC: 0.6269413948463818\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01940926952638488, AUC: 0.626949968491853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019519178023249466, AUC: 0.6259232744466784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019626594725109282, AUC: 0.6243832333789165\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.019731523580926297, AUC: 0.6244003806698588\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01983404060821849, AUC: 0.6238870336472716\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01993417739868164, AUC: 0.6228774868930395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02003201885499816, AUC: 0.6218507928478649\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02012763408400257, AUC: 0.6197974047575159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020221124771465673, AUC: 0.6197974047575159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02031256199870297, AUC: 0.6187707107123412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02040205238768773, AUC: 0.617752590312638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020489640364242143, AUC: 0.617752590312638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020575396022441225, AUC: 0.6172392432900506\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020659358851904702, AUC: 0.6172478169355218\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020741559457087864, AUC: 0.6167344699129347\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020822050161736844, AUC: 0.6167344699129347\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020900868480990393, AUC: 0.6151944288451727\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02097806673859464, AUC: 0.6141677347999983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021053716015865098, AUC: 0.6131410407548238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02112790318996516, AUC: 0.6126276937322364\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021200681571881468, AUC: 0.6121229203551204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021272128166372486, AUC: 0.6121314940005916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02134230615682977, AUC: 0.6126534146686501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021411252071151576, AUC: 0.6126534146686501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02147899750103368, AUC: 0.6126534146686501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021545554293362003, AUC: 0.6121400676460629\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02161091158849112, AUC: 0.6116267206234756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021675068399180538, AUC: 0.6111133736008882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02173800201889891, AUC: 0.6111219472463595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021799697639038843, AUC: 0.6106086002237722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021860155259600337, AUC: 0.6111305208918306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02191934328888761, AUC: 0.6116524415598891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02197727258654608, AUC: 0.612696282896006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02203392439500639, AUC: 0.6121829358734187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02208931253563543, AUC: 0.6121829358734187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022143442931876173, AUC: 0.6127048565414771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02219632249441206, AUC: 0.6127048565414771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02224796504461, AUC: 0.6127048565414771\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022298416982773173, AUC: 0.612200083164361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022347677321661086, AUC: 0.6111733891191865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02239580035950086, AUC: 0.6106600420965993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022442785109052007, AUC: 0.6091200010288375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022488678957858194, AUC: 0.6086066540062501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02253350856141274, AUC: 0.6086066540062501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022577301562449453, AUC: 0.6080933069836629\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022620086590942636, AUC: 0.6075799599610756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022661869570335245, AUC: 0.6075799599610756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02270269591368997, AUC: 0.6065532659159011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02274256858272829, AUC: 0.6065532659159011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022781516207424503, AUC: 0.6065532659159011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022819570379474394, AUC: 0.6060399188933139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022856740971282895, AUC: 0.6060399188933139\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02289306352350776, AUC: 0.6050132248481394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02292855383199688, AUC: 0.6050217984936105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022963237565003073, AUC: 0.6050217984936105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022997148288703112, AUC: 0.6050217984936105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02303030278618538, AUC: 0.6050217984936105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02306271685329777, AUC: 0.6050303721390816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023094419120014576, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02312542834390518, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023155761308057955, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023185433808320798, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023214459666060613, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023242860600568245, AUC: 0.6045170251164944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023270638586324686, AUC: 0.6045255987619655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02329780349573487, AUC: 0.6045255987619655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02332435927776076, AUC: 0.6040122517393783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02335032370273124, AUC: 0.603498904716791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023375701706848776, AUC: 0.603498904716791\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033992494855608256, AUC: 0.4614571767842828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02911826443721542, AUC: 0.45349226014155086\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02488325940402645, AUC: 0.44771790991670707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0215485920323595, AUC: 0.4498066642946248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019147966712651537, AUC: 0.4560793576624813\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017658136893009792, AUC: 0.4821164472527897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01691824654367893, AUC: 0.49040823412911055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016707489455955616, AUC: 0.5100536710206496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01686557726336809, AUC: 0.5327791900477123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017227361908116943, AUC: 0.5434405181911323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01769981818663161, AUC: 0.5530665786439064\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018228488432447856, AUC: 0.5589620316110309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018777586658548864, AUC: 0.564344137555568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019327207134870763, AUC: 0.5727977519901575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01987216586158389, AUC: 0.5703424742683465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02040004335328412, AUC: 0.5699405846368847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020906067289427448, AUC: 0.5715663621593583\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021390231746570912, AUC: 0.5768455843582413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021851107200480394, AUC: 0.5769055998765394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02228934621712189, AUC: 0.5775046833538385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022705129461505644, AUC: 0.5791304608763124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023099537961971686, AUC: 0.5791733291036683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0234757555691105, AUC: 0.5792676392038513\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02383611315772647, AUC: 0.5777533190725029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024180710439109406, AUC: 0.5767694932546844\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024508859306635572, AUC: 0.5757770937913946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02482079077458036, AUC: 0.5747761206826336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025118272990667056, AUC: 0.5737837212193438\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025403135311529504, AUC: 0.5717560540654083\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02567633042424362, AUC: 0.5743656574057007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025938455609307774, AUC: 0.5754437933237022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026190339161495737, AUC: 0.5739294731923541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026432942653047867, AUC: 0.5734332734607092\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026666944318182968, AUC: 0.572423726706477\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026892579120138416, AUC: 0.5703703386161278\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02710980756929449, AUC: 0.5693607918618957\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02731847269441277, AUC: 0.568873165775722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02751859818926509, AUC: 0.567872192666961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027710516753897657, AUC: 0.5668454986217865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027894779268505657, AUC: 0.5658273782220831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028071996834954368, AUC: 0.567915060894317\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02824272428240095, AUC: 0.5684455552078466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028407400932864868, AUC: 0.5679322081852592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02856635948639232, AUC: 0.5689760495213761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028719827008296738, AUC: 0.5689846231668475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028868050308701414, AUC: 0.5695065438349058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029011217950540548, AUC: 0.5700370381484355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029149529356393755, AUC: 0.5700456117939068\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029283184936081154, AUC: 0.5710894531300237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029412339686360173, AUC: 0.5721332944661406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029537169336038595, AUC: 0.5716199474435533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02965785553736716, AUC: 0.5721418681116117\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029774557236065282, AUC: 0.5706018270438499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0298874699057506, AUC: 0.5700970536667338\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.029996743606978075, AUC: 0.5706189743347923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03010256986440339, AUC: 0.570105627312205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03020505628724029, AUC: 0.569600853935089\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030304333191233886, AUC: 0.5690875069125017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03040053385385075, AUC: 0.5690875069125017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030493761935342666, AUC: 0.5690875069125017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030584178355910024, AUC: 0.5680608128673271\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03067193218886729, AUC: 0.5685913071808567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03075719027785781, AUC: 0.5685913071808567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030840061219335836, AUC: 0.5691132278489152\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03092069507385633, AUC: 0.5675731867811534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03099919056546861, AUC: 0.5670598397585661\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031075651354424454, AUC: 0.5660331457133916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031150181100975654, AUC: 0.5665636400269213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03122288741433596, AUC: 0.566050293004334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03129386605683321, AUC: 0.5645102519365721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03136319995666883, AUC: 0.563492131536869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0314309513099939, AUC: 0.563492131536869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03149718823640243, AUC: 0.5629787845142815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0315619443020712, AUC: 0.5624654374916944\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03162521259631676, AUC: 0.5619606641145782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03168702865979686, AUC: 0.5624825847826367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03174739940319496, AUC: 0.5624825847826367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03180633272443499, AUC: 0.5624825847826367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03186382862351696, AUC: 0.5619692377600495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03191990388352925, AUC: 0.5614558907374622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0319745683768768, AUC: 0.560942543714875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032027819141838124, AUC: 0.560942543714875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032079670987020616, AUC: 0.559402502647113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0321301643892845, AUC: 0.5588891556245259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032179312182756194, AUC: 0.5588891556245259\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03222713904844801, AUC: 0.5583843822474097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03227367262909378, AUC: 0.5578710352248224\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03231894550362976, AUC: 0.5573576882022352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03236298432754927, AUC: 0.5573576882022352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03240581674358613, AUC: 0.5573576882022352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03244747829239808, AUC: 0.5568443411796479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03248799266775696, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03252738849963707, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03256568750732927, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03260291634632687, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03263908883799677, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032674220778186866, AUC: 0.5563309941570607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03270833586066899, AUC: 0.556852914825119\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03274147160058189, AUC: 0.5573748354931776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.032773614176558656, AUC: 0.5568614884705901\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03280480998890247, AUC: 0.5568614884705901\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOFTMAX 2 CLASS RATIO \n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 1e-5, 1e-6, 1e-7, 1e-8]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_reduced_ratio, network, optimizer, verbose=False)\n",
    "            _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "            model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "        plt.plot(np.arange(-1, n_epochs), aucs[i])\n",
    "    plt.title(\"Logistic Regression 2 Classes \" + str(ratio) + \" with Softmax \\n Learning Rate = \" + str(learning_rate))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5756578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGMOID 2 CLASS \n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.0001, 0.00001, 1e-6, 1e-7]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced,  network, optimizer, verbose=False)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "            model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "        plt.plot(np.arange(-1, n_epochs), aucs[i])\n",
    "    plt.title(\"Logistic Regression 2 Classes with Sigmoid \\n Learning Rate = \" + str(learning_rate))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4cf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOFTMAX 2 CLASS  \n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 1e-5, 1e-6, 1e-7, 1e-8]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_reduced, network, optimizer, verbose=False)\n",
    "            _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "            model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "        plt.plot(np.arange(-1, n_epochs), aucs[i])\n",
    "    plt.title(\"Logistic Regression 2 Classes with Softmax \\n Learning Rate = \" + str(learning_rate))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4bfba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f42d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f622e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import class_sampling\n",
    "import train\n",
    "import metric_utils\n",
    "import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316238b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "momentum = 0\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "nums = (0, 1)\n",
    "ratio = (100, 1)\n",
    "#nums = (0, 3, 1)\n",
    "#ratio = (200, 20, 1)\n",
    "\n",
    "CLASS_LABELS = {'airplane': 0,\n",
    "                 'automobile': 1,\n",
    "                 'bird': 2,\n",
    "                 'cat': 3,\n",
    "                 'deer': 4,\n",
    "                 'dog': 5,\n",
    "                 'frog': 6,\n",
    "                 'horse': 7,\n",
    "                 'ship': 8,\n",
    "                 'truck': 9}\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45084171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, num_classes, classes used, ratio, learning rate, mean 10, variance 10, mean 20, variance 20, ... 50\n",
    "\n",
    "# mean, variance every 10 epochs - average of 10 models \n",
    "# name, num_classes, classes used, ratio, learning rate, mean 10, variance 10, mean 20, variance 20, ... 50\n",
    "# name: normal/ratio/oversampled/undersampled/weighted\n",
    "\n",
    "col_names = [\"name\", \n",
    "            \"num_classes\", \n",
    "            \"classes_used\", \n",
    "            \"ratio\", \n",
    "            \"learning_rate\", \n",
    "            \"mean_0\", \"variance_0\",\n",
    "            \"mean_10\", \"variance_10\",\n",
    "            \"mean_20\", \"variance_20\",\n",
    "            \"mean_30\", \"variance_30\",\n",
    "            \"mean_40\", \"variance_40\",\n",
    "            \"mean_50\", \"variance_50\"]\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53bc6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor() ]))  \n",
    "\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()]))\n",
    "\n",
    "train_CIFAR10.data = train_CIFAR10.data.reshape(50000, 3, 32, 32)\n",
    "test_CIFAR10.data = test_CIFAR10.data.reshape(10000, 3, 32, 32)\n",
    "\n",
    "    \n",
    "reduced_train_CIFAR10 = class_sampling.Reduce(train_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "reduced_test_CIFAR10 = class_sampling.Reduce(test_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "\n",
    "ratio_train_CIFAR10 = class_sampling.Ratio(train_CIFAR10, NUM_CLASSES_REDUCED, ratio, nums=nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea24f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000   50]\n",
      "[  1. 100.]\n"
     ]
    }
   ],
   "source": [
    "targets = ratio_train_CIFAR10.labels \n",
    "\n",
    "class_count = np.unique(targets, return_counts=True)[1]\n",
    "print(class_count)\n",
    "\n",
    "weight = 1. / class_count\n",
    "\n",
    "samples_weight = weight[targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "oversampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(max(class_count) * NUM_CLASSES_REDUCED), replacement=True)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "undersampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * NUM_CLASSES_REDUCED), replacement=False)\n",
    "\n",
    "weight *= class_count[0]\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "129b16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_reduced = DataLoader(reduced_train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_ratio = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True) \n",
    "\n",
    "train_loader_oversampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=oversampler)\n",
    "\n",
    "train_loader_undersampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler)\n",
    "\n",
    "train_loader_sampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=sampler)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_CIFAR10, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62bfbc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5050])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader_oversampled.dataset.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39a165b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02157968044281006, AUC: 0.6867034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03557538032531738, AUC: 0.570759\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013752534389495849, AUC: 0.889133\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007762441396713257, AUC: 0.8451270000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008736375808715821, AUC: 0.8208995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008814629077911376, AUC: 0.8945854999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023658716201782226, AUC: 0.398378\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12261966705322265, AUC: 0.532487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00910294771194458, AUC: 0.8903105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00748134970664978, AUC: 0.8410195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.048084203720092776, AUC: 0.7297494999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007408306837081909, AUC: 0.848622\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04466411209106445, AUC: 0.5848144999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009844433307647706, AUC: 0.8901745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011238266944885254, AUC: 0.7808945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010974647521972657, AUC: 0.8965535000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04756582450866699, AUC: 0.5249565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009717530250549316, AUC: 0.8946590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04384331321716309, AUC: 0.4436590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024437979698181154, AUC: 0.839005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02754481792449951, AUC: 0.8283135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011495758533477783, AUC: 0.782538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05346719932556152, AUC: 0.7063005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007859370470046997, AUC: 0.8909530000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04979433250427246, AUC: 0.46103200000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03539727020263672, AUC: 0.7777075000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00665674090385437, AUC: 0.881261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069861550331115725, AUC: 0.858966\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011598192691802978, AUC: 0.8935744999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04395664978027344, AUC: 0.7528575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011570464134216309, AUC: 0.651253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008485919952392578, AUC: 0.8310584999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007137730836868286, AUC: 0.873239\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007003791332244873, AUC: 0.8596834999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068540554046630855, AUC: 0.878115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007024867057800293, AUC: 0.8563305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03422253608703613, AUC: 0.6372905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006847788572311401, AUC: 0.8748335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041805192947387694, AUC: 0.7538664999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04375720977783203, AUC: 0.748456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02581379699707031, AUC: 0.6126409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0126045241355896, AUC: 0.8899775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04881747627258301, AUC: 0.4903955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02173524856567383, AUC: 0.8547454999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007633687973022461, AUC: 0.8359445000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014351594448089599, AUC: 0.758213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007851038694381713, AUC: 0.84555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03978425025939941, AUC: 0.551257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02902210330963135, AUC: 0.636784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04108669662475586, AUC: 0.758172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009445556163787842, AUC: 0.8907415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022098307609558106, AUC: 0.6658614999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03197484016418457, AUC: 0.5869779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012054906368255616, AUC: 0.7623385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0384180850982666, AUC: 0.49347649999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006990707397460937, AUC: 0.862115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01045944356918335, AUC: 0.7911435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03387751388549805, AUC: 0.7927390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006703308582305908, AUC: 0.8741925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012621391296386718, AUC: 0.8944415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019174320220947266, AUC: 0.4311704999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032376829385757444, AUC: 0.8108195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027001585960388184, AUC: 0.8255600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002303639054298401, AUC: 0.81335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019409794211387634, AUC: 0.830818\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018947908282279967, AUC: 0.838327\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01882424736022949, AUC: 0.6324909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030493323802947996, AUC: 0.782018\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003033123254776001, AUC: 0.7864504999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019657838940620423, AUC: 0.824504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018309500217437743, AUC: 0.8252754999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002569401264190674, AUC: 0.8524075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017050434112548828, AUC: 0.49219050000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029734364748001097, AUC: 0.8060115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022927021980285647, AUC: 0.81248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001998478949069977, AUC: 0.822905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019378600120544434, AUC: 0.816849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002032427728176117, AUC: 0.8113474999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025902076721191405, AUC: 0.6785265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003256563901901245, AUC: 0.8101260000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00293392276763916, AUC: 0.7972734999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036092838048934935, AUC: 0.846182\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002104672074317932, AUC: 0.8188085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019120048880577087, AUC: 0.8373705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013246777534484864, AUC: 0.5174624999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031004265546798705, AUC: 0.7907150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026331080198287965, AUC: 0.8279855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021486014127731325, AUC: 0.823504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020407789945602415, AUC: 0.831711\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019359016418457032, AUC: 0.8363550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013060497283935548, AUC: 0.651512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003436782479286194, AUC: 0.7757329999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035022896528244018, AUC: 0.8150865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00308358359336853, AUC: 0.8215815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020748037099838257, AUC: 0.8113415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001982709228992462, AUC: 0.8203625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07371361541748046, AUC: 0.4995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003697535753250122, AUC: 0.7845390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004488152980804443, AUC: 0.8214275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002518478989601135, AUC: 0.8105085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002313725590705872, AUC: 0.801301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002170778512954712, AUC: 0.822812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024945231437683107, AUC: 0.4672625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028195897340774537, AUC: 0.7991145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004302370190620422, AUC: 0.8391795000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031840784549713136, AUC: 0.844318\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0026250687837600707, AUC: 0.846704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019217836856842041, AUC: 0.8186145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02865324306488037, AUC: 0.5881215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036935971975326537, AUC: 0.8149775000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002425878882408142, AUC: 0.816405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022541437149047852, AUC: 0.8344265000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002055408775806427, AUC: 0.8397625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024357545375823975, AUC: 0.8479534999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01381754732131958, AUC: 0.39081350000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030883557796478273, AUC: 0.7823054999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031230605840682985, AUC: 0.7761524999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024366183280944823, AUC: 0.822926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001995400428771973, AUC: 0.8110945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030639694929122923, AUC: 0.8413615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01307798433303833, AUC: 0.6445015000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0035883730649948122, AUC: 0.778147\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003048780798912048, AUC: 0.7884659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027584158182144165, AUC: 0.80607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0025184576511383056, AUC: 0.809596\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model_aucs\u001b[38;5;241m.\u001b[39mappend(auc)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 18\u001b[0m     _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[1;32m     20\u001b[0m         _, auc \u001b[38;5;241m=\u001b[39m metric_utils\u001b[38;5;241m.\u001b[39mauc_sigmoid(test_loader_reduced, network)\n",
      "File \u001b[0;32m~/Downloads/ML/numbers mnist/train.py:20\u001b[0m, in \u001b[0;36mtrain_sigmoid\u001b[0;34m(epoch, train_loader, network, optimizer, directory, verbose, class_weights)\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m     19\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m     output \u001b[38;5;241m=\u001b[39m network(data)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Downloads/ML/numbers mnist/class_sampling.py:25\u001b[0m, in \u001b[0;36mReduce.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index): \n\u001b[0;32m---> 25\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnums[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     27\u001b[0m         label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS normal AUC saving  \n",
    "# df.to_csv()\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf85b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learning_rate_aucs.shape)\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "print(auc_mean.shape)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "print(auc_variance.shape)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"normal\", 2, nums, (1, 1), learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n",
    "\n",
    "print(rows)\n",
    "\n",
    "# pd.DataFrame(rows, columns = col_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd6b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SIGMOID 2 CLASS ratio\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(2, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"ratio\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "886952fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02157968044281006, AUC: 0.6867034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020572117805480957, AUC: 0.8238075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02619137954711914, AUC: 0.8130915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04026922607421875, AUC: 0.752547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027536532402038575, AUC: 0.7995220000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029943819046020507, AUC: 0.790417\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07544555282592773, AUC: 0.497509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07978406143188477, AUC: 0.5938809999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024683547973632813, AUC: 0.8177650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025677730560302734, AUC: 0.8069000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019481823921203612, AUC: 0.8099750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15527237701416016, AUC: 0.502493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06202663040161133, AUC: 0.4889945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01783221435546875, AUC: 0.8321440000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024161662101745605, AUC: 0.815463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026190677642822267, AUC: 0.8061104999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029901447296142577, AUC: 0.7997035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03159477138519287, AUC: 0.789463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025665547370910643, AUC: 0.39067900000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018697924613952636, AUC: 0.8366764999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01939465045928955, AUC: 0.8308875000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03777942657470703, AUC: 0.7624605000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024574057579040527, AUC: 0.8184305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02835252380371094, AUC: 0.80124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02892872142791748, AUC: 0.45862400000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014839864730834961, AUC: 0.8314069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026047286033630372, AUC: 0.8084825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028749720573425293, AUC: 0.7980625000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029259493827819824, AUC: 0.7941769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.032902906417846677, AUC: 0.7863735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01644024467468262, AUC: 0.587917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013634578704833984, AUC: 0.816617\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03314400100708008, AUC: 0.7770739999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029624836921691895, AUC: 0.78721\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02469535446166992, AUC: 0.8062315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03241754531860352, AUC: 0.7790865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03370501708984375, AUC: 0.4401570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017398488998413085, AUC: 0.8243755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026878009796142577, AUC: 0.7988310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017503741264343262, AUC: 0.6145225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02786328125, AUC: 0.7947354999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03188971519470215, AUC: 0.7802560000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01582411575317383, AUC: 0.5076475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02599990749359131, AUC: 0.8206235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02362984371185303, AUC: 0.8286044999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0209399995803833, AUC: 0.8273455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027757577896118164, AUC: 0.8039000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02833512210845947, AUC: 0.7988099999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023318387031555175, AUC: 0.5376645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013784738540649414, AUC: 0.8259365000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025893837928771972, AUC: 0.8087729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027919134140014647, AUC: 0.8008375000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038381309509277345, AUC: 0.7529079999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031638400077819824, AUC: 0.782297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05670656204223633, AUC: 0.4929965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019071245193481447, AUC: 0.822611\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01473063325881958, AUC: 0.8214305000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028449040412902832, AUC: 0.7999750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030598509788513185, AUC: 0.7868195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03148854351043701, AUC: 0.7870760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01993434143066406, AUC: 0.4495585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007204032659530639, AUC: 0.7692889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007194324016571045, AUC: 0.7622055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007401659965515137, AUC: 0.7565829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008101206541061402, AUC: 0.760645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010123478889465331, AUC: 0.7671485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04160093879699707, AUC: 0.6590889999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007038892507553101, AUC: 0.722614\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006997632265090942, AUC: 0.729902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008047364234924316, AUC: 0.737923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008194916486740112, AUC: 0.738978\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008335441112518311, AUC: 0.739757\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019925479888916017, AUC: 0.3601495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048744680881500245, AUC: 0.715619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006346189975738525, AUC: 0.748024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007020243883132935, AUC: 0.7570959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007398994922637939, AUC: 0.761617\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008439533233642578, AUC: 0.763304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0870197525024414, AUC: 0.4874965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006544911861419677, AUC: 0.742891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006256911516189575, AUC: 0.7425205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007481712818145752, AUC: 0.7590965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070980236530303956, AUC: 0.754417\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008783752918243409, AUC: 0.7657575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01355340576171875, AUC: 0.5695005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007898482084274292, AUC: 0.745055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005472979784011841, AUC: 0.744739\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006851338863372803, AUC: 0.755853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007844200611114502, AUC: 0.7616940000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007973899126052857, AUC: 0.7638495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.054784852981567385, AUC: 0.5822725000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006718125820159912, AUC: 0.739935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075343379974365235, AUC: 0.749395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007557567119598389, AUC: 0.7542165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076274175643920895, AUC: 0.7525869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007939435005187989, AUC: 0.752883\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037927940368652345, AUC: 0.4870960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005390148401260376, AUC: 0.7623820000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006487617254257202, AUC: 0.767162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00862623405456543, AUC: 0.7731585000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00785892939567566, AUC: 0.76512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009236201286315918, AUC: 0.7664245000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026381865501403808, AUC: 0.574986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005602195024490357, AUC: 0.678267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007446335792541504, AUC: 0.708533\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008934931755065918, AUC: 0.7221204999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008285297393798827, AUC: 0.7170655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008601171493530273, AUC: 0.7247485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028600391387939454, AUC: 0.5015890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007076167106628418, AUC: 0.7563165000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059969954490661625, AUC: 0.7480745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00765001916885376, AUC: 0.754456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008010348796844483, AUC: 0.7541990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00846003532409668, AUC: 0.752889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012969661712646484, AUC: 0.610886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006359605312347412, AUC: 0.7423335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007411887407302856, AUC: 0.7552285000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008989880084991455, AUC: 0.7648335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009389509201049804, AUC: 0.7707374999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008668808460235596, AUC: 0.770296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0162079496383667, AUC: 0.4449305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005753995180130005, AUC: 0.6909075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006727019786834717, AUC: 0.7211565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00740347409248352, AUC: 0.7365885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00668119215965271, AUC: 0.7333959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007157733917236328, AUC: 0.7387469999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045274477005004886, AUC: 0.633389\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005458020687103272, AUC: 0.7398745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005225775480270386, AUC: 0.733253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006173064708709717, AUC: 0.7396929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006216863632202149, AUC: 0.7379275\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007803581714630127, AUC: 0.7509425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02522551441192627, AUC: 0.687897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005271515130996704, AUC: 0.7197325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005499098300933838, AUC: 0.726059\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006402374267578125, AUC: 0.728049\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006547322034835815, AUC: 0.7265980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007059020757675171, AUC: 0.7297285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009229622840881347, AUC: 0.604512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005724687099456787, AUC: 0.690681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00515353512763977, AUC: 0.6875884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006271977186203003, AUC: 0.7067395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00663629937171936, AUC: 0.7148905000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007044186592102051, AUC: 0.7193314999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05417813491821289, AUC: 0.4504045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052720818519592285, AUC: 0.7127730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050723919868469235, AUC: 0.7112704999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006078349590301514, AUC: 0.725719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006219670057296753, AUC: 0.7280855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006499816179275513, AUC: 0.7328435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03072497272491455, AUC: 0.566026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005296936273574829, AUC: 0.7011745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005754709005355835, AUC: 0.717902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005902926206588745, AUC: 0.732993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005902008295059204, AUC: 0.738402\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006561286926269531, AUC: 0.7472245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031015604972839356, AUC: 0.5203485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005190430164337158, AUC: 0.7094990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059433414936065675, AUC: 0.7255875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00628291392326355, AUC: 0.7332985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007605926513671875, AUC: 0.7421309999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006972286462783813, AUC: 0.7384839999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023429944038391114, AUC: 0.36182650000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00589929485321045, AUC: 0.708175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006021058082580567, AUC: 0.7084\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006877594947814941, AUC: 0.7255995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0064341058731079105, AUC: 0.727054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006921231508255005, AUC: 0.733162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04299314689636231, AUC: 0.46662200000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0054551661014556885, AUC: 0.7342150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005887871265411377, AUC: 0.7374385000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006078028202056885, AUC: 0.7412320000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00592348837852478, AUC: 0.7387055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007408865690231323, AUC: 0.7483035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07160737991333008, AUC: 0.5528225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005362311601638794, AUC: 0.6656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006487279891967773, AUC: 0.6890995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006849389314651489, AUC: 0.698654\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006646604776382447, AUC: 0.70325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007454846382141113, AUC: 0.7113775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03915175628662109, AUC: 0.7049200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006456350326538086, AUC: 0.7256269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005569377422332764, AUC: 0.7309730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005319470167160034, AUC: 0.7397874999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005192838668823242, AUC: 0.743317\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005284496307373047, AUC: 0.7423035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04465376472473145, AUC: 0.46927350000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070303606986999514, AUC: 0.6676519999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006100249290466308, AUC: 0.698157\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00618621826171875, AUC: 0.718136\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006100293874740601, AUC: 0.7292785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006179602861404419, AUC: 0.7334915000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07071049118041992, AUC: 0.49350499999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066069686412811275, AUC: 0.6573235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005496017456054688, AUC: 0.7024925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005355669498443604, AUC: 0.7211565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005357623100280762, AUC: 0.722296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005317841768264771, AUC: 0.7218910000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011724015712738038, AUC: 0.5009494999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006746816396713257, AUC: 0.6555165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006551162242889404, AUC: 0.6870955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006248275756835938, AUC: 0.6948844999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006041650772094727, AUC: 0.7004525000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005888529062271118, AUC: 0.7046275000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01316322374343872, AUC: 0.5846735000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005511029720306397, AUC: 0.7489625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00525792121887207, AUC: 0.7551359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005246086359024048, AUC: 0.7578934999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005139570713043213, AUC: 0.755212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051955080032348635, AUC: 0.7520935000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017283541679382324, AUC: 0.45734250000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006143395185470581, AUC: 0.6673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005003010034561157, AUC: 0.7253555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0050454728603363036, AUC: 0.7394904999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004976492404937744, AUC: 0.7426355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005003942728042603, AUC: 0.7434575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012339428424835205, AUC: 0.630328\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007095186948776245, AUC: 0.664552\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00623014497756958, AUC: 0.677782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005793031454086304, AUC: 0.679737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005560998916625977, AUC: 0.6852925000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005575772047042847, AUC: 0.6924285000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012112011909484863, AUC: 0.5335245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005585522413253784, AUC: 0.686819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00509861946105957, AUC: 0.712406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004913978338241577, AUC: 0.7277549999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005007426738739013, AUC: 0.734458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005232869386672973, AUC: 0.7389285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017568720817565917, AUC: 0.38178500000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006132487058639526, AUC: 0.6462695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005599560737609863, AUC: 0.683597\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005481916427612305, AUC: 0.6947355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005533893823623657, AUC: 0.707707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005498219966888427, AUC: 0.710967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03492076110839844, AUC: 0.454148\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007058679819107056, AUC: 0.637808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006083515882492066, AUC: 0.698051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005803151845932007, AUC: 0.7160915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005721674919128418, AUC: 0.7151295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005997978687286377, AUC: 0.7173974999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05360672760009766, AUC: 0.464383\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014152910709381104, AUC: 0.3563535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012496975898742676, AUC: 0.38713949999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011218606948852539, AUC: 0.4198115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010284472465515136, AUC: 0.45265299999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00950212812423706, AUC: 0.47818800000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03256502914428711, AUC: 0.48172350000000014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010203298091888427, AUC: 0.5922970000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009250565052032471, AUC: 0.613336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008550222396850587, AUC: 0.630933\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007938631057739258, AUC: 0.647851\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007457002878189087, AUC: 0.662945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019160040855407713, AUC: 0.5944605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010317764282226562, AUC: 0.53847\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009182993412017823, AUC: 0.5542895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008448741912841796, AUC: 0.5664685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007980426788330079, AUC: 0.5821449999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007576358318328857, AUC: 0.592797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008539947986602783, AUC: 0.6333785000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007576767444610596, AUC: 0.6740944999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007204181432723999, AUC: 0.6819235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006930314302444458, AUC: 0.6889715\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0067416255474090575, AUC: 0.6962735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006592718601226807, AUC: 0.7002335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012907815456390382, AUC: 0.575434\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011563073635101319, AUC: 0.591401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0106242995262146, AUC: 0.6025739999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009890056610107422, AUC: 0.6133085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009341772079467774, AUC: 0.623823\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00890287971496582, AUC: 0.6340315000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026033576011657716, AUC: 0.422333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013315052986145019, AUC: 0.5064865000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01190878963470459, AUC: 0.5262104999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01089624547958374, AUC: 0.5509645000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00981254768371582, AUC: 0.568669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009073453903198242, AUC: 0.5884425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07091891860961914, AUC: 0.5562685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009477341651916504, AUC: 0.606248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00898822832107544, AUC: 0.6171115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008593398571014405, AUC: 0.623138\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00825862979888916, AUC: 0.6314095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007960164785385132, AUC: 0.636529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0831487159729004, AUC: 0.535583\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011179291248321533, AUC: 0.5523155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010384990215301513, AUC: 0.568425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00975725221633911, AUC: 0.5872284999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009222503185272218, AUC: 0.603444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008861841201782227, AUC: 0.6199650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06255937194824218, AUC: 0.5659230000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012548660278320313, AUC: 0.459463\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011135607719421388, AUC: 0.491163\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010098475933074951, AUC: 0.520459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009389609813690185, AUC: 0.544662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008840382099151611, AUC: 0.56376\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02067055606842041, AUC: 0.419526\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015534491062164306, AUC: 0.40869099999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013228944301605225, AUC: 0.43844099999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01163780403137207, AUC: 0.469762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010541852474212646, AUC: 0.49221349999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009737247467041016, AUC: 0.5127585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS oversampled\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(2, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_oversampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"oversampled\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae9dc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.015905908584594727, AUC: 0.437009\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.053795656204223635, AUC: 0.6535575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1587593765258789, AUC: 0.501994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01805019474029541, AUC: 0.6331034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1484091567993164, AUC: 0.5029924999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009051459789276123, AUC: 0.8229664999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02131798267364502, AUC: 0.591936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12902787017822265, AUC: 0.504987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13112792205810547, AUC: 0.507501\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01427377700805664, AUC: 0.693999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06267182540893555, AUC: 0.6296015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00982688331604004, AUC: 0.8241054999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014709303379058838, AUC: 0.45297750000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10771421813964843, AUC: 0.5169520000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12480251693725586, AUC: 0.5094899999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009759426593780518, AUC: 0.8117519999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0461632080078125, AUC: 0.7085905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022487581253051756, AUC: 0.8051774999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01924972915649414, AUC: 0.36129300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04422708511352539, AUC: 0.702714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11805906677246093, AUC: 0.5140009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020174236297607423, AUC: 0.8065279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008612649917602539, AUC: 0.8076574999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009191646099090576, AUC: 0.761574\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014307125568389893, AUC: 0.5140305000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015298494338989258, AUC: 0.5525415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023130674362182618, AUC: 0.7741509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029788542747497558, AUC: 0.7686869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15245992279052734, AUC: 0.504998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007963288068771363, AUC: 0.8054145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012669984817504882, AUC: 0.523349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029263435363769533, AUC: 0.7357279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01977951717376709, AUC: 0.7703869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11639044570922852, AUC: 0.5215059999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013650013923645019, AUC: 0.8079615000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02248130702972412, AUC: 0.8034619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03404822540283203, AUC: 0.5993275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010538324356079102, AUC: 0.7141735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029056017875671386, AUC: 0.7742855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022778802871704102, AUC: 0.7989750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1455408706665039, AUC: 0.508505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07524991607666015, AUC: 0.590275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016978429794311523, AUC: 0.604751\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08919465255737305, AUC: 0.5350715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009472489356994629, AUC: 0.7776785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13076905822753906, AUC: 0.512985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007431054592132568, AUC: 0.7939635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011519535541534424, AUC: 0.8195450000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03965247344970703, AUC: 0.6790369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033731246948242186, AUC: 0.7553884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12523973846435546, AUC: 0.510999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07109103393554687, AUC: 0.59875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12969153976440428, AUC: 0.5150115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007774809837341309, AUC: 0.780456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029166802406311036, AUC: 0.37398899999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018155370712280273, AUC: 0.5320575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007969343662261963, AUC: 0.74685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014006327152252198, AUC: 0.7915209999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009024486541748047, AUC: 0.7922045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03023654270172119, AUC: 0.775123\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01914181709289551, AUC: 0.514704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014618961811065674, AUC: 0.50813\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013918217658996581, AUC: 0.530224\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012595004558563232, AUC: 0.5456455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011778825283050538, AUC: 0.5688685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012396257877349853, AUC: 0.590548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05401417541503906, AUC: 0.471969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012449532508850098, AUC: 0.483642\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010071088790893554, AUC: 0.50256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010035435199737548, AUC: 0.5519425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010169595241546632, AUC: 0.57985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007682609796524048, AUC: 0.572977\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03855527687072754, AUC: 0.429198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020027913093566895, AUC: 0.37802249999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01572463512420654, AUC: 0.40258950000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013455118179321289, AUC: 0.44748649999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01104200792312622, AUC: 0.48458700000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010879563808441161, AUC: 0.542189\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03192385292053223, AUC: 0.4793575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011733138561248779, AUC: 0.5979585000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011687823295593262, AUC: 0.6165885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010791167736053467, AUC: 0.619422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010690369606018067, AUC: 0.631471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010253456592559815, AUC: 0.638121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022821941375732423, AUC: 0.4860675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016240822792053224, AUC: 0.4723715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012989057064056396, AUC: 0.47246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01147736930847168, AUC: 0.48123800000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013328434467315674, AUC: 0.5278395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010938319206237793, AUC: 0.529406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05581355857849121, AUC: 0.500008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010540269374847411, AUC: 0.6789995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010277366638183594, AUC: 0.681393\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008496018409729003, AUC: 0.670903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008199808120727538, AUC: 0.674284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008267477989196777, AUC: 0.6824584999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018783426284790038, AUC: 0.40228299999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012695842742919922, AUC: 0.48996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01180584716796875, AUC: 0.5390025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01080722427368164, AUC: 0.5756475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010157716751098634, AUC: 0.6045395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009114491939544677, AUC: 0.622953\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01772861671447754, AUC: 0.6179140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010412405967712403, AUC: 0.5948849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011174295902252197, AUC: 0.6268855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008499871253967286, AUC: 0.6182384999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008305439472198486, AUC: 0.6315145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011303849220275879, AUC: 0.6666515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028557591438293457, AUC: 0.4529895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014517169952392578, AUC: 0.5734475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01285807180404663, AUC: 0.5759865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011893203735351562, AUC: 0.5872895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011977774143218994, AUC: 0.598465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010422253608703613, AUC: 0.5948275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06470269393920898, AUC: 0.5635819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011814839363098144, AUC: 0.5747255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010835601806640624, AUC: 0.5935625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012350340366363526, AUC: 0.629559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009245434284210204, AUC: 0.6206455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009206931114196777, AUC: 0.6325304999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01618959712982178, AUC: 0.5965495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014330172061920166, AUC: 0.595266\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013609260082244874, AUC: 0.6036600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012578857421875, AUC: 0.6082505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01219424819946289, AUC: 0.6172759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011683306694030761, AUC: 0.6226750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022097429275512694, AUC: 0.36951399999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01990588665008545, AUC: 0.4322335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018797728538513185, AUC: 0.44835349999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01762927722930908, AUC: 0.4609150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01575849437713623, AUC: 0.46623149999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014617741107940674, AUC: 0.4805559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04699446678161621, AUC: 0.5586260000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018848861694335937, AUC: 0.454565\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.017284958839416505, AUC: 0.4734685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014687091827392577, AUC: 0.47818700000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014056768894195557, AUC: 0.5093544999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01316795301437378, AUC: 0.5372545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020566884994506835, AUC: 0.42508200000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014414824962615968, AUC: 0.4999595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012933335304260253, AUC: 0.5075405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011820468425750732, AUC: 0.5165455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011909185409545898, AUC: 0.5478265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01024878215789795, AUC: 0.5472199999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03545813369750977, AUC: 0.5858304999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015742668628692627, AUC: 0.510902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013860924243927002, AUC: 0.5114894999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013291391372680664, AUC: 0.5273589999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012884458541870118, AUC: 0.5423775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011252122402191162, AUC: 0.5428815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020801584243774415, AUC: 0.38946299999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014379768371582032, AUC: 0.464329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014312679290771485, AUC: 0.489246\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012338516235351562, AUC: 0.4888024999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012019060611724853, AUC: 0.5069575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011449435234069823, AUC: 0.5225500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07142297744750976, AUC: 0.485992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019862879753112794, AUC: 0.39558699999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018034494400024415, AUC: 0.40130699999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018485008239746095, AUC: 0.4282045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016314915657043457, AUC: 0.429024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016540637969970705, AUC: 0.4512375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06060859870910645, AUC: 0.594112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012159369945526122, AUC: 0.5587535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010545722484588623, AUC: 0.563134\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009706135749816894, AUC: 0.5715650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008843770027160644, AUC: 0.5726455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0086389799118042, AUC: 0.593639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022837069511413573, AUC: 0.5592355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012827011585235595, AUC: 0.5121445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012591752052307129, AUC: 0.5466765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01129591703414917, AUC: 0.5581579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010526697635650634, AUC: 0.5744765000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009848604679107666, AUC: 0.58946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04958654022216797, AUC: 0.46148799999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013705434799194336, AUC: 0.46605100000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013436857223510743, AUC: 0.4796625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012689392566680908, AUC: 0.4893465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011730112552642823, AUC: 0.49619349999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011636629581451416, AUC: 0.5132654999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09020543670654296, AUC: 0.517926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07681789398193359, AUC: 0.5339659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06295834732055663, AUC: 0.570866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050122716903686526, AUC: 0.6087685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037524917602539065, AUC: 0.642537\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0256679048538208, AUC: 0.634995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025908671379089355, AUC: 0.4630809999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010351833343505859, AUC: 0.524971\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01056408977508545, AUC: 0.5558585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010525833606719971, AUC: 0.5585715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01057222032546997, AUC: 0.5634365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010952091693878174, AUC: 0.5720895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041673633575439455, AUC: 0.59776\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029315386772155762, AUC: 0.5670725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02146409511566162, AUC: 0.5296379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018260560989379882, AUC: 0.511401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01682420063018799, AUC: 0.5031915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0165357027053833, AUC: 0.505108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016884451866149904, AUC: 0.44731200000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010040956020355225, AUC: 0.5276915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010365745544433595, AUC: 0.5371130000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010264771461486816, AUC: 0.538347\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010283681869506836, AUC: 0.5410825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010189440727233887, AUC: 0.5418734999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01920564365386963, AUC: 0.4595635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011591114044189454, AUC: 0.5403749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011832335948944091, AUC: 0.5580415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011963104724884033, AUC: 0.567016\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011880742549896241, AUC: 0.5709280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01184085988998413, AUC: 0.5756575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018234063148498535, AUC: 0.5381429999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009513277053833008, AUC: 0.6288495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009304122447967529, AUC: 0.643362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00970654296875, AUC: 0.6596209999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009289958953857421, AUC: 0.6555285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009241360187530518, AUC: 0.657946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01655087947845459, AUC: 0.47561600000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017019051551818848, AUC: 0.4977485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016970823287963867, AUC: 0.5027615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0171344633102417, AUC: 0.5105845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017002546310424804, AUC: 0.5146285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0168932466506958, AUC: 0.51794\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0317716064453125, AUC: 0.446217\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013154318809509277, AUC: 0.504876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01288154411315918, AUC: 0.5412905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013079341888427734, AUC: 0.5507305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013069800853729248, AUC: 0.5556625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012766430377960205, AUC: 0.5564195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018936123847961426, AUC: 0.3788715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01770387077331543, AUC: 0.42184850000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018455702781677245, AUC: 0.44024949999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01858794593811035, AUC: 0.44778000000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017824517250061036, AUC: 0.446164\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017749204635620117, AUC: 0.45216999999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037330652236938475, AUC: 0.48279550000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00898223066329956, AUC: 0.5896455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008290510654449463, AUC: 0.6380460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008652337074279785, AUC: 0.64584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008623576164245606, AUC: 0.6471555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008587841033935548, AUC: 0.6485259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03551677894592285, AUC: 0.44124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03185014915466309, AUC: 0.4291465000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02811328125, AUC: 0.421304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024767127990722657, AUC: 0.41396349999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021711002349853514, AUC: 0.4121995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01900738525390625, AUC: 0.4230665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013831187725067138, AUC: 0.4876285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013801758289337157, AUC: 0.4909565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013797249794006348, AUC: 0.495756\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01380235767364502, AUC: 0.49798599999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013817180156707763, AUC: 0.5004385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013843274593353272, AUC: 0.5031684999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026758121490478515, AUC: 0.59536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025710365295410157, AUC: 0.5907415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024739437103271485, AUC: 0.5870405000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02372247886657715, AUC: 0.583202\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02277411937713623, AUC: 0.5792765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021870746612548828, AUC: 0.5752355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05620915412902832, AUC: 0.625766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05487890243530273, AUC: 0.6287670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.053597681045532225, AUC: 0.6368259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05232225799560547, AUC: 0.642388\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05108534622192383, AUC: 0.6434365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04984508514404297, AUC: 0.6456355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020355981826782228, AUC: 0.483362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017733615875244142, AUC: 0.49319900000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015484703540802001, AUC: 0.5123605\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.013757198810577393, AUC: 0.5223409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012491308689117431, AUC: 0.5308965000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01164536714553833, AUC: 0.541986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05268109703063965, AUC: 0.6191185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05134394073486328, AUC: 0.626167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0499963436126709, AUC: 0.633591\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04874342918395996, AUC: 0.640828\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0474197940826416, AUC: 0.644409\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04612111663818359, AUC: 0.650694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03865525436401367, AUC: 0.480105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03443008232116699, AUC: 0.47356050000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030458396911621093, AUC: 0.47061650000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026622346878051758, AUC: 0.4623749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023026430130004882, AUC: 0.46787850000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01974360656738281, AUC: 0.4644125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025465276718139647, AUC: 0.37267249999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02252425479888916, AUC: 0.3630045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02003372097015381, AUC: 0.35652649999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017903664588928222, AUC: 0.3544284999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016330544471740722, AUC: 0.35972350000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015053500175476074, AUC: 0.3661225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028054658889770507, AUC: 0.438689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02459756851196289, AUC: 0.43419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02140919780731201, AUC: 0.42270599999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018725915908813475, AUC: 0.418733\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016542980194091797, AUC: 0.4126935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01495895528793335, AUC: 0.4224245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010441665172576903, AUC: 0.5421940000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010515846252441407, AUC: 0.544065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01061657428741455, AUC: 0.546752\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010681099414825439, AUC: 0.548027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010733800888061524, AUC: 0.549112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010793748855590821, AUC: 0.550527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS undersampled\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(2, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_undersampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"undersampled\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48eb1e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.05337999534606934, AUC: 0.49600249999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008310622453689576, AUC: 0.8229409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022032556533813478, AUC: 0.8314815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020795438766479494, AUC: 0.8312719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023313258171081545, AUC: 0.816831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02472116184234619, AUC: 0.815073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03646420097351074, AUC: 0.470191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01589971446990967, AUC: 0.836288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025143569946289062, AUC: 0.8164925000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02244034481048584, AUC: 0.8232850000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02390873432159424, AUC: 0.8161570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026851189613342284, AUC: 0.810004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034110681533813476, AUC: 0.4865600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014527852058410645, AUC: 0.847634\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018952420234680176, AUC: 0.8347775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02224026870727539, AUC: 0.8251065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02541550922393799, AUC: 0.813118\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02396948528289795, AUC: 0.817657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04869622039794922, AUC: 0.46657550000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011211713790893555, AUC: 0.823882\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02186649799346924, AUC: 0.8216720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021905203819274903, AUC: 0.8219960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02907278347015381, AUC: 0.7952645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027104207038879394, AUC: 0.8017305000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045407302856445314, AUC: 0.6844590000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017766657829284667, AUC: 0.8399755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020855578422546386, AUC: 0.825917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027371079444885253, AUC: 0.8129435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025271970748901366, AUC: 0.8077084999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028096034049987794, AUC: 0.8015804999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10770918273925781, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019810518264770507, AUC: 0.8356079999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020333189964294434, AUC: 0.836548\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019909469604492188, AUC: 0.831915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016892193794250488, AUC: 0.8202475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023851142883300782, AUC: 0.81864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029925457000732424, AUC: 0.6897485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010314714431762696, AUC: 0.8371465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04701984977722168, AUC: 0.718591\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02683828639984131, AUC: 0.815663\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01140342378616333, AUC: 0.8184069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027754305839538574, AUC: 0.8086120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01624446964263916, AUC: 0.43986899999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01134183931350708, AUC: 0.716143\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020706384658813477, AUC: 0.8274805000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02488365364074707, AUC: 0.818329\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02721707057952881, AUC: 0.8064535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022462801933288576, AUC: 0.8163879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017911408424377443, AUC: 0.46994900000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01286607837677002, AUC: 0.831258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02091547679901123, AUC: 0.8250230000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02265408706665039, AUC: 0.819027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02958592128753662, AUC: 0.7962355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015075889110565186, AUC: 0.802225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014935132026672363, AUC: 0.4487885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02143026542663574, AUC: 0.826297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013237558841705322, AUC: 0.8377034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02224949550628662, AUC: 0.8204060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02309818935394287, AUC: 0.81798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02061091995239258, AUC: 0.8187120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02929398822784424, AUC: 0.4295725000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005689704418182373, AUC: 0.7287505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055538413524627685, AUC: 0.7298255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047078711986541745, AUC: 0.719516\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007149281740188598, AUC: 0.7409955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007112576723098755, AUC: 0.742225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017444239616394044, AUC: 0.4181975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00606496262550354, AUC: 0.7322234999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058536243438720706, AUC: 0.7436604999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004883285522460938, AUC: 0.740165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059304296970367435, AUC: 0.7519545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007043286561965943, AUC: 0.760467\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016207193374633787, AUC: 0.601288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005971125841140747, AUC: 0.7336345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00594150185585022, AUC: 0.7332425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00619521689414978, AUC: 0.739754\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006426405668258667, AUC: 0.7395394999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007106548070907593, AUC: 0.7415465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021463964462280275, AUC: 0.37199600000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005245116233825684, AUC: 0.6912910000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0071033620834350586, AUC: 0.7312445000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070620720386505124, AUC: 0.7342835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007058339834213257, AUC: 0.7327385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00780880331993103, AUC: 0.739607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026223966598510742, AUC: 0.6348119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004528656721115112, AUC: 0.7302765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004557187080383301, AUC: 0.7432219999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005892546653747559, AUC: 0.7572255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005636573314666748, AUC: 0.760749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0059029836654663085, AUC: 0.7621545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012805318355560303, AUC: 0.620904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005551677703857422, AUC: 0.725355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006333193302154541, AUC: 0.7472894999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006841071128845215, AUC: 0.7521335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006882416248321533, AUC: 0.7507110000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00785590648651123, AUC: 0.754152\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018355891227722167, AUC: 0.5170635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048424069881439205, AUC: 0.721692\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004649573802947998, AUC: 0.7154499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0061684994697570805, AUC: 0.7316039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0072227623462677, AUC: 0.7407490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006604081392288208, AUC: 0.738378\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07858432388305664, AUC: 0.523949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005592524290084839, AUC: 0.7113935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006013874292373657, AUC: 0.7357610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005673536777496338, AUC: 0.7410835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006373127222061157, AUC: 0.7536919999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006919132709503174, AUC: 0.7593995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02466383361816406, AUC: 0.6521495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005999918222427368, AUC: 0.6885924999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00599662184715271, AUC: 0.6977125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006804267406463623, AUC: 0.7170015000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006970141887664795, AUC: 0.722394\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007843874216079712, AUC: 0.7285579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03907412147521973, AUC: 0.500096\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005949079990386963, AUC: 0.716262\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006798956155776977, AUC: 0.7328605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006023383140563965, AUC: 0.7280325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006624180555343628, AUC: 0.7358275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007023089170455933, AUC: 0.7384445000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02072107124328613, AUC: 0.569656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0054963650703430175, AUC: 0.732135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057322075366973875, AUC: 0.7445815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005767701387405395, AUC: 0.737638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005565931320190429, AUC: 0.7310559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0060776426792144775, AUC: 0.740486\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026445794105529784, AUC: 0.419355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005125851154327393, AUC: 0.6810385000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0054242899417877195, AUC: 0.7039785000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058410043716430665, AUC: 0.7104159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066481072902679446, AUC: 0.715804\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0060977694988250735, AUC: 0.713497\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015269526958465576, AUC: 0.450575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005683955192565918, AUC: 0.6775589999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005292999029159546, AUC: 0.700404\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053687052726745605, AUC: 0.709642\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005569222450256347, AUC: 0.7146595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005684868335723877, AUC: 0.717832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051963306427001955, AUC: 0.4924895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005880682468414306, AUC: 0.6820695000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006101168394088745, AUC: 0.702693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006057300567626953, AUC: 0.709321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006103636503219605, AUC: 0.716093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005981874704360962, AUC: 0.7195864999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03933146286010742, AUC: 0.46998100000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0061132292747497555, AUC: 0.666534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006323894739151001, AUC: 0.6790095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00644889497756958, AUC: 0.6905540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006482554912567139, AUC: 0.6995535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006409404516220093, AUC: 0.7000915000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014718925476074219, AUC: 0.435355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005599549293518066, AUC: 0.7073665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005785110712051391, AUC: 0.714635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006320733547210694, AUC: 0.7243275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006792780160903931, AUC: 0.7278855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070649199485778805, AUC: 0.7338749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0559282398223877, AUC: 0.49600400000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00544759750366211, AUC: 0.706955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0049178521633148195, AUC: 0.7293675000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004905719518661499, AUC: 0.7338290000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00519354510307312, AUC: 0.7415225000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005553271532058716, AUC: 0.744993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038448514938354494, AUC: 0.6820760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005061862468719483, AUC: 0.7490685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004962852001190185, AUC: 0.75316\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004913546800613403, AUC: 0.755322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051495440006256105, AUC: 0.7611414999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005241083860397339, AUC: 0.7651049999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0373864860534668, AUC: 0.561082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006410305500030518, AUC: 0.6887064999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006920888900756836, AUC: 0.702577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00726292896270752, AUC: 0.7137429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068596026897430416, AUC: 0.7175185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068980176448822025, AUC: 0.7240495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016216830253601076, AUC: 0.4559695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005656766176223755, AUC: 0.7172624999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005636085748672485, AUC: 0.7313745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051012208461761474, AUC: 0.7278895000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005751341342926025, AUC: 0.7360025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005869579553604126, AUC: 0.7381800000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04993067741394043, AUC: 0.46438350000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0075037553310394285, AUC: 0.5952455000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006273175239562988, AUC: 0.6500090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005702116012573242, AUC: 0.6816735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005425362348556518, AUC: 0.6970384999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005340474605560303, AUC: 0.7084555000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07143661499023438, AUC: 0.494495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00998366928100586, AUC: 0.574808\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008469681739807128, AUC: 0.6153915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074726386070251465, AUC: 0.629886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006981770038604737, AUC: 0.646732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006366737127304077, AUC: 0.653195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05843734359741211, AUC: 0.588075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006201417446136475, AUC: 0.6557765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005713151693344116, AUC: 0.6802885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005434356451034546, AUC: 0.69328\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052620058059692386, AUC: 0.7048535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005200499057769775, AUC: 0.7082824999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013334235191345216, AUC: 0.506391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00716947054862976, AUC: 0.643105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006216244220733642, AUC: 0.6852955000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005871500015258789, AUC: 0.7068065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005775955677032471, AUC: 0.7198709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005692249298095703, AUC: 0.726947\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02704063034057617, AUC: 0.5629204999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008321754455566406, AUC: 0.5586945000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007066127061843872, AUC: 0.609077\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006693380117416382, AUC: 0.6410125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066213467121124265, AUC: 0.6580785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00643619179725647, AUC: 0.6656754999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026804728507995604, AUC: 0.659459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007249543905258179, AUC: 0.6353825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006240317821502686, AUC: 0.6738299999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005789464235305786, AUC: 0.690515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005514679908752441, AUC: 0.7043079999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005419859647750855, AUC: 0.7148559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.062489398956298826, AUC: 0.49851800000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008038825988769531, AUC: 0.5875315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006759064435958862, AUC: 0.6459565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006159598588943481, AUC: 0.676866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005756318807601929, AUC: 0.6917135000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005514349937438965, AUC: 0.7005389999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.039063741683959964, AUC: 0.6303769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0077323029041290285, AUC: 0.607127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006882725954055786, AUC: 0.6608999999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006732069730758667, AUC: 0.682686\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006625088453292846, AUC: 0.6925535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065056953430175785, AUC: 0.7044490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031607476234436035, AUC: 0.4931875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006758122444152832, AUC: 0.693439\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006091978788375855, AUC: 0.7113405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057047328948974605, AUC: 0.7289844999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0053365519046783445, AUC: 0.7369385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005202737331390381, AUC: 0.744687\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01950564956665039, AUC: 0.282902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010355851650238036, AUC: 0.4607375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008211937427520752, AUC: 0.5467635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00725754976272583, AUC: 0.5942235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006903096675872803, AUC: 0.6277995000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006647613525390625, AUC: 0.6450130000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07373953628540039, AUC: 0.4969945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010638680934906006, AUC: 0.5366089999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009917736053466797, AUC: 0.5520575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009402429580688477, AUC: 0.5597949999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008907330513000489, AUC: 0.570713\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008479730129241943, AUC: 0.5798695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024087662696838378, AUC: 0.703213\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00928443193435669, AUC: 0.6462105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008934814453125, AUC: 0.6456655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008678411960601807, AUC: 0.647402\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008530542373657227, AUC: 0.6533100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008321101665496827, AUC: 0.653998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026890033721923827, AUC: 0.4316545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011778818607330323, AUC: 0.47870599999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011184245586395263, AUC: 0.491846\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010736716747283935, AUC: 0.500958\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010353522300720215, AUC: 0.5096849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010020199775695801, AUC: 0.52017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01407158660888672, AUC: 0.569909\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013186783790588378, AUC: 0.5818540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012231193542480468, AUC: 0.5843905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011358974456787109, AUC: 0.5857165\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.010636056423187256, AUC: 0.589032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00998073148727417, AUC: 0.5914725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04502298355102539, AUC: 0.6186195000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013403358459472657, AUC: 0.48017699999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0122496657371521, AUC: 0.491198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011295950889587403, AUC: 0.50719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010495823383331299, AUC: 0.5189485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009846956253051757, AUC: 0.5313245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0540279655456543, AUC: 0.49598099999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011802628517150878, AUC: 0.4863555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010868781566619874, AUC: 0.5042105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010142717838287353, AUC: 0.5194075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009516834735870361, AUC: 0.533965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008957656383514404, AUC: 0.54678\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044719474792480465, AUC: 0.49898899999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009033169269561768, AUC: 0.614405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008681437969207763, AUC: 0.6219665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008311189651489258, AUC: 0.62639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007996260643005371, AUC: 0.632333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007705244541168213, AUC: 0.6364920000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10558390808105468, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009016942977905274, AUC: 0.6040300000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008407763957977295, AUC: 0.625113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00811585283279419, AUC: 0.63204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00787772536277771, AUC: 0.6386624999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007692070960998535, AUC: 0.6429104999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024944669723510744, AUC: 0.31417849999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017205278396606447, AUC: 0.349482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01605662441253662, AUC: 0.35492199999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015089130878448487, AUC: 0.363584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014206204414367676, AUC: 0.371141\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01348450231552124, AUC: 0.3811405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04292696189880371, AUC: 0.48380049999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011461918830871581, AUC: 0.5361275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010809150695800782, AUC: 0.5506805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010223649024963378, AUC: 0.5584885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009736180305480957, AUC: 0.570546\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009324260234832763, AUC: 0.582166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS over+undersampled\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(2, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_sampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"both sampled\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ded04a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02157968044281006, AUC: 0.6867034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08839923477172852, AUC: 0.698482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05532261276245117, AUC: 0.771594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09743415069580078, AUC: 0.7073455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11138107681274415, AUC: 0.688415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13640005111694337, AUC: 0.6599929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023658716201782226, AUC: 0.398378\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052448091506958006, AUC: 0.7732169999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09756592178344727, AUC: 0.7000415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1643876495361328, AUC: 0.626525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07234828948974609, AUC: 0.7532825000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1506313934326172, AUC: 0.6473849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04466411209106445, AUC: 0.5848144999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04493079566955566, AUC: 0.790555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050890846252441405, AUC: 0.7878215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09636771774291993, AUC: 0.7050115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1612254180908203, AUC: 0.577601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06544087219238282, AUC: 0.766041\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04384331321716309, AUC: 0.4436590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11038293838500976, AUC: 0.670772\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12887449645996094, AUC: 0.6135715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09475616455078124, AUC: 0.7039505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.158717529296875, AUC: 0.642831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09753376388549805, AUC: 0.7136825000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04979433250427246, AUC: 0.46103200000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0980591926574707, AUC: 0.6833490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0794267578125, AUC: 0.7333749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15823641204833985, AUC: 0.5679804999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08469314193725586, AUC: 0.7309325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12557212829589845, AUC: 0.668317\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011570464134216309, AUC: 0.651253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06621040344238281, AUC: 0.7493879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11741202926635742, AUC: 0.6739245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11351173782348632, AUC: 0.676276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14357730865478516, AUC: 0.6618974999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11922500610351562, AUC: 0.684242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03422253608703613, AUC: 0.6372905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07083571624755859, AUC: 0.7435020000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07244134521484374, AUC: 0.743447\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09049646377563476, AUC: 0.7197285000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.060721210479736325, AUC: 0.7649495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0822372932434082, AUC: 0.7476029999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04881747627258301, AUC: 0.4903955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.056398857116699216, AUC: 0.7646465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07658190155029297, AUC: 0.7344879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08769236755371093, AUC: 0.724584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1180020523071289, AUC: 0.6889195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11112405014038086, AUC: 0.700199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02902210330963135, AUC: 0.636784\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.098030517578125, AUC: 0.6778249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12719892120361329, AUC: 0.651942\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08356612777709961, AUC: 0.7233410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11593923568725586, AUC: 0.6781710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08526019287109375, AUC: 0.7356739999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0384180850982666, AUC: 0.49347649999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.4750877227783203, AUC: 0.5005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04882532119750976, AUC: 0.7820625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05811293029785156, AUC: 0.771635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1517682647705078, AUC: 0.6454430000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.17808724212646485, AUC: 0.6238045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019174320220947266, AUC: 0.4311704999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010546699047088623, AUC: 0.8381664999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007555591583251953, AUC: 0.7731889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013263277530670166, AUC: 0.8410085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012488607883453368, AUC: 0.8312655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014552930831909179, AUC: 0.8279179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01882424736022949, AUC: 0.6324909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009511597633361816, AUC: 0.816876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00807780122756958, AUC: 0.7446335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01559631061553955, AUC: 0.827025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010454961776733399, AUC: 0.823521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008205495357513427, AUC: 0.8158055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017050434112548828, AUC: 0.49219050000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015216345310211182, AUC: 0.815562\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010343952655792236, AUC: 0.8110345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006673668384552002, AUC: 0.801571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013372177600860596, AUC: 0.8194325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014423328399658203, AUC: 0.819747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025902076721191405, AUC: 0.6785265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007671199798583985, AUC: 0.831451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007000543117523193, AUC: 0.8222575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012307519435882569, AUC: 0.836022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013739291191101075, AUC: 0.8326585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01091397476196289, AUC: 0.8301525000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013246777534484864, AUC: 0.5174624999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010291318893432617, AUC: 0.8177195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013617868423461915, AUC: 0.8309925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015598464965820312, AUC: 0.8244745000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01669950294494629, AUC: 0.827272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008151468753814697, AUC: 0.8021444999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013060497283935548, AUC: 0.651512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02003101444244385, AUC: 0.5981799999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011684247970581055, AUC: 0.8110824999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010305722236633301, AUC: 0.804079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011599114894866943, AUC: 0.8137025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017143693923950196, AUC: 0.808691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07371361541748046, AUC: 0.4995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01246802806854248, AUC: 0.8216114999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01408237886428833, AUC: 0.819368\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008389312744140625, AUC: 0.8078485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014019711017608643, AUC: 0.825343\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014791861057281494, AUC: 0.8267034999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024945231437683107, AUC: 0.4672625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007745407581329346, AUC: 0.8260045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010520395278930663, AUC: 0.8328705000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006850440740585327, AUC: 0.8253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009818801879882813, AUC: 0.8277334999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01480823040008545, AUC: 0.8302845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02865324306488037, AUC: 0.5881215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007297211408615113, AUC: 0.8193175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012670190334320068, AUC: 0.8426815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01272748613357544, AUC: 0.8410875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007251353740692139, AUC: 0.8208405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013654342651367187, AUC: 0.8326484999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01381754732131958, AUC: 0.39081350000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005951570749282837, AUC: 0.8077375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008329186916351318, AUC: 0.8192719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014477829933166503, AUC: 0.8291525000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013573427200317383, AUC: 0.8209275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010389121055603027, AUC: 0.8159185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01307798433303833, AUC: 0.6445015000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006123400449752807, AUC: 0.7918575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005186422348022461, AUC: 0.7908765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007715855360031128, AUC: 0.8057185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052066490650177, AUC: 0.7622955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009603912830352784, AUC: 0.809983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03605061531066894, AUC: 0.5307915000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00617436170578003, AUC: 0.7300610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005770718812942505, AUC: 0.7302765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0074440155029296875, AUC: 0.755719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008938265323638917, AUC: 0.760594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008294040441513061, AUC: 0.7615375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07314897918701171, AUC: 0.499006\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00561512041091919, AUC: 0.736377\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006349770069122315, AUC: 0.775451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007801422119140625, AUC: 0.7887299999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01001564073562622, AUC: 0.7935670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006772331953048706, AUC: 0.7783950000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02219521713256836, AUC: 0.616943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00567103910446167, AUC: 0.7970124999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004923522472381592, AUC: 0.787687\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009285329818725586, AUC: 0.8153110000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008109431505203248, AUC: 0.8174030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009222801208496095, AUC: 0.8184280000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024299232482910157, AUC: 0.6556175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006862485885620117, AUC: 0.7896795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006230347871780396, AUC: 0.7827719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008897309780120849, AUC: 0.8061459999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009166713237762452, AUC: 0.8068195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009326404571533203, AUC: 0.809284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019841660499572755, AUC: 0.461005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008004547834396362, AUC: 0.7726975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006851936101913452, AUC: 0.7738875000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007051745176315308, AUC: 0.784028\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007714756727218628, AUC: 0.7911885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010595582962036132, AUC: 0.8059019999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016441554069519044, AUC: 0.41137499999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006315555810928345, AUC: 0.7955245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048641347885131836, AUC: 0.7727285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007500527620315551, AUC: 0.8079624999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010323135852813721, AUC: 0.8080685000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009103180408477783, AUC: 0.8073629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03080391025543213, AUC: 0.4539889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0066866455078125, AUC: 0.802357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01040900993347168, AUC: 0.8162905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008137972116470337, AUC: 0.8094\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008508358478546143, AUC: 0.8133220000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008354036808013917, AUC: 0.8080004999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019459853172302245, AUC: 0.401874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00969520378112793, AUC: 0.6417375000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007743050575256347, AUC: 0.796538\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008456768751144409, AUC: 0.7991995000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006232941627502441, AUC: 0.7947015000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008077199935913087, AUC: 0.8030710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015312075138092041, AUC: 0.6002565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0058245410919189455, AUC: 0.7447604999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006375702857971191, AUC: 0.771938\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010736172199249267, AUC: 0.790826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005499963283538818, AUC: 0.7631795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010111536502838135, AUC: 0.798168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04828184509277344, AUC: 0.486481\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007046663999557495, AUC: 0.70153\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006295820474624634, AUC: 0.7226465000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006003504514694214, AUC: 0.7253129999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006478522300720215, AUC: 0.7379524999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006643293380737304, AUC: 0.7441065000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.062263944625854495, AUC: 0.49799550000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005597777366638183, AUC: 0.6906775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005853367328643799, AUC: 0.7377499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005986363410949707, AUC: 0.6841729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004978148221969604, AUC: 0.7209534999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005839346408843994, AUC: 0.751231\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035586790084838865, AUC: 0.647975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006827529907226563, AUC: 0.6776825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005556782722473144, AUC: 0.7129885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005084310054779053, AUC: 0.732674\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004853848695755005, AUC: 0.7429725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004909822702407837, AUC: 0.7558484999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028565075874328612, AUC: 0.43635849999999987\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006967652559280396, AUC: 0.6710849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006086209774017334, AUC: 0.7159324999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005777947187423706, AUC: 0.7285590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0071173739433288575, AUC: 0.7494639999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006050959587097168, AUC: 0.741804\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04257582855224609, AUC: 0.46773650000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006778290271759033, AUC: 0.6569655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005827343940734863, AUC: 0.72445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005291679859161377, AUC: 0.7339850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005469103336334228, AUC: 0.752523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005290682077407837, AUC: 0.7561215\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.061005592346191406, AUC: 0.49299049999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007548582315444946, AUC: 0.7157344999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005995778560638427, AUC: 0.716199\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055477356910705565, AUC: 0.719296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005665763854980469, AUC: 0.7302044999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005651756525039673, AUC: 0.7316335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0277275333404541, AUC: 0.44274450000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005927171230316162, AUC: 0.7237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005879244089126587, AUC: 0.7611340000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004865958452224732, AUC: 0.745673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048186776638031005, AUC: 0.7534395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005568744421005249, AUC: 0.7699825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07662530899047852, AUC: 0.539671\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006969614505767822, AUC: 0.6960759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005233192443847656, AUC: 0.726478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052268245220184325, AUC: 0.744528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005435244560241699, AUC: 0.7569764999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005161712408065796, AUC: 0.7591635000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04312462997436523, AUC: 0.6561009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005250229597091675, AUC: 0.7221935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004638153791427613, AUC: 0.724518\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004828550577163696, AUC: 0.7510465000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004535033941268921, AUC: 0.7519355000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004541507720947266, AUC: 0.756956\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040207550048828124, AUC: 0.4491095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006972499132156372, AUC: 0.619707\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008172675371170043, AUC: 0.6979864999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007059107780456543, AUC: 0.710078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006814057111740112, AUC: 0.719878\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006181773900985718, AUC: 0.7194405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08669427871704101, AUC: 0.49800400000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012762170314788818, AUC: 0.5156365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01163519287109375, AUC: 0.5199769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010810114860534669, AUC: 0.5266885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010181878566741943, AUC: 0.541951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00974288272857666, AUC: 0.5511495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049582605361938474, AUC: 0.5020074999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068200242519378665, AUC: 0.6823715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00625031065940857, AUC: 0.7004635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005853131532669067, AUC: 0.7144714999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005592248916625977, AUC: 0.719932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00539269471168518, AUC: 0.7249765\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05526366996765137, AUC: 0.6254205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01035127878189087, AUC: 0.5825819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009578083515167236, AUC: 0.596419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008896479606628418, AUC: 0.611114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008358670234680175, AUC: 0.6273065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007941794872283936, AUC: 0.6431175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051190927505493165, AUC: 0.5851744999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012034539699554442, AUC: 0.416565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010655524253845215, AUC: 0.444468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00979693031311035, AUC: 0.475574\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.009174903392791749, AUC: 0.4983055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008649335861206055, AUC: 0.5161884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03852338981628418, AUC: 0.5131654999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008823648929595947, AUC: 0.7267680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008030216932296753, AUC: 0.7369275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007270618200302124, AUC: 0.7439725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006689181804656982, AUC: 0.7518289999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0061951904296875, AUC: 0.7552835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06580369186401368, AUC: 0.5360860000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011504874706268311, AUC: 0.40957849999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010178947925567627, AUC: 0.44301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009091023921966552, AUC: 0.476949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008313036441802979, AUC: 0.5113445000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007778212547302246, AUC: 0.534639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034681669235229494, AUC: 0.4495929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011998960971832276, AUC: 0.470208\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010920190811157226, AUC: 0.49627449999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009937760829925537, AUC: 0.5193350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00898745632171631, AUC: 0.5365695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00826041841506958, AUC: 0.5563735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01720845317840576, AUC: 0.39403199999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009213735580444336, AUC: 0.491528\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008221039056777953, AUC: 0.5250239999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007522909641265869, AUC: 0.5532205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007025018453598022, AUC: 0.5788415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00662710452079773, AUC: 0.5977385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05087214469909668, AUC: 0.4924375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010984900951385499, AUC: 0.5575095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010053628444671631, AUC: 0.585683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009479619026184083, AUC: 0.5999610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008996250152587891, AUC: 0.6105814999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008620713710784912, AUC: 0.618219\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015332425117492676, AUC: 0.5502675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012291146278381347, AUC: 0.528696\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01160543155670166, AUC: 0.545337\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011019601821899414, AUC: 0.5578255000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010595107555389404, AUC: 0.5767595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010144785404205322, AUC: 0.585292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SIGMOID 2 CLASS weighted \n",
    "\n",
    "momentum=0\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SigmoidLogisticRegression(2, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, network, optimizer, verbose=False, class_weights=weight)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"weighted\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0757ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES_REDUCED = 3\n",
    "nums = (0, 3, 1)\n",
    "ratio = (200, 20, 1)\n",
    "\n",
    "\n",
    "reduced_train_CIFAR10 = class_sampling.Reduce(train_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "reduced_test_CIFAR10 = class_sampling.Reduce(test_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True)\n",
    "\n",
    "ratio_train_CIFAR10 = class_sampling.Ratio(train_CIFAR10, NUM_CLASSES_REDUCED, ratio, nums=nums)\n",
    "targets = ratio_train_CIFAR10.labels \n",
    "class_count = np.unique(targets, return_counts=True)[1]\n",
    "\n",
    "weight = 1. / class_count\n",
    "samples_weight = weight[targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "oversampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(max(class_count) * NUM_CLASSES_REDUCED), replacement=True)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "undersampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * NUM_CLASSES_REDUCED), replacement=False)\n",
    "\n",
    "weight *= max(class_count)\n",
    "\n",
    "\n",
    "train_loader_reduced = DataLoader(reduced_train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_ratio = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True) \n",
    "\n",
    "train_loader_oversampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=oversampler)\n",
    "\n",
    "train_loader_undersampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler)\n",
    "\n",
    "train_loader_sampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=sampler)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_CIFAR10, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8056e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Softmax 3 class normal\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_reduced, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"normal\", 3, nums, (1, 1), learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax 3 class ratio\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_ratio, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"ratio\", 3, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "092d0715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02759136454264323, AUC: 0.45233975000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03174774042765299, AUC: 0.71556\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024263559341430666, AUC: 0.6862747499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13270845031738282, AUC: 0.6056192499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.053983177185058594, AUC: 0.6308360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05420574061075847, AUC: 0.63994625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0633147481282552, AUC: 0.49774975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0627286376953125, AUC: 0.6289874999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026620399475097655, AUC: 0.65993375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07573316446940104, AUC: 0.60570375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025286399205525716, AUC: 0.7284740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02852927335103353, AUC: 0.7332429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016128000259399415, AUC: 0.47398900000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05959883499145508, AUC: 0.685323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05680835723876953, AUC: 0.499127\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05567755889892578, AUC: 0.6586679999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0343619130452474, AUC: 0.61048275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04748976389567057, AUC: 0.658555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034061147054036456, AUC: 0.47371775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04944189961751302, AUC: 0.6486984999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023873954772949218, AUC: 0.6763545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042909730275472006, AUC: 0.6808305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026869746526082358, AUC: 0.740376\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04629450225830078, AUC: 0.666065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02802930514017741, AUC: 0.4889395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0424200922648112, AUC: 0.6898010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03317641830444336, AUC: 0.73760625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02596500523885091, AUC: 0.7552725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05018684260050456, AUC: 0.650453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03653498331705729, AUC: 0.6990100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046749301910400394, AUC: 0.515105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01856188710530599, AUC: 0.72752825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029628105799357096, AUC: 0.7412112500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030789432525634767, AUC: 0.6164762500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0817971700032552, AUC: 0.5783312500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0227040163675944, AUC: 0.7244412500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0498909543355306, AUC: 0.46775275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019582595189412435, AUC: 0.75430925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020664418538411458, AUC: 0.7437542500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02831309191385905, AUC: 0.72965125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023371118545532227, AUC: 0.6736055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02237410036722819, AUC: 0.6765542499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07856465911865235, AUC: 0.448978\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03828496297200521, AUC: 0.71480175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019149785359700522, AUC: 0.71529475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.050760005950927736, AUC: 0.6641397499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14510747782389322, AUC: 0.52479725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022262718200683592, AUC: 0.69188075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04573096466064453, AUC: 0.49232025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03816016387939453, AUC: 0.7060265000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019613693237304688, AUC: 0.7315740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027844472249348957, AUC: 0.7548815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05331258010864258, AUC: 0.54695375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06000522740681966, AUC: 0.6343319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07145664723714193, AUC: 0.5384202499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14445747375488283, AUC: 0.6654610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02594074885050456, AUC: 0.6711805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019776312510172527, AUC: 0.72176275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0240688419342041, AUC: 0.7416707499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07244449361165364, AUC: 0.607812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15735057067871094, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0070382507642110185, AUC: 0.6923839999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006590328375498454, AUC: 0.6295010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0068728515307108565, AUC: 0.7137480000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006185853322347005, AUC: 0.7082279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010274443944295247, AUC: 0.638898\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.041808133443196616, AUC: 0.47783500000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009173896471659343, AUC: 0.6988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006104832967122396, AUC: 0.6816444999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006553720315297444, AUC: 0.69605425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00559605614344279, AUC: 0.7020212499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005156401475270589, AUC: 0.6838629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04046293258666992, AUC: 0.5150295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014719374974568685, AUC: 0.6577280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009179675738016764, AUC: 0.68071575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00967228062947591, AUC: 0.6736219999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017976115544637045, AUC: 0.63265475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005746415297190348, AUC: 0.6845272500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.17237427775065103, AUC: 0.48975225000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011655453046162924, AUC: 0.68841425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013989895502726238, AUC: 0.6434875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007923534552256266, AUC: 0.6964847499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0064593801498413084, AUC: 0.6940982499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006674419085184733, AUC: 0.6927025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06616741180419922, AUC: 0.49172425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010716429074605306, AUC: 0.6844480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02074752998352051, AUC: 0.61394225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0055234599113464355, AUC: 0.63934375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005329504489898682, AUC: 0.69660675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0048925609588623045, AUC: 0.6816989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06461004002888997, AUC: 0.4609225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009477181116739909, AUC: 0.681669\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00589048433303833, AUC: 0.6797275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007707028230031331, AUC: 0.6648132499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007741530895233154, AUC: 0.672638\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0085938720703125, AUC: 0.6564597500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02810840670267741, AUC: 0.57770125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007705361207326253, AUC: 0.68803\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005839045524597168, AUC: 0.713508\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005914435704549153, AUC: 0.7089445000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005181318918863933, AUC: 0.7098194999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004770515441894531, AUC: 0.7069730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0357341906229655, AUC: 0.462598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009423380851745605, AUC: 0.7068919999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008310783545176188, AUC: 0.6835009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008253718058268229, AUC: 0.6782974999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011113210360209147, AUC: 0.6475430000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005300031503041585, AUC: 0.70290475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020365578333536784, AUC: 0.5317782500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008806509335835775, AUC: 0.70689175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006643751462300619, AUC: 0.7118410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005555764039357503, AUC: 0.6880644999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007667877197265625, AUC: 0.699592\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007339644432067871, AUC: 0.69068775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07256966908772787, AUC: 0.441775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00890009339650472, AUC: 0.70036375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006897517999013265, AUC: 0.71033825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005625058015187582, AUC: 0.7030609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005414473533630371, AUC: 0.7011505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004986588001251221, AUC: 0.676474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13488222249348958, AUC: 0.47960474999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00889262835184733, AUC: 0.707726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008808841705322265, AUC: 0.7112129999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006655409971872965, AUC: 0.7115525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006998875459035238, AUC: 0.7128135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005059063752492269, AUC: 0.69741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03431269963582357, AUC: 0.47898199999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01017423915863037, AUC: 0.69251475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008285956064860026, AUC: 0.69168\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.007086555163065593, AUC: 0.6939725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006652998765309652, AUC: 0.68656425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008103957017262776, AUC: 0.68106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07789510854085287, AUC: 0.5253734999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011227512995402018, AUC: 0.69161175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008605889956156413, AUC: 0.701222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007929009278615316, AUC: 0.7012729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006564739227294922, AUC: 0.6873497499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007130799293518067, AUC: 0.6951059999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.16779090372721353, AUC: 0.420122\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010558457692464192, AUC: 0.7041875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010410885175069173, AUC: 0.69615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006845006465911865, AUC: 0.7092339999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008380580107371012, AUC: 0.7001535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006592520236968994, AUC: 0.7044765000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0804031244913737, AUC: 0.4518035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010301872571309408, AUC: 0.6767502500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007504733403523763, AUC: 0.6806949999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007643171151479085, AUC: 0.69373425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006733851909637451, AUC: 0.6931145000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007385058403015137, AUC: 0.69422725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10803143819173178, AUC: 0.5479215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009382303555806477, AUC: 0.706234\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008201499938964844, AUC: 0.71891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007616013050079346, AUC: 0.7152310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007079144318898519, AUC: 0.7061485000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007287272771199544, AUC: 0.69935275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07561480204264323, AUC: 0.4613225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009457375208536784, AUC: 0.685839\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00815510622660319, AUC: 0.69613425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008138670285542805, AUC: 0.69104275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007503003120422363, AUC: 0.6881285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007190152168273926, AUC: 0.6879325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051265459696451826, AUC: 0.50532125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011675307273864746, AUC: 0.70075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008366680463155111, AUC: 0.6922987500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007320447285970052, AUC: 0.6939385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00787890084584554, AUC: 0.6961375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006999681154886882, AUC: 0.7017365000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024676120122273763, AUC: 0.63194025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009455806732177734, AUC: 0.6935969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008788470904032388, AUC: 0.69287825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00647342316309611, AUC: 0.68685725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006153024832407633, AUC: 0.69032975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007172391414642334, AUC: 0.69058775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08554988098144531, AUC: 0.477703\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011436571439107259, AUC: 0.71444475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00800192912419637, AUC: 0.700733\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00985663382212321, AUC: 0.69092075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007760697841644287, AUC: 0.6987990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006150369803110759, AUC: 0.691604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05671908315022786, AUC: 0.533668\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015709013303120932, AUC: 0.62234275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012219577471415203, AUC: 0.6682805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011401678085327148, AUC: 0.6822522499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010150791803995769, AUC: 0.684853\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009571785926818848, AUC: 0.6859705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017568076451619466, AUC: 0.552037\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01510899257659912, AUC: 0.6327462500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012406338373819987, AUC: 0.658345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010656320571899414, AUC: 0.6817845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009291366577148437, AUC: 0.694849\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008692078590393067, AUC: 0.707087\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08856733703613281, AUC: 0.50411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014533365249633789, AUC: 0.65792475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01241419283548991, AUC: 0.6762757500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011105119387308756, AUC: 0.68713025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0104086701075236, AUC: 0.69055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009729955355326335, AUC: 0.6880704999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04360883712768555, AUC: 0.5185945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013422953605651855, AUC: 0.6412957499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011118162790934244, AUC: 0.669717\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010347522417704265, AUC: 0.6891022499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00948649787902832, AUC: 0.70020675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009515050252278646, AUC: 0.70157375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1643933359781901, AUC: 0.50325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014211595217386882, AUC: 0.6394249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012195903142293294, AUC: 0.673805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010350594202677409, AUC: 0.68132525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009725240389506023, AUC: 0.6853774999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00935900084177653, AUC: 0.6946750000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0660697758992513, AUC: 0.5135694999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01560573641459147, AUC: 0.6153299999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012945067087809245, AUC: 0.66796725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011738615989685059, AUC: 0.690298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010425549825032552, AUC: 0.6968665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010332967758178711, AUC: 0.700646\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05926859029134115, AUC: 0.60221975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01279738966623942, AUC: 0.63695275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010833484013875325, AUC: 0.674874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009537099838256836, AUC: 0.6896280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008747622807820639, AUC: 0.6938095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00828853988647461, AUC: 0.698684\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07285715738932291, AUC: 0.50675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017531503041585288, AUC: 0.671572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01308748467763265, AUC: 0.6748810000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011537857373555501, AUC: 0.685424\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010613829612731933, AUC: 0.6865515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01011445426940918, AUC: 0.690375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09763377126057943, AUC: 0.5022500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01373263390858968, AUC: 0.5764334999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012426781972249348, AUC: 0.62909875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011550174395243328, AUC: 0.645832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010789374987284342, AUC: 0.66507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010394479115804036, AUC: 0.674981\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06822527821858725, AUC: 0.447226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014332292238871256, AUC: 0.65176575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010996535619099935, AUC: 0.68590575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009717923800150553, AUC: 0.703718\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00909661070505778, AUC: 0.717946\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008599328358968098, AUC: 0.7217552500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03411801338195801, AUC: 0.497422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022077224095662436, AUC: 0.62268525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019720694859822592, AUC: 0.6208365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018516958872477212, AUC: 0.62140625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017730655034383137, AUC: 0.6281344999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016948844273885093, AUC: 0.63455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.18042217508951822, AUC: 0.46525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023322931925455728, AUC: 0.4911945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02044300842285156, AUC: 0.51327975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018756487528483072, AUC: 0.53349425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01746732457478841, AUC: 0.5584264999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015934155146280923, AUC: 0.5761550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02325810686747233, AUC: 0.631892\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024324716567993163, AUC: 0.587237\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022137495040893556, AUC: 0.60039575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020352453867594402, AUC: 0.6111424999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01926018778483073, AUC: 0.6195634999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018348526000976563, AUC: 0.626608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09032121022542318, AUC: 0.47581275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020768335978190104, AUC: 0.61878225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01974758275349935, AUC: 0.6250217499999999\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.01855265235900879, AUC: 0.627667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017725901285807293, AUC: 0.6326095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016895203272501626, AUC: 0.63418825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018617775599161782, AUC: 0.540304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02647641944885254, AUC: 0.53209525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024486117045084636, AUC: 0.540969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02307672119140625, AUC: 0.547566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02115683937072754, AUC: 0.5650835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019348943710327148, AUC: 0.57118125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15332138061523437, AUC: 0.506514\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023836283365885415, AUC: 0.63452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021744002024332684, AUC: 0.627308\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020054114659627278, AUC: 0.628565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019174705505371092, AUC: 0.628949\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018202950795491536, AUC: 0.62999825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04917230733235677, AUC: 0.33498750000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025942994435628256, AUC: 0.37271750000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022548391977945965, AUC: 0.4041557499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020069451649983725, AUC: 0.4484975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01900673548380534, AUC: 0.48382025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018035298665364585, AUC: 0.5150507499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021969970067342123, AUC: 0.5320484999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017730456670125325, AUC: 0.593783\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01767593765258789, AUC: 0.5954985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017375267664591472, AUC: 0.5962182500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01677971394856771, AUC: 0.609223\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01605204709370931, AUC: 0.6231095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15781500752766928, AUC: 0.492252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022463621775309243, AUC: 0.51104275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0196594664255778, AUC: 0.5352815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018275842666625977, AUC: 0.5587535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01761970329284668, AUC: 0.5751392499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01684068234761556, AUC: 0.5918825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09496248118082683, AUC: 0.606968\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02092951265970866, AUC: 0.6711269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01968722089131673, AUC: 0.6559695000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01862999153137207, AUC: 0.65804025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01789906883239746, AUC: 0.6605300000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017676013310750326, AUC: 0.656416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax 3 class oversampled\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_oversampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"oversampled\", 3, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c7c1578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.06791185506184896, AUC: 0.4566004999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08671995798746744, AUC: 0.5282500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09225210825602213, AUC: 0.566\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0833435287475586, AUC: 0.706586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12462593332926432, AUC: 0.40312625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07695217132568359, AUC: 0.5251574999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.18642843627929687, AUC: 0.49625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021841992060343426, AUC: 0.54775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03414060211181641, AUC: 0.5727819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1417373352050781, AUC: 0.53453375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06535907745361329, AUC: 0.62525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3198079325358073, AUC: 0.4785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04631866073608398, AUC: 0.42072350000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13835987854003906, AUC: 0.5195000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051361016591389974, AUC: 0.6435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07425342814127604, AUC: 0.6607350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07757727813720704, AUC: 0.64284725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03721042505900065, AUC: 0.6778495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02098095448811849, AUC: 0.47322075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.16095573933919272, AUC: 0.50825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034695546468098956, AUC: 0.5850000000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01952930768330892, AUC: 0.7052499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08565375264485676, AUC: 0.5975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.20981897481282552, AUC: 0.5120082499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09289242299397786, AUC: 0.506735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.19363004048665364, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.054670645395914715, AUC: 0.617\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07925079600016276, AUC: 0.6259749999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07442671203613281, AUC: 0.4968645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11843157450358073, AUC: 0.54425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04225417709350586, AUC: 0.5312614999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08632454427083333, AUC: 0.5407562499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07916334025065104, AUC: 0.578\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0905707041422526, AUC: 0.5886064999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.18736929829915364, AUC: 0.6848439999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06501365661621093, AUC: 0.6124105000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0285569642384847, AUC: 0.56917\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0390445925394694, AUC: 0.52748325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04369677225748698, AUC: 0.6465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02975761349995931, AUC: 0.61544175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08371634674072266, AUC: 0.63944325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023585657119750976, AUC: 0.6835680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05551881281534831, AUC: 0.5087525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08560390472412109, AUC: 0.542256\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09854295094807942, AUC: 0.6492020000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03722023010253906, AUC: 0.7619155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06495366668701172, AUC: 0.61525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03355563926696777, AUC: 0.760559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02749937884012858, AUC: 0.44883674999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07351869455973307, AUC: 0.4578585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02108225440979004, AUC: 0.715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025557597478230793, AUC: 0.65389875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1922625681559245, AUC: 0.52377625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06593928654988607, AUC: 0.617919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03492198689778646, AUC: 0.46230574999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024630342483520508, AUC: 0.61875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03410712432861328, AUC: 0.56475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13260887400309246, AUC: 0.45789050000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04906223678588867, AUC: 0.66874275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.19964121500651041, AUC: 0.4950965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03939613342285156, AUC: 0.3961875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017431598663330078, AUC: 0.5200425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01370955499013265, AUC: 0.5369204999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01750962511698405, AUC: 0.5695325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015213075955708822, AUC: 0.5258777499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02855021286010742, AUC: 0.5794295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0702648417154948, AUC: 0.55526875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030321114222208657, AUC: 0.5047295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03292193857828776, AUC: 0.51471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02321117655436198, AUC: 0.5869065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015741393089294432, AUC: 0.52681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016091182072957358, AUC: 0.5483830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036114991505940754, AUC: 0.48668925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01868545405069987, AUC: 0.5649959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017328842163085938, AUC: 0.61411825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012733923276265463, AUC: 0.6162995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014975570360819498, AUC: 0.597366\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017072644551595052, AUC: 0.6420115000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05582231648763021, AUC: 0.5051615000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022970229466756184, AUC: 0.41054749999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02178586959838867, AUC: 0.524928\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013495848019917807, AUC: 0.5080582499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021119544982910157, AUC: 0.58015275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014171557744344076, AUC: 0.5355315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03253977839152018, AUC: 0.5179284999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024007829666137695, AUC: 0.67109425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014369452476501465, AUC: 0.6566114999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011822139104207357, AUC: 0.6911192500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012993083953857423, AUC: 0.68320325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012996536254882812, AUC: 0.65358\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02295385233561198, AUC: 0.49830299999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0273132692972819, AUC: 0.6031385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01074817721048991, AUC: 0.58614325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01104074478149414, AUC: 0.615472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020914362589518228, AUC: 0.6251475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014787112871805827, AUC: 0.6405025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08037962849934896, AUC: 0.4628359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01809362983703613, AUC: 0.5330565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020722461700439454, AUC: 0.4889255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017747627258300782, AUC: 0.5882764999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01833732732137044, AUC: 0.55105525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01741223907470703, AUC: 0.57722075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04959615198771159, AUC: 0.6203489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023673035303751627, AUC: 0.6377204999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020209052403767903, AUC: 0.6498085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017940044403076172, AUC: 0.6033207500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017316078186035155, AUC: 0.6572015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020635093688964844, AUC: 0.6582539999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05744741439819336, AUC: 0.519733\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01976061948140462, AUC: 0.5030840000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01904069709777832, AUC: 0.5676349999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025588862101236978, AUC: 0.6220815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0230066769917806, AUC: 0.6287335000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01813083585103353, AUC: 0.5423005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0582355219523112, AUC: 0.5374399999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025380194346110024, AUC: 0.60289025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024897900899251302, AUC: 0.60294025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0207283509572347, AUC: 0.60634225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014867133140563964, AUC: 0.57120925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016415149052937825, AUC: 0.63211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07092256164550781, AUC: 0.45551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01873568344116211, AUC: 0.54165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01357651392618815, AUC: 0.5340185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020140457153320312, AUC: 0.54319\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014944022178649902, AUC: 0.59401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014092280705769856, AUC: 0.601253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05099944814046224, AUC: 0.5224775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017991117477416992, AUC: 0.5075117499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018941848754882813, AUC: 0.5308280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016492526690165203, AUC: 0.53056625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015302247365315755, AUC: 0.5692657499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015310078303019206, AUC: 0.5605137499999999\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.04025861612955729, AUC: 0.5220560000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020912960688273113, AUC: 0.45255475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0220375607808431, AUC: 0.47045675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019324415842692056, AUC: 0.5046815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014438618024190266, AUC: 0.49843249999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018100303014119468, AUC: 0.48330799999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022196496963500977, AUC: 0.49147175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0213782590230306, AUC: 0.47660975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017011202494303386, AUC: 0.47069049999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017968064626057944, AUC: 0.5514395000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015594100634256999, AUC: 0.5063630000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01593225129445394, AUC: 0.54639675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0748257293701172, AUC: 0.45289375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02488068135579427, AUC: 0.550902\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018912328084309895, AUC: 0.5579725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0176573060353597, AUC: 0.567916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018083048502604167, AUC: 0.5864227499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01872659683227539, AUC: 0.61277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02003700319925944, AUC: 0.47823499999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02026980145772298, AUC: 0.523676\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019526674270629884, AUC: 0.54862025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01745258649190267, AUC: 0.54490325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019238205591837566, AUC: 0.5777632500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01747227414449056, AUC: 0.55598875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029482690811157227, AUC: 0.4134495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022608853658040363, AUC: 0.44749300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01591034952799479, AUC: 0.4510745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014206652959187825, AUC: 0.4734515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014117222785949707, AUC: 0.4829435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014135409990946451, AUC: 0.46867000000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07733729553222657, AUC: 0.514\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01978271230061849, AUC: 0.6284625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01943801180521647, AUC: 0.5618529999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018782593409220377, AUC: 0.6396245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02197055943806966, AUC: 0.58559675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015723384221394857, AUC: 0.63102375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08639242553710938, AUC: 0.44622049999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01906998062133789, AUC: 0.55345575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01628123919169108, AUC: 0.5830825000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014755275090535482, AUC: 0.544347\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015178144137064616, AUC: 0.5718735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01576442813873291, AUC: 0.597281\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06804661560058593, AUC: 0.50124725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01599384593963623, AUC: 0.6327615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017801820119222007, AUC: 0.6273114999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02052441660563151, AUC: 0.5913550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016175780614217122, AUC: 0.6497134999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01329606056213379, AUC: 0.64671225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07752686055501302, AUC: 0.508238\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02917424201965332, AUC: 0.58314375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019931953430175783, AUC: 0.56763075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02064315414428711, AUC: 0.57564375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021608676274617513, AUC: 0.580406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02054514821370443, AUC: 0.57553775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0674105478922526, AUC: 0.4728205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019937909444173178, AUC: 0.5487402499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019948922475179036, AUC: 0.580615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01908419672648112, AUC: 0.58060725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018642005920410157, AUC: 0.5823885000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019032108306884767, AUC: 0.5586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04307663218180339, AUC: 0.5421400000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031121135075887044, AUC: 0.5097672500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030905821482340494, AUC: 0.5186885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0296244322458903, AUC: 0.51594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028053012212117513, AUC: 0.5158355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028321638107299804, AUC: 0.52181875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023577195485432943, AUC: 0.56701375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019355218251546225, AUC: 0.5596375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01783757781982422, AUC: 0.5250857499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019409919102986655, AUC: 0.4927619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021135842641194662, AUC: 0.47981525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02017619260152181, AUC: 0.48346600000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13144989267985027, AUC: 0.48923275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04465501403808594, AUC: 0.448436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025628090540568034, AUC: 0.49360625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022518166224161786, AUC: 0.5075242499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022671367009480796, AUC: 0.5288857499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022941177368164062, AUC: 0.535334\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019993571599324543, AUC: 0.4894635\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02075418217976888, AUC: 0.5276945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02110629971822103, AUC: 0.5280819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021369503021240233, AUC: 0.52989025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02162250010172526, AUC: 0.5413039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019616316477457683, AUC: 0.538723\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052807510375976564, AUC: 0.508723\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02868321355183919, AUC: 0.504621\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020712902069091797, AUC: 0.48709250000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01952614212036133, AUC: 0.50118325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021457932790120444, AUC: 0.513975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019957902272542318, AUC: 0.4976835\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05844790522257487, AUC: 0.436079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04161790974934896, AUC: 0.41017574999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03297936248779297, AUC: 0.45298150000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03173651186625163, AUC: 0.484166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031239687601725262, AUC: 0.4969775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030712552388509114, AUC: 0.49375825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0825753911336263, AUC: 0.5067455000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028864243825276692, AUC: 0.57772475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013822872161865235, AUC: 0.6299349999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013534768104553223, AUC: 0.6126012500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01534874693552653, AUC: 0.6228402500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014747143109639486, AUC: 0.62378125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1514639129638672, AUC: 0.496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.056467967987060545, AUC: 0.5228677500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02668975003560384, AUC: 0.55353375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0192316951751709, AUC: 0.62123175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01710187021891276, AUC: 0.61490525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016537907282511394, AUC: 0.628521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017855923970540366, AUC: 0.5148452499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0177015749613444, AUC: 0.5100979999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017785176595052084, AUC: 0.5129177500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01792516072591146, AUC: 0.5183495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017912006378173827, AUC: 0.5193242499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018037789662679035, AUC: 0.5230805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0830342788696289, AUC: 0.59685\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07981536610921224, AUC: 0.5952575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07686905415852864, AUC: 0.59561275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07359730275472005, AUC: 0.5931742500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07007958984375, AUC: 0.5917107500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06668889363606771, AUC: 0.59312875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04654472351074219, AUC: 0.5052355000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04232405598958333, AUC: 0.50597625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03877248509724935, AUC: 0.5034955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.035101715087890624, AUC: 0.50419425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03185273933410644, AUC: 0.504876\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028522071838378907, AUC: 0.508505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06314700190226237, AUC: 0.49481850000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.059364199320475264, AUC: 0.49259775000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05568407185872396, AUC: 0.49136525000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05261873118082682, AUC: 0.4891175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0492468376159668, AUC: 0.485177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04589188385009765, AUC: 0.48085300000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03781058883666992, AUC: 0.5287555\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.03586234410603841, AUC: 0.530854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03428972816467285, AUC: 0.52935225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03286473210652669, AUC: 0.52563\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0316736806233724, AUC: 0.5248975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03038536580403646, AUC: 0.523923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018682617823282878, AUC: 0.49140350000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01834485181172689, AUC: 0.48672449999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018244314829508463, AUC: 0.4827665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01841034444173177, AUC: 0.4929812499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018288359959920248, AUC: 0.49100124999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018316246032714843, AUC: 0.49401399999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.054578914642333984, AUC: 0.49975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05042789204915365, AUC: 0.49925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04630350621541341, AUC: 0.4985\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042328463236490886, AUC: 0.49525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03776787439982096, AUC: 0.49125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033916096369425455, AUC: 0.489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.051419334411621095, AUC: 0.562046\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0489683723449707, AUC: 0.5580135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.046271133422851565, AUC: 0.554611\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043787618001302084, AUC: 0.54975475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04167738850911459, AUC: 0.54636275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038966139475504556, AUC: 0.544304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020273751576741536, AUC: 0.42567449999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020355927149454753, AUC: 0.42919025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02056033452351888, AUC: 0.43619425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020682441075642904, AUC: 0.4430045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021071726481119792, AUC: 0.45022724999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021033005396525067, AUC: 0.4539877499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06032994206746419, AUC: 0.49855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055692938486735025, AUC: 0.4903955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05186021550496419, AUC: 0.487726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04863836924235026, AUC: 0.4837415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04537117767333984, AUC: 0.47235374999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042214483896891274, AUC: 0.46409199999999995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax 3 class undersampled\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_undersampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"undersampled\", 3, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2779a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.016055294354756673, AUC: 0.47430125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03611184946695963, AUC: 0.7559492499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03562041346232096, AUC: 0.6264779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06254090118408204, AUC: 0.62928425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1142723871866862, AUC: 0.55781875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04170296859741211, AUC: 0.72629925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.038351935068766274, AUC: 0.41669600000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021730786641438803, AUC: 0.7741105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021552952448527018, AUC: 0.7625515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09568314615885416, AUC: 0.607448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022815556208292644, AUC: 0.75852225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02285769526163737, AUC: 0.6950555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023275182088216145, AUC: 0.6044660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14629796346028645, AUC: 0.6123725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03382949829101563, AUC: 0.7257669999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033460545857747395, AUC: 0.719191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021380350112915038, AUC: 0.6827650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03066267776489258, AUC: 0.7325909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012790461540222169, AUC: 0.581855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09936481221516927, AUC: 0.6232325000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05565328725179036, AUC: 0.643502\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026218731562296548, AUC: 0.684607\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03306907018025716, AUC: 0.72404125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.037367998758951824, AUC: 0.696581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.045794024149576826, AUC: 0.5279094999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14354694112141927, AUC: 0.46023775000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09222124735514323, AUC: 0.4818905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04089860026041667, AUC: 0.577169\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.044669743855794274, AUC: 0.69609525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0232276299794515, AUC: 0.7324579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05181436665852865, AUC: 0.5708355\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02135098838806152, AUC: 0.7595225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055828638712565104, AUC: 0.6434209999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08294895426432292, AUC: 0.5324955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12871635182698568, AUC: 0.558932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09302480824788412, AUC: 0.56569925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.060630779266357425, AUC: 0.46326875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03703741200764974, AUC: 0.6256362499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055502588907877605, AUC: 0.6633374999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10618753306070963, AUC: 0.5813404999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02176751200358073, AUC: 0.7374425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03355073610941569, AUC: 0.6054115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018496875127156576, AUC: 0.48829524999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02671456782023112, AUC: 0.72948175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027273154576619465, AUC: 0.66245925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03575896453857422, AUC: 0.732705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06200951385498047, AUC: 0.62559375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019033656120300294, AUC: 0.727309\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02291465441385905, AUC: 0.5112005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03519356791178385, AUC: 0.640046\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03525608825683594, AUC: 0.7110897500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03568172073364258, AUC: 0.7211090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030747600555419922, AUC: 0.73623925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02386469841003418, AUC: 0.7365207500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03950813420613607, AUC: 0.5819482500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022212451299031575, AUC: 0.76538475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03878905614217122, AUC: 0.7560057500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.049655349731445315, AUC: 0.672006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036036944071451825, AUC: 0.7002165000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11899886067708333, AUC: 0.541277\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03906822331746419, AUC: 0.58535325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012327479362487794, AUC: 0.7076292500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008978109995524088, AUC: 0.714212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008156375090281168, AUC: 0.7202494999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0076681642532348635, AUC: 0.65680575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007864104429880779, AUC: 0.7167395000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08223818969726562, AUC: 0.5790609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01040104039510091, AUC: 0.6992\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008204577604929606, AUC: 0.7045100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006907828648885091, AUC: 0.654234\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011890000979105631, AUC: 0.6528425000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005349295616149902, AUC: 0.6920515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022533815383911134, AUC: 0.48888824999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01407694403330485, AUC: 0.7038144999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008764299074808756, AUC: 0.717774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011738661448160808, AUC: 0.7028047499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010634668986002604, AUC: 0.693258\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009100358963012695, AUC: 0.708078\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06402586619059245, AUC: 0.516766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008756762822469075, AUC: 0.70093675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011492543538411459, AUC: 0.6924680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010308994611104329, AUC: 0.7057655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008574975967407226, AUC: 0.693762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005933338483174642, AUC: 0.67088375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1416108652750651, AUC: 0.487263\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012895804087320963, AUC: 0.6970875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007884906133015951, AUC: 0.709414\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005928963661193848, AUC: 0.67998325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008646313985188801, AUC: 0.69911225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010072717030843099, AUC: 0.673478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02893419392903646, AUC: 0.427747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010559511820475261, AUC: 0.693295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007269387086232503, AUC: 0.6919712499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008081448554992677, AUC: 0.7042634999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005894083976745606, AUC: 0.6870690000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007918983141581218, AUC: 0.7033457500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023420071919759113, AUC: 0.5963620000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00855690336227417, AUC: 0.69785325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011611592292785645, AUC: 0.68083075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006724252700805664, AUC: 0.68254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008679204940795899, AUC: 0.6874345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00812897253036499, AUC: 0.6870875000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0631892458597819, AUC: 0.520509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014058592796325684, AUC: 0.7104565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01391873296101888, AUC: 0.692715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012446569124857585, AUC: 0.683352\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00712129545211792, AUC: 0.6971670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013337043762207032, AUC: 0.6629885000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043535789489746096, AUC: 0.495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009071105321248373, AUC: 0.6661060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01504934565226237, AUC: 0.51368175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010103240013122558, AUC: 0.6047045\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010002804438273113, AUC: 0.6837955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008092653910319011, AUC: 0.7050314999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036135873158772785, AUC: 0.533866\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014435569127400716, AUC: 0.6638135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008396699587504068, AUC: 0.70215875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007864575544993082, AUC: 0.7102425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0067564943631490074, AUC: 0.6970745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0065613835652669275, AUC: 0.7040464999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03976090749104818, AUC: 0.45014025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011630398114522298, AUC: 0.671645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010336338678995768, AUC: 0.6974147500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009164682706197103, AUC: 0.6895639999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008986194610595704, AUC: 0.69600275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007866462389628093, AUC: 0.7043975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1216561737060547, AUC: 0.5001305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016188626607259116, AUC: 0.674406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01277285925547282, AUC: 0.6827245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008881619135538737, AUC: 0.6888154999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009830967585245768, AUC: 0.693422\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.010699673334757487, AUC: 0.68692625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13140752156575522, AUC: 0.40731150000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009092360814412434, AUC: 0.6532545000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00915279992421468, AUC: 0.6635584999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008236936410268148, AUC: 0.68385875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008985475540161133, AUC: 0.68551075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00788552967707316, AUC: 0.6936002499999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055584776560465496, AUC: 0.5012015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013723857243855794, AUC: 0.6519984999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010038552284240722, AUC: 0.69695825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008345432122548421, AUC: 0.70370825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007355899175008138, AUC: 0.695063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01339964230855306, AUC: 0.6635892500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.043987809499104816, AUC: 0.5163030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012440644900004069, AUC: 0.6470849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009844256401062011, AUC: 0.687621\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010419578234354654, AUC: 0.7014585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008877911567687989, AUC: 0.7032975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00784685246149699, AUC: 0.7006917500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10329928334554037, AUC: 0.478474\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012333295186360676, AUC: 0.6938122499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008914847373962403, AUC: 0.71429425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008689377148946126, AUC: 0.7240175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007515768051147461, AUC: 0.7259194999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007687704086303711, AUC: 0.724637\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015706805864969888, AUC: 0.47631249999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016135951360066732, AUC: 0.6504320000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01372808583577474, AUC: 0.69282175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008877521197001139, AUC: 0.6995815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008750017484029133, AUC: 0.7087890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007644993305206299, AUC: 0.7078195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0355071652730306, AUC: 0.60903125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01099613094329834, AUC: 0.6783659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009785359382629394, AUC: 0.70701775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008285115559895834, AUC: 0.6965255000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0073421122233072915, AUC: 0.6996015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006832772254943847, AUC: 0.7022755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.034445589701334635, AUC: 0.543596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016404394785563152, AUC: 0.6274365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01124718952178955, AUC: 0.6982367500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00866994063059489, AUC: 0.7055935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007906129360198974, AUC: 0.6861079999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008005694071451823, AUC: 0.7083957499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02252826499938965, AUC: 0.49408050000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012760955492655436, AUC: 0.6475814999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010815210978190104, AUC: 0.6984277500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00865162467956543, AUC: 0.71362375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008169202009836833, AUC: 0.712768\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007235498746236166, AUC: 0.71003575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04927709452311198, AUC: 0.5360809999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020444090525309246, AUC: 0.6114245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018066187540690105, AUC: 0.61097725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016372182210286457, AUC: 0.64874725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014463507970174153, AUC: 0.652595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013871166547139486, AUC: 0.6688622499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016269872029622396, AUC: 0.56457375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019392504374186197, AUC: 0.6632262500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017602567036946615, AUC: 0.676465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01554740301767985, AUC: 0.6668775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0141172882715861, AUC: 0.6675977500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013984037399291991, AUC: 0.66656275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02185945765177409, AUC: 0.44386000000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020324805577596028, AUC: 0.5484450000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017433102289835613, AUC: 0.5816335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01608048756917318, AUC: 0.6251482499999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014942967096964518, AUC: 0.6394407499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0141406192779541, AUC: 0.63423425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052826864878336585, AUC: 0.5232692500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017311200459798178, AUC: 0.60036475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015557159423828125, AUC: 0.629264\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013975793520609538, AUC: 0.6431795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013513456662495931, AUC: 0.646793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012495676676432291, AUC: 0.6523802500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11159884389241537, AUC: 0.5022500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020158546447753906, AUC: 0.619614\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016582982381184896, AUC: 0.6298455000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014823368390401204, AUC: 0.64545325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014286836624145509, AUC: 0.65364725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013569975852966308, AUC: 0.6705687499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017981125513712566, AUC: 0.62403175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016956002235412597, AUC: 0.65057875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014717447598775227, AUC: 0.67077575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014448850949605307, AUC: 0.6772630000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013784406661987304, AUC: 0.6800772500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013297622680664062, AUC: 0.6883662500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02253176244099935, AUC: 0.38025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017007452964782715, AUC: 0.49491849999999993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013702949206034343, AUC: 0.5722999999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012091657638549805, AUC: 0.62188175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011345415115356446, AUC: 0.6478435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010520956039428712, AUC: 0.6517965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05872567876180013, AUC: 0.477442\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016288041750590006, AUC: 0.5482722499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015374170303344727, AUC: 0.5966499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013903141975402832, AUC: 0.6167762499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013051496505737305, AUC: 0.6307605000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012020354588826497, AUC: 0.6369975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09410391743977864, AUC: 0.53997375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015711320877075195, AUC: 0.5547935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0132825927734375, AUC: 0.6225419999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012496577580769858, AUC: 0.65790775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011546629587809245, AUC: 0.6855102500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011075790723164875, AUC: 0.6923239999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03843972905476888, AUC: 0.40332999999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015896211942036945, AUC: 0.57113575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014678731600443522, AUC: 0.608488\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013891726175944011, AUC: 0.6276667499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012714048067728679, AUC: 0.6478772500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012240392049153646, AUC: 0.654326\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13109347279866537, AUC: 0.50525275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03300445556640625, AUC: 0.47930075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029332815170288087, AUC: 0.48819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028594566345214845, AUC: 0.499108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027081735610961916, AUC: 0.511413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025909495035807292, AUC: 0.5185365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1029901123046875, AUC: 0.50025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02301000912984212, AUC: 0.43321924999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022569849014282228, AUC: 0.441427\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02158186912536621, AUC: 0.44763050000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020538097381591798, AUC: 0.4659785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019702627817789715, AUC: 0.48062625000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023564292271931967, AUC: 0.45241875000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02916544532775879, AUC: 0.53080425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.028007539749145507, AUC: 0.5446295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026478137334187826, AUC: 0.5537464999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025641573588053385, AUC: 0.56487725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02404318936665853, AUC: 0.5736215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02543938191731771, AUC: 0.47996125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021576783498128256, AUC: 0.4897385\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.02067400868733724, AUC: 0.495604\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01999156379699707, AUC: 0.50437225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019627861658732097, AUC: 0.5110064999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01923505210876465, AUC: 0.5279547499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1341986287434896, AUC: 0.50725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021371795654296876, AUC: 0.5519390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018644033432006837, AUC: 0.5479595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01800613530476888, AUC: 0.550837\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017945244471232098, AUC: 0.55038875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01756190045674642, AUC: 0.5450485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0460149294535319, AUC: 0.50478975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031996718088785805, AUC: 0.46061275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.030549344380696616, AUC: 0.4556745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02836615753173828, AUC: 0.46326725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02741913604736328, AUC: 0.4685975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02567314910888672, AUC: 0.47316024999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019836244583129884, AUC: 0.49259749999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02396564737955729, AUC: 0.511819\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023041847229003907, AUC: 0.51656875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02163593292236328, AUC: 0.5297827500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021023804346720378, AUC: 0.53771275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020544043223063153, AUC: 0.5495460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.13260897827148438, AUC: 0.48898499999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026807572046915692, AUC: 0.49509125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024481999715169272, AUC: 0.50918575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022158309936523436, AUC: 0.521662\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020969959259033204, AUC: 0.537382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019950795491536458, AUC: 0.559904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012096856753031413, AUC: 0.5851649999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0187947998046875, AUC: 0.64145775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02236570421854655, AUC: 0.5851535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021723355611165365, AUC: 0.58228925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02076173973083496, AUC: 0.583962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02045643997192383, AUC: 0.5925315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024747300465901692, AUC: 0.557861\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022461910883585613, AUC: 0.5737\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021815043767293294, AUC: 0.5746705000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02103948465983073, AUC: 0.5805822500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02046873474121094, AUC: 0.58130175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019558881759643553, AUC: 0.58998375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax 3 class both sampled\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_sampled, network, optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"both sampled\", 3, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fb1709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.04363488133748372, AUC: 0.4146269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04962215296427409, AUC: 0.62180475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.17878415934244793, AUC: 0.543741\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03869622294108073, AUC: 0.6913607500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15376093037923177, AUC: 0.5556925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2706865743001302, AUC: 0.5105124999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09862606811523437, AUC: 0.38977124999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2495005391438802, AUC: 0.67860725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12525575002034506, AUC: 0.58943425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03223107210795085, AUC: 0.675779\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06034561920166016, AUC: 0.5864699999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09735928090413412, AUC: 0.6044039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09450116729736328, AUC: 0.48917175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.21149256388346355, AUC: 0.52174275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03852157719930013, AUC: 0.68021375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08718929290771485, AUC: 0.62881575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10507400258382162, AUC: 0.6670825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.048800389607747394, AUC: 0.7183990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05848376210530599, AUC: 0.46758725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05955242538452148, AUC: 0.69980325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.17376915486653646, AUC: 0.55425625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0648731206258138, AUC: 0.639452\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03374654134114583, AUC: 0.7472715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042087989807128905, AUC: 0.686296\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04608045705159505, AUC: 0.5249912499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06195318603515625, AUC: 0.732211\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12120848592122396, AUC: 0.58463975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036402669270833334, AUC: 0.7281365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04801129913330078, AUC: 0.72215725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.12949637349446613, AUC: 0.5917385000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024358436584472655, AUC: 0.4287875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.16968157450358073, AUC: 0.55372225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07440952555338541, AUC: 0.6560864999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09203959147135417, AUC: 0.6671954999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14386396789550782, AUC: 0.5808435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.042079591115315756, AUC: 0.74354975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07577235412597656, AUC: 0.49188000000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05159897740681966, AUC: 0.75609425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11204680633544922, AUC: 0.70022925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03384982554117839, AUC: 0.7464955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1946669667561849, AUC: 0.50425125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09043670908610026, AUC: 0.63722075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.055693312327067056, AUC: 0.5191872500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03606189982096354, AUC: 0.7411745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.18051688639322916, AUC: 0.548418\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08310211435953777, AUC: 0.6188524999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07699418131510416, AUC: 0.672619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0881559066772461, AUC: 0.5530099999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04299561564127604, AUC: 0.5087517500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.15546345011393228, AUC: 0.5800845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03873108037312826, AUC: 0.7399070000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06728227742513021, AUC: 0.71144575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07123749033610026, AUC: 0.6652324999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0848887710571289, AUC: 0.6615619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1270685501098633, AUC: 0.48275075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09582519276936849, AUC: 0.6299814999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06694557189941407, AUC: 0.7138075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03426960245768229, AUC: 0.7505274999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07431981913248698, AUC: 0.66552725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.036539794921875, AUC: 0.6821465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07454308319091797, AUC: 0.434209\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013316583633422852, AUC: 0.70420875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01124629306793213, AUC: 0.7086512500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007920485814412435, AUC: 0.73830775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008849317232767741, AUC: 0.6498504999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010091832160949707, AUC: 0.7125495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10069638315836589, AUC: 0.49956849999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01421258576711019, AUC: 0.594288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015730713526407876, AUC: 0.6453924999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008920839309692383, AUC: 0.703027\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009730610211690267, AUC: 0.5883565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008338184038798014, AUC: 0.6933117500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.09017036437988281, AUC: 0.5322840000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007687253634134928, AUC: 0.6536964999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010423506418863932, AUC: 0.70096525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011187792778015137, AUC: 0.6915150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005874096711476644, AUC: 0.6873484999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006040340105692546, AUC: 0.70571625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08387016042073568, AUC: 0.51374125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0264178778330485, AUC: 0.66674125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007123372713724772, AUC: 0.63179675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009579925855000814, AUC: 0.70849575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03910842514038086, AUC: 0.47300025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00787201468149821, AUC: 0.6980597500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029839368184407553, AUC: 0.5555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020737744013468423, AUC: 0.6480060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018538522084554036, AUC: 0.6686960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007344334602355957, AUC: 0.629575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007039662520090739, AUC: 0.6465035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008246427536010742, AUC: 0.7091225000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05784117889404297, AUC: 0.428782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017408482233683267, AUC: 0.566055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008381917317708333, AUC: 0.7153147500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007022868792215983, AUC: 0.6993965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0069561947186787924, AUC: 0.69534275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007438094139099121, AUC: 0.643257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.11644402821858724, AUC: 0.482735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00888379700978597, AUC: 0.689367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01177847957611084, AUC: 0.6940360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01343868637084961, AUC: 0.70688825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009436445871988932, AUC: 0.6030139999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0061645070711771645, AUC: 0.69882675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029085997899373373, AUC: 0.462816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0164246088663737, AUC: 0.6404845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010561179478963217, AUC: 0.6986525000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011386508623758953, AUC: 0.66756425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011250067710876464, AUC: 0.6364415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011979742050170899, AUC: 0.6492600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.052094874064127605, AUC: 0.41186675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007855097611745198, AUC: 0.7123175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007371882279713949, AUC: 0.71560025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006560898145039877, AUC: 0.704473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009296425819396973, AUC: 0.7006827499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007070754369099935, AUC: 0.7227552499999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04920239130655924, AUC: 0.45506650000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013413733800252278, AUC: 0.68122325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.026320532480875652, AUC: 0.5872227499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012405441919962566, AUC: 0.67520675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007073937892913818, AUC: 0.6434925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006966787179311117, AUC: 0.6589654999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.03188890139261882, AUC: 0.48664775000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011648878415425619, AUC: 0.65467525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007969536781311036, AUC: 0.6784969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01371242618560791, AUC: 0.6348517499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009105655988057454, AUC: 0.68488375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011321789423624674, AUC: 0.6619085000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01638830025990804, AUC: 0.44145775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013998000144958497, AUC: 0.65674175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008305228710174561, AUC: 0.665267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007991666634877524, AUC: 0.70684025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007690181732177734, AUC: 0.6913872500000001\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.012132413546244303, AUC: 0.6738875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10782556406656901, AUC: 0.46748075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01704342969258626, AUC: 0.66308925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02381509717305501, AUC: 0.63820125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011747226079305013, AUC: 0.6678249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00783754825592041, AUC: 0.6960740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008658348083496093, AUC: 0.7064284999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05203556950887044, AUC: 0.39201675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012291367212931316, AUC: 0.673396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017334779739379882, AUC: 0.67508725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010636355717976888, AUC: 0.6902425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011524249712626139, AUC: 0.6736275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010668145497639975, AUC: 0.684875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10393102518717448, AUC: 0.5525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013746212959289551, AUC: 0.6797715\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009276555061340333, AUC: 0.706631\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008293928305308024, AUC: 0.70217375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009424553871154786, AUC: 0.68287325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006800747076670329, AUC: 0.6936475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.040763876597086586, AUC: 0.4992782500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01301093292236328, AUC: 0.6925330000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009786645571390787, AUC: 0.6863984999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007128142833709717, AUC: 0.655247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008048458099365234, AUC: 0.6908912500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008178005536397298, AUC: 0.69945725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2084924570719401, AUC: 0.4995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01627512327829997, AUC: 0.6693960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012040935198465982, AUC: 0.6866904999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012673090934753418, AUC: 0.6935407499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009800802230834961, AUC: 0.692769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009424535751342774, AUC: 0.7018377499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06502225748697917, AUC: 0.503001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007964890003204345, AUC: 0.65181\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011343360900878906, AUC: 0.6731689999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.022087998708089192, AUC: 0.6330995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008024752457936605, AUC: 0.6874324999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009253157297770181, AUC: 0.6897719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07185153452555339, AUC: 0.45100025000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009637622515360515, AUC: 0.6718987500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008470650355021158, AUC: 0.6718695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012917198499043783, AUC: 0.660728\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013326950391133626, AUC: 0.67106675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007107755661010742, AUC: 0.64912425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07134564971923828, AUC: 0.5458515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017540618260701496, AUC: 0.67257\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011079156557718912, AUC: 0.6736655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008552858670552572, AUC: 0.704681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008437433878580728, AUC: 0.696625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007123847643534342, AUC: 0.6689149999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021634162267049152, AUC: 0.43666399999999994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014987191836039226, AUC: 0.63145925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013842075983683269, AUC: 0.6552752500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012107837041219075, AUC: 0.6576875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013599220911661785, AUC: 0.67393025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010749432881673177, AUC: 0.6741815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.033939566294352214, AUC: 0.45522674999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01725614102681478, AUC: 0.6104149999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015038999557495117, AUC: 0.63701075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013305308977762859, AUC: 0.6616200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012748385747273763, AUC: 0.668221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010733090718587239, AUC: 0.6705344999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.056802549997965496, AUC: 0.429302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018670122146606447, AUC: 0.56151875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01573946221669515, AUC: 0.6071215000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014314886728922525, AUC: 0.654967\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01147825558980306, AUC: 0.65495375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012093286196390787, AUC: 0.6614979999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.08207818349202474, AUC: 0.5015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010894773165384928, AUC: 0.63230975\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00993249225616455, AUC: 0.656677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00998604933420817, AUC: 0.6622204999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00969446881612142, AUC: 0.665255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010646321296691895, AUC: 0.667017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10307446034749349, AUC: 0.39473525000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013449175198872884, AUC: 0.6413705000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01240819485982259, AUC: 0.6579860000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011618833859761556, AUC: 0.6779787499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011932540893554687, AUC: 0.6819350000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009558104197184244, AUC: 0.680918\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.06537764231363932, AUC: 0.504011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011672021865844727, AUC: 0.565074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012642004648844402, AUC: 0.6255170000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010598973592122396, AUC: 0.6428105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010454548835754394, AUC: 0.63099425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011468182881673178, AUC: 0.6546750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05565381749471029, AUC: 0.56928575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01292149829864502, AUC: 0.6342015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01203975518544515, AUC: 0.6725727499999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011351526260375977, AUC: 0.6575584999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011287477493286133, AUC: 0.6859489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009301058133443197, AUC: 0.6846742499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04205302047729492, AUC: 0.48225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01363312562306722, AUC: 0.6245335000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011814168294270833, AUC: 0.6465695\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012035372098286947, AUC: 0.664747\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012087131182352702, AUC: 0.676244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011498126029968261, AUC: 0.6763117500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014589320500691732, AUC: 0.5301525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016330102920532226, AUC: 0.66414375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01481008021036784, AUC: 0.6711922499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0140481170018514, AUC: 0.6764834999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011343215942382813, AUC: 0.6814629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01264106019337972, AUC: 0.68691575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.023673147201538087, AUC: 0.5606457499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013253023147583008, AUC: 0.67181825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01283176867167155, AUC: 0.6600950000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010371809005737304, AUC: 0.6838500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010835079828898113, AUC: 0.67707275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010656075795491536, AUC: 0.6930109999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.05952193450927734, AUC: 0.55007425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015438363711039226, AUC: 0.651938\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01512073040008545, AUC: 0.65696775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014937430063883464, AUC: 0.6558785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014672116915384928, AUC: 0.658575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014125942548116048, AUC: 0.65860225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07686312103271484, AUC: 0.57553525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02448072878519694, AUC: 0.5608625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021110279083251953, AUC: 0.5747172500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018814202626546223, AUC: 0.58371425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01746867307027181, AUC: 0.5948125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016521777153015137, AUC: 0.6054462500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.14315791829427083, AUC: 0.49825275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014307780583699544, AUC: 0.66247375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.013678332646687826, AUC: 0.661121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01295363171895345, AUC: 0.6579365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.012683864911397297, AUC: 0.6598515\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01238056214650472, AUC: 0.66437225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1247994867960612, AUC: 0.48969125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.031908031463623046, AUC: 0.4813192500000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.029488585154215496, AUC: 0.4886585\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.027441251754760743, AUC: 0.495814\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02583952267964681, AUC: 0.50692925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02429039510091146, AUC: 0.52350125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0811489003499349, AUC: 0.55550675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.027510016759236654, AUC: 0.5137315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024729629516601563, AUC: 0.5159265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02257259941101074, AUC: 0.52208825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020779212951660155, AUC: 0.537371\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01924815495808919, AUC: 0.543128\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.047958841959635415, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018643898010253908, AUC: 0.5093172499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017556528091430663, AUC: 0.5206435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016849175135294596, AUC: 0.53612525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01629000155131022, AUC: 0.55140875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0157201239267985, AUC: 0.5684462499999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.07679866536458334, AUC: 0.446039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019376900990804035, AUC: 0.584483\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018456173578898113, AUC: 0.5984240000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018232669194539388, AUC: 0.610113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017514451344807943, AUC: 0.61333075\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01681936009724935, AUC: 0.6166690000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1036588363647461, AUC: 0.47480575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.024433186848958333, AUC: 0.4201805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.021908035914103192, AUC: 0.43715975000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019969642639160155, AUC: 0.45478399999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018553023020426433, AUC: 0.48104349999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017067347844441732, AUC: 0.499111\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.10283290100097656, AUC: 0.41275700000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02197241147359212, AUC: 0.57553425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020275236129760742, AUC: 0.5854705000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.019363845825195312, AUC: 0.60017675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.018173115412394206, AUC: 0.610443\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.017710837682088216, AUC: 0.613726\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.04857513554890951, AUC: 0.39813099999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.020976876576741535, AUC: 0.42901775000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01863106028238932, AUC: 0.45469175\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01704348882039388, AUC: 0.47677349999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.016009422938028973, AUC: 0.4866855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.015267799059549968, AUC: 0.5029202500000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Softmax 3 class weighted\n",
    "\n",
    "learning_rates = [1e-5, 1e-6, 5e-7, 1e-7, 1e-8]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10):\n",
    "        model_aucs = []\n",
    "        network = models.SoftmaxLogisticRegression(NUM_CLASSES_REDUCED, shape=32*32*3)\n",
    "        optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        _, auc = metric_utils.auc_softmax(test_loader_reduced, network) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_softmax(epoch, train_loader_ratio, network, optimizer, verbose=False, class_weights=weight)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_softmax(test_loader_reduced, network)\n",
    "                model_aucs.append(auc)\n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"weighted\", 3, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3],\n",
    "            auc_mean[i][4], auc_variance[i][4],\n",
    "            auc_mean[i][5], auc_variance[i][5]]\n",
    "    rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dbb739c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>classes_used</th>\n",
       "      <th>ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>variance_0</th>\n",
       "      <th>mean_10</th>\n",
       "      <th>variance_10</th>\n",
       "      <th>mean_20</th>\n",
       "      <th>variance_20</th>\n",
       "      <th>mean_30</th>\n",
       "      <th>variance_30</th>\n",
       "      <th>mean_40</th>\n",
       "      <th>variance_40</th>\n",
       "      <th>mean_50</th>\n",
       "      <th>variance_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.548379</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.719227</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.692638</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.694694</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.534905</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.810738</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.823757</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.824270</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.821001</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>5.000000e-07</td>\n",
       "      <td>0.527536</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.760206</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.779845</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.796304</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.791114</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.800013</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.687535</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.724008</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.727533</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.741630</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.748629</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(100, 1)</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.514619</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.538144</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.559358</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.577911</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.595342</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.608298</td>\n",
       "      <td>0.005704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 3, 1)</td>\n",
       "      <td>(200, 20, 1)</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.471751</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.631073</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.685806</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.636715</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.638884</td>\n",
       "      <td>0.004918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 3, 1)</td>\n",
       "      <td>(200, 20, 1)</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.477657</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.676633</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.692445</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.632403</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.689182</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 3, 1)</td>\n",
       "      <td>(200, 20, 1)</td>\n",
       "      <td>5.000000e-07</td>\n",
       "      <td>0.483873</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.668588</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.675548</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.674923</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.686763</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.682985</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 3, 1)</td>\n",
       "      <td>(200, 20, 1)</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.486377</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.649002</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.663992</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.669602</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.674974</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weighted</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 3, 1)</td>\n",
       "      <td>(200, 20, 1)</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.490079</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.538886</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.549378</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.559340</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.570045</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.579592</td>\n",
       "      <td>0.003359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  num_classes classes_used         ratio  learning_rate    mean_0  \\\n",
       "0  weighted            2       (0, 1)      (100, 1)   1.000000e-05  0.548379   \n",
       "1  weighted            2       (0, 1)      (100, 1)   1.000000e-06  0.534905   \n",
       "2  weighted            2       (0, 1)      (100, 1)   5.000000e-07  0.527536   \n",
       "3  weighted            2       (0, 1)      (100, 1)   1.000000e-07  0.511716   \n",
       "4  weighted            2       (0, 1)      (100, 1)   1.000000e-08  0.514619   \n",
       "5  weighted            3    (0, 3, 1)  (200, 20, 1)   1.000000e-05  0.471751   \n",
       "6  weighted            3    (0, 3, 1)  (200, 20, 1)   1.000000e-06  0.477657   \n",
       "7  weighted            3    (0, 3, 1)  (200, 20, 1)   5.000000e-07  0.483873   \n",
       "8  weighted            3    (0, 3, 1)  (200, 20, 1)   1.000000e-07  0.486377   \n",
       "9  weighted            3    (0, 3, 1)  (200, 20, 1)   1.000000e-08  0.490079   \n",
       "\n",
       "   variance_0   mean_10  variance_10   mean_20  variance_20   mean_30  \\\n",
       "0    0.009424  0.705224     0.006322  0.719227     0.003053  0.692638   \n",
       "1    0.008606  0.799263     0.004559  0.810738     0.000798  0.823757   \n",
       "2    0.008331  0.760206     0.002216  0.779845     0.000442  0.796304   \n",
       "3    0.005766  0.687535     0.000949  0.724008     0.000250  0.727533   \n",
       "4    0.003869  0.538144     0.009743  0.559358     0.008715  0.577911   \n",
       "5    0.001913  0.651523     0.006141  0.631073     0.005076  0.685806   \n",
       "6    0.002019  0.655639     0.001957  0.676633     0.001646  0.692445   \n",
       "7    0.002099  0.668588     0.000139  0.675548     0.000274  0.674923   \n",
       "8    0.002996  0.623684     0.001199  0.649002     0.000381  0.663992   \n",
       "9    0.003195  0.538886     0.006294  0.549378     0.005560  0.559340   \n",
       "\n",
       "   variance_30   mean_40  variance_40   mean_50  variance_50  \n",
       "0     0.002961  0.683244     0.002862  0.694694     0.001923  \n",
       "1     0.000192  0.824270     0.000030  0.821001     0.000095  \n",
       "2     0.000275  0.791114     0.000428  0.800013     0.000264  \n",
       "3     0.000350  0.741630     0.000171  0.748629     0.000196  \n",
       "4     0.007555  0.595342     0.006466  0.608298     0.005704  \n",
       "5     0.002068  0.636715     0.005314  0.638884     0.004918  \n",
       "6     0.000774  0.632403     0.004050  0.689182     0.000715  \n",
       "7     0.000722  0.686763     0.000070  0.682985     0.000321  \n",
       "8     0.000137  0.669602     0.000240  0.674974     0.000128  \n",
       "9     0.004759  0.570045     0.004029  0.579592     0.003359  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows, columns = col_names) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dff89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results/auc_analysis_weighted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08d45e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0a36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
